<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 50]
- [nucl-th](#nucl-th) [Total: 2]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.IR](#cs.IR) [Total: 17]
- [cs.AI](#cs.AI) [Total: 18]
- [eess.SY](#eess.SY) [Total: 10]
- [cs.DC](#cs.DC) [Total: 2]
- [nucl-ex](#nucl-ex) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Expert-Guided Explainable Few-Shot Learning with Active Sample Selection for Medical Image Analysis](https://arxiv.org/abs/2601.02409)
*Longwei Wang,Ifrat Ikhtear Uddin,KC Santosh*

Main category: cs.CV

TL;DR: 该研究提出EGxFSL和xGAL双框架，解决医学图像分析中标注数据稀缺和模型可解释性不足的问题，通过专家引导的可解释性少样本学习和注意力引导的主动学习，在多个医学影像数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析面临两大关键挑战：标注数据稀缺和模型可解释性不足，这阻碍了临床AI的部署。少样本学习虽然能解决数据限制问题，但缺乏预测透明度；主动学习方法虽然优化数据获取，但忽视了获取样本的可解释性。

Method: 提出双框架解决方案：1) EGxFSL（专家引导的可解释性少样本学习）：通过Grad-CAM-based Dice损失整合放射科医生定义的感兴趣区域作为空间监督，与原型分类联合优化；2) xGAL（可解释性引导的主动学习）：引入迭代样本获取策略，优先考虑预测不确定性和注意力错位，形成闭环框架。

Result: 在BraTS（MRI）、VinDr-CXR（胸部X光）和SIIM-COVID-19（胸部X光）数据集上分别达到92%、76%和62%的准确率，在所有数据集上持续优于非引导基线。在严重数据限制下，xGAL仅用680个样本就达到76%准确率，而随机采样仅为57%。Grad-CAM可视化显示引导模型聚焦于诊断相关区域，并在乳腺超声上验证了跨模态适用性。

Conclusion: 该研究提出的双框架有效解决了医学图像分析中的数据稀缺和可解释性问题，通过专家知识和注意力机制的协同作用，实现了性能提升和临床可解释性，为临床AI部署提供了实用解决方案。

Abstract: Medical image analysis faces two critical challenges: scarcity of labeled data and lack of model interpretability, both hindering clinical AI deployment. Few-shot learning (FSL) addresses data limitations but lacks transparency in predictions. Active learning (AL) methods optimize data acquisition but overlook interpretability of acquired samples. We propose a dual-framework solution: Expert-Guided Explainable Few-Shot Learning (EGxFSL) and Explainability-Guided AL (xGAL). EGxFSL integrates radiologist-defined regions-of-interest as spatial supervision via Grad-CAM-based Dice loss, jointly optimized with prototypical classification for interpretable few-shot learning. xGAL introduces iterative sample acquisition prioritizing both predictive uncertainty and attention misalignment, creating a closed-loop framework where explainability guides training and sample selection synergistically. On the BraTS (MRI), VinDr-CXR (chest X-ray), and SIIM-COVID-19 (chest X-ray) datasets, we achieve accuracies of 92\%, 76\%, and 62\%, respectively, consistently outperforming non-guided baselines across all datasets. Under severe data constraints, xGAL achieves 76\% accuracy with only 680 samples versus 57\% for random sampling. Grad-CAM visualizations demonstrate guided models focus on diagnostically relevant regions, with generalization validated on breast ultrasound confirming cross-modality applicability.

</details>


### [2] [Watch Wider and Think Deeper: Collaborative Cross-modal Chain-of-Thought for Complex Visual Reasoning](https://arxiv.org/abs/2601.02422)
*Wenting Lu,Didi Zhu,Tao Shen,Donglin Zhu,Ayong Ye,Chao Wu*

Main category: cs.CV

TL;DR: CoCoT框架通过动态多区域定位和关系感知推理解决多模态推理中的视觉-语言对齐问题，显著提升复杂视觉推理性能


<details>
  <summary>Details</summary>
Motivation: 现有Chain-of-Thought方法在多模态场景中存在两个关键限制：过度依赖单一粗粒度图像区域，以及连续推理步骤间的语义碎片化问题

Method: 提出CoCoT框架，包含动态多区域定位（基于问题自适应检测最相关图像区域）和关系感知推理（通过迭代对齐视觉线索形成连贯逻辑推理链）

Result: 构建了CoCoT-70K数据集（74,691个高质量样本），在六个挑战性基准测试中，LLaVA-1.5平均准确率提升15.4%，Qwen2-VL提升4.0%

Conclusion: CoCoT框架通过多区域协作和关系感知推理有效解决了多模态推理中的视觉-语言对齐问题，显著提升了复杂视觉推理能力

Abstract: Multi-modal reasoning requires the seamless integration of visual and linguistic cues, yet existing Chain-of-Thought methods suffer from two critical limitations in cross-modal scenarios: (1) over-reliance on single coarse-grained image regions, and (2) semantic fragmentation between successive reasoning steps. To address these issues, we propose the CoCoT (Collaborative Coross-modal Thought) frame- work, built upon two key innovations: a) Dynamic Multi-Region Grounding to adaptively detect the most relevant image regions based on the question, and b) Relation-Aware Reasoning to enable multi-region collaboration by iteratively align- ing visual cues to form a coherent and logical chain of thought. Through this approach, we construct the CoCoT-70K dataset, comprising 74,691 high-quality samples with multi-region annotations and structured reasoning chains. Extensive experiments demonstrate that CoCoT significantly enhances complex visual rea- soning, achieving an average accuracy improvement of 15.4% on LLaVA-1.5 and 4.0% on Qwen2-VL across six challenging benchmarks. The data and code are available at: https://github.com/deer-echo/CoCoT.

</details>


### [3] [NitroGen: An Open Foundation Model for Generalist Gaming Agents](https://arxiv.org/abs/2601.02427)
*Loïc Magne,Anas Awadalla,Guanzhi Wang,Yinzhen Xu,Joshua Belofsky,Fengyuan Hu,Joohwan Kim,Ludwig Schmidt,Georgia Gkioxari,Jan Kautz,Yisong Yue,Yejin Choi,Yuke Zhu,Linxi "Jim" Fan*

Main category: cs.CV

TL;DR: NitroGen是一个基于40000小时游戏视频训练的视觉-动作基础模型，能够在1000多款游戏中实现跨游戏泛化，在未见过的游戏中任务成功率相比从头训练模型提升高达52%。


<details>
  <summary>Details</summary>
Motivation: 构建通用的游戏智能体需要能够理解和执行跨多种游戏类型的复杂任务，现有方法往往针对特定游戏训练，缺乏跨游戏泛化能力。NitroGen旨在解决这一挑战，通过大规模视频数据训练实现通用游戏智能。

Method: 1) 从公开游戏视频中自动提取玩家动作构建互联网规模视频-动作数据集；2) 创建多游戏基准环境以评估跨游戏泛化能力；3) 使用大规模行为克隆训练统一的视觉-动作模型。

Result: NitroGen在3D动作游戏的战斗遭遇、2D平台游戏的高精度控制以及程序生成世界的探索等多样化领域表现出强大能力。在未见过的游戏中，相比从头训练的模型，任务成功率相对提升高达52%。

Conclusion: NitroGen展示了通过大规模视频数据训练实现跨游戏泛化的可行性，为通用具身智能体的研究提供了重要进展。作者发布了数据集、评估套件和模型权重以推动该领域发展。

Abstract: We introduce NitroGen, a vision-action foundation model for generalist gaming agents that is trained on 40,000 hours of gameplay videos across more than 1,000 games. We incorporate three key ingredients: 1) an internet-scale video-action dataset constructed by automatically extracting player actions from publicly available gameplay videos, 2) a multi-game benchmark environment that can measure cross-game generalization, and 3) a unified vision-action model trained with large-scale behavior cloning. NitroGen exhibits strong competence across diverse domains, including combat encounters in 3D action games, high-precision control in 2D platformers, and exploration in procedurally generated worlds. It transfers effectively to unseen games, achieving up to 52% relative improvement in task success rates over models trained from scratch. We release the dataset, evaluation suite, and model weights to advance research on generalist embodied agents.

</details>


### [4] [Understanding Pure Textual Reasoning for Blind Image Quality Assessment](https://arxiv.org/abs/2601.02441)
*Yuan Li,Shin'ya Nishida*

Main category: cs.CV

TL;DR: 该研究从信息流角度分析文本推理在盲图像质量评估中的作用，比较了三种学习图像-文本-分数关系的范式，发现自一致性范式能显著缩小图像与文本预测之间的差距。


<details>
  <summary>Details</summary>
Motivation: 虽然文本推理在盲图像质量评估中已被广泛采用，但文本信息如何贡献于质量预测以及文本能在多大程度上代表与分数相关的图像内容仍不清楚。本研究旨在从信息流角度解决这些问题。

Method: 通过比较现有BIQA模型与三种设计用于学习图像-文本-分数关系的范式：思维链、自一致性和自动编码器，从信息流角度进行分析。

Result: 实验显示：仅使用文本信息时现有模型的预测性能显著下降；思维链范式对BIQA性能提升有限；自一致性范式显著缩小了图像与文本条件预测之间的差距（PLCC/SRCC差异缩小到0.02/0.03）；自动编码器类范式在缩小图像-文本差距方面效果较差，但揭示了进一步优化的方向。

Conclusion: 这些发现为如何改进BIQA和高级视觉任务中的文本推理提供了见解，表明自一致性范式在弥合图像与文本表示差距方面具有潜力。

Abstract: Textual reasoning has recently been widely adopted in Blind Image Quality Assessment (BIQA). However, it remains unclear how textual information contributes to quality prediction and to what extent text can represent the score-related image contents. This work addresses these questions from an information-flow perspective by comparing existing BIQA models with three paradigms designed to learn the image-text-score relationship: Chain-of-Thought, Self-Consistency, and Autoencoder. Our experiments show that the score prediction performance of the existing model significantly drops when only textual information is used for prediction. Whereas the Chain-of-Thought paradigm introduces little improvement in BIQA performance, the Self-Consistency paradigm significantly reduces the gap between image- and text-conditioned predictions, narrowing the PLCC/SRCC difference to 0.02/0.03. The Autoencoder-like paradigm is less effective in closing the image-text gap, yet it reveals a direction for further optimization. These findings provide insights into how to improve the textual reasoning for BIQA and high-level vision tasks.

</details>


### [5] [Evaluating the Diagnostic Classification Ability of Multimodal Large Language Models: Insights from the Osteoarthritis Initiative](https://arxiv.org/abs/2601.02443)
*Li Wang,Xi Chen,XiangWen Deng,HuaHui Yi,ZeKun Jiang,Kang Li,Jian Li*

Main category: cs.CV

TL;DR: 该研究评估了多模态大语言模型在膝骨关节炎X光片分类任务中的表现，发现传统视觉编码器单独使用比完整MLLM管道表现更好，LLM在分类任务中更适合作为解释器和报告生成器而非主要分类器。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在医学视觉问答和报告生成方面表现良好，但其在疾病特异性分类任务上的能力尚未得到可靠验证。膝骨关节炎影响全球3-4亿人，但在现有医学MLLM基准中代表性不足，因此需要评估MLLM在此类医学图像诊断分类任务中的适用性。

Method: 通过系统消融研究，操纵视觉编码器、连接器和大语言模型组件，采用不同训练策略，测量每个组件对诊断准确性的贡献。比较了视觉编码器单独使用与完整MLLM管道的性能，评估了提示引导与微调LLM的效果，并对比了小规模平衡数据集（500张图像）与大规模不平衡数据集（5,778张图像）的训练结果。

Result: 在膝骨关节炎分类任务中，训练好的视觉编码器单独使用比完整MLLM管道分类准确率更高；微调LLM相比基于提示的指导没有显著改进；在小规模平衡数据集上的LoRA微调比在大规模不平衡数据集上训练效果更好，表明数据平衡和质量比原始规模更重要。

Conclusion: 对于领域特定的医学分类任务，大语言模型更适合作为解释器和报告生成器，而不是主要分类器。MLLM架构不太适合需要高确定性的医学图像诊断分类任务。建议在开发临床适用系统时优先优化视觉编码器并进行仔细的数据集构建。

Abstract: Multimodal large language models (MLLMs) show promising performance on medical visual question answering (VQA) and report generation, but these generation and explanation abilities do not reliably transfer to disease-specific classification. We evaluated MLLM architectures on knee osteoarthritis (OA) radiograph classification, which remains underrepresented in existing medical MLLM benchmarks, even though knee OA affects an estimated 300 to 400 million people worldwide. Through systematic ablation studies manipulating the vision encoder, the connector, and the large language model (LLM) across diverse training strategies, we measured each component's contribution to diagnostic accuracy. In our classification task, a trained vision encoder alone could outperform full MLLM pipelines in classification accuracy and fine-tuning the LLM provided no meaningful improvement over prompt-based guidance. And LoRA fine-tuning on a small, class-balanced dataset (500 images) gave better results than training on a much larger but class-imbalanced set (5,778 images), indicating that data balance and quality can matter more than raw scale for this task. These findings suggest that for domain-specific medical classification, LLMs are more effective as interpreters and report generators rather than as primary classifiers. Therefore, the MLLM architecture appears less suitable for medical image diagnostic classification tasks that demand high certainty. We recommend prioritizing vision encoder optimization and careful dataset curation when developing clinically applicable systems.

</details>


### [6] [PatchAlign3D: Local Feature Alignment for Dense 3D Shape understanding](https://arxiv.org/abs/2601.02457)
*Souhail Hadgi,Bingchen Gong,Ramana Sundararaman,Emery Pierson,Lei Li,Peter Wonka,Maks Ovsjanikov*

Main category: cs.CV

TL;DR: 提出PatchAlign3D：一种直接从点云生成语言对齐的patch级特征的编码器模型，实现零样本3D部件分割，无需多视角渲染或LLM提示工程


<details>
  <summary>Details</summary>
Motivation: 当前3D基础模型擅长全局任务（检索、分类），但在局部部件级推理上表现不佳。现有方法依赖多视角渲染和文本查询，需要昂贵的推理过程、依赖LLM提示工程，且未能充分利用3D几何信息

Method: 引入编码器式3D模型，直接从点云生成语言对齐的patch级特征。预训练分两阶段：1）从视觉编码器（如DINOv2）蒸馏密集2D特征到3D patch；2）通过多正对比目标将patch嵌入与部件级文本嵌入对齐

Result: 模型实现零样本3D部件分割，单次推理无需多视角渲染，在多个3D部件分割基准上显著优于之前的渲染式和前馈方法

Conclusion: PatchAlign3D填补了3D基础模型在局部部件级推理上的空白，通过直接处理点云并实现语言对齐的patch特征，提供了高效且性能优越的3D部件分割解决方案

Abstract: Current foundation models for 3D shapes excel at global tasks (retrieval, classification) but transfer poorly to local part-level reasoning. Recent approaches leverage vision and language foundation models to directly solve dense tasks through multi-view renderings and text queries. While promising, these pipelines require expensive inference over multiple renderings, depend heavily on large language-model (LLM) prompt engineering for captions, and fail to exploit the inherent 3D geometry of shapes. We address this gap by introducing an encoder-only 3D model that produces language-aligned patch-level features directly from point clouds. Our pre-training approach builds on existing data engines that generate part-annotated 3D shapes by pairing multi-view SAM regions with VLM captioning. Using this data, we train a point cloud transformer encoder in two stages: (1) distillation of dense 2D features from visual encoders such as DINOv2 into 3D patches, and (2) alignment of these patch embeddings with part-level text embeddings through a multi-positive contrastive objective. Our 3D encoder achieves zero-shot 3D part segmentation with fast single-pass inference without any test-time multi-view rendering, while significantly outperforming previous rendering-based and feed-forward approaches across several 3D part segmentation benchmarks. Project website: https://souhail-hadgi.github.io/patchalign3dsite/

</details>


### [7] [MovieRecapsQA: A Multimodal Open-Ended Video Question-Answering Benchmark](https://arxiv.org/abs/2601.02536)
*Shaden Shaar,Bradon Thymes,Sirawut Chaixanien,Claire Cardie,Bharath Hariharan*

Main category: cs.CV

TL;DR: MovieRecapsQA：首个提供显式文本上下文的开放式多模态视频问答基准，基于电影重述视频构建，包含约8.2K个问答对，支持无参考评估。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答基准难以捕捉真实电影理解所需的多模态推理能力，且大多不是开放式的，因为自由形式答案难以评估。

Method: 利用YouTube电影重述视频构建基准，通过重述摘要生成约8.2K个与电影字幕对齐的问答对，提供验证答案所需的"事实"信息，支持无参考评估。

Result: 评估了7个最先进的多模态大语言模型，发现：1）纯视觉问题最具挑战性；2）模型倾向于依赖文本输入；3）从视频中提取准确事实信息仍然困难；4）专有和开源模型在视频依赖问题上表现相当。

Conclusion: MovieRecapsQA是首个提供显式文本上下文的开放式视频问答基准，支持细粒度分析，揭示了当前多模态模型在视频理解方面的局限性。

Abstract: Understanding real-world videos such as movies requires integrating visual and dialogue cues to answer complex questions. Yet existing VideoQA benchmarks struggle to capture this multimodal reasoning and are largely not open-ended, given the difficulty of evaluating free-form answers. In this paper, we introduce a novel open-ended multi-modal VideoQA benchmark, MovieRecapsQA created using movie recap videos--a distinctive type of YouTube content that summarizes a film by presenting its key events through synchronized visual (recap video) and textual (recap summary) modalities. Using the recap summary, we generate $\approx 8.2$ K question-answer (QA) pairs (aligned with movie-subtitles) and provide the necessary "facts" needed to verify an answer in a reference-free manner. To our knowledge, this is the first open-ended VideoQA benchmark that supplies explicit textual context of the input (video and/or text); which we use for evaluation. Our benchmark provides videos of multiple lengths (i.e., recap-segments, movie-segments) and categorizations of questions (by modality and type) to enable fine-grained analysis. We evaluate the performance of seven state-of-the-art MLLMs using our benchmark and observe that: 1) visual-only questions remain the most challenging; 2) models default to textual inputs whenever available; 3) extracting factually accurate information from video content is still difficult for all models; and 4) proprietary and open-source models perform comparably on video-dependent questions.

</details>


### [8] [DreamLoop: Controllable Cinemagraph Generation from a Single Photograph](https://arxiv.org/abs/2601.02646)
*Aniruddha Mahapatra,Long Mai,Cusuh Ham,Feng Liu*

Main category: cs.CV

TL;DR: DreamLoop是一个可控的视频合成框架，能够从单张照片生成高质量的电影循环图，无需专门的电影循环训练数据，通过时间桥接和运动条件训练实现灵活控制。


<details>
  <summary>Details</summary>
Motivation: 现有图像动画技术仅限于简单、低频运动，且只能在具有重复纹理的狭窄领域（如水和烟雾）工作。大规模视频扩散模型不适合电影循环约束，缺乏生成无缝、可控循环所需的专门数据。需要一种能够从单张照片生成可控电影循环图的方法。

Method: DreamLoop通过训练视频扩散模型的两个目标来适应电影循环生成：时间桥接和运动条件。在推理时，使用输入图像作为第一帧和最后一帧条件来强制无缝循环，通过静态轨迹条件保持静态背景，并通过用户指定的目标对象运动路径提供直观控制。

Result: DreamLoop能够生成高质量、复杂的电影循环图，与用户意图一致，优于现有方法。这是第一个能够为一般场景生成具有灵活直观控制的电影循环图的方法。

Conclusion: DreamLoop成功解决了从单张照片生成可控电影循环图的挑战，通过创新的训练策略实现了高质量、用户可控的电影循环生成，为一般场景提供了首个灵活直观的控制方法。

Abstract: Cinemagraphs, which combine static photographs with selective, looping motion, offer unique artistic appeal. Generating them from a single photograph in a controllable manner is particularly challenging. Existing image-animation techniques are restricted to simple, low-frequency motions and operate only in narrow domains with repetitive textures like water and smoke. In contrast, large-scale video diffusion models are not tailored for cinemagraph constraints and lack the specialized data required to generate seamless, controlled loops. We present DreamLoop, a controllable video synthesis framework dedicated to generating cinemagraphs from a single photo without requiring any cinemagraph training data. Our key idea is to adapt a general video diffusion model by training it on two objectives: temporal bridging and motion conditioning. This strategy enables flexible cinemagraph generation. During inference, by using the input image as both the first- and last- frame condition, we enforce a seamless loop. By conditioning on static tracks, we maintain a static background. Finally, by providing a user-specified motion path for a target object, our method provides intuitive control over the animation's trajectory and timing. To our knowledge, DreamLoop is the first method to enable cinemagraph generation for general scenes with flexible and intuitive controls. We demonstrate that our method produces high-quality, complex cinemagraphs that align with user intent, outperforming existing approaches.

</details>


### [9] [GRRE: Leveraging G-Channel Removed Reconstruction Error for Robust Detection of AI-Generated Images](https://arxiv.org/abs/2601.02709)
*Shuman He,Xiehua Li,Xioaju Yang,Yang Xiong,Keqin Li*

Main category: cs.CV

TL;DR: 本文提出了一种基于绿色通道移除重建误差（GRRE）的AI生成图像检测新方法，通过分析真实图像与AI生成图像在绿色通道移除重建后的误差差异来实现鲁棒检测。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型和GAN等生成模型的快速发展，区分合成图像与真实图像变得越来越困难。现有的检测方法在面对新型或未见过的生成模型时，检测精度往往会下降，这突显了实现强泛化能力的挑战。

Method: 提出了一种基于通道移除重建的检测范式。具体来说，观察到当从真实图像中移除绿色（G）通道并进行重建时，其重建误差与AI生成图像的重建误差存在显著差异。基于这一发现，提出了绿色通道移除重建误差（GRRE）方法，利用这种差异进行鲁棒的AI生成图像检测。

Result: 大量实验表明，GRRE在多个生成模型（包括训练期间未见过的模型）上都能持续实现高检测精度。与现有方法相比，GRRE不仅对各种扰动和后处理操作保持强鲁棒性，而且表现出优越的跨模型泛化能力。

Conclusion: 基于通道移除重建的方法具有作为强大取证工具的潜力，能够在生成式AI时代保护图像的真实性。GRRE方法简单而有效，为解决AI生成图像检测的泛化问题提供了新思路。

Abstract: The rapid progress of generative models, particularly diffusion models and GANs, has greatly increased the difficulty of distinguishing synthetic images from real ones. Although numerous detection methods have been proposed, their accuracy often degrades when applied to images generated by novel or unseen generative models, highlighting the challenge of achieving strong generalization. To address this challenge, we introduce a novel detection paradigm based on channel removal reconstruction. Specifically, we observe that when the green (G) channel is removed from real images and reconstructed, the resulting reconstruction errors differ significantly from those of AI-generated images. Building upon this insight, we propose G-channel Removed Reconstruction Error (GRRE), a simple yet effective method that exploits this discrepancy for robust AI-generated image detection. Extensive experiments demonstrate that GRRE consistently achieves high detection accuracy across multiple generative models, including those unseen during training. Compared with existing approaches, GRRE not only maintains strong robustness against various perturbations and post-processing operations but also exhibits superior cross-model generalization. These results highlight the potential of channel-removal-based reconstruction as a powerful forensic tool for safeguarding image authenticity in the era of generative AI.

</details>


### [10] [CAMO: Category-Agnostic 3D Motion Transfer from Monocular 2D Videos](https://arxiv.org/abs/2601.02716)
*Taeyeon Kim,Youngju Na,Jumin Lee,Minhyuk Sung,Sung-Eui Yoon*

Main category: cs.CV

TL;DR: CAMO是一个类别无关的框架，能够从单目2D视频直接将运动转移到多样化的目标网格，无需预定义模板或显式3D监督。


<details>
  <summary>Details</summary>
Motivation: 现有的运动转移方法面临姿态歧义和物体形状多样性的挑战，通常需要类别特定的参数化模板，限制了方法的通用性。

Method: CAMO采用形态参数化的关节3D高斯泼溅模型，结合密集语义对应关系，通过优化联合调整形状和姿态，有效缓解形状-姿态歧义。

Result: 实验结果表明，CAMO在运动准确性、效率和视觉连贯性方面优于现有方法，在多样化物体类别和日常视频场景中显著推进了运动转移技术。

Conclusion: CAMO框架通过形态参数化的3D高斯泼溅模型和语义对应关系，实现了类别无关的运动转移，有效解决了形状-姿态歧义问题，为多样化物体的运动转移提供了有效解决方案。

Abstract: Motion transfer from 2D videos to 3D assets is a challenging problem, due to inherent pose ambiguities and diverse object shapes, often requiring category-specific parametric templates. We propose CAMO, a category-agnostic framework that transfers motion to diverse target meshes directly from monocular 2D videos without relying on predefined templates or explicit 3D supervision. The core of CAMO is a morphology-parameterized articulated 3D Gaussian splatting model combined with dense semantic correspondences to jointly adapt shape and pose through optimization. This approach effectively alleviates shape-pose ambiguities, enabling visually faithful motion transfer for diverse categories. Experimental results demonstrate superior motion accuracy, efficiency, and visual coherence compared to existing methods, significantly advancing motion transfer in varied object categories and casual video scenarios.

</details>


### [11] [Robust Mesh Saliency GT Acquisition in VR via View Cone Sampling and Geometric Smoothing](https://arxiv.org/abs/2601.02721)
*Guoquan Zheng,Jie Hao,Huiyu Duan,Yongming Han,Liang Yuan,Dong Zhang,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了一种用于VR环境中3D网格显著性标注的鲁棒框架，通过视锥采样和混合流形-欧几里得约束扩散算法，解决了现有方法在复杂拓扑结构下的采样和传播问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D网格显著性标注方法大多沿用2D图像方法，忽略了3D几何拓扑与2D图像阵列的差异。VR眼动追踪管道依赖单射线采样和欧几里得平滑，导致纹理注意力和信号在间隙中泄漏，需要更符合人类感知的高保真3D注意力获取方法。

Method: 1. 视锥采样策略：通过高斯分布的射线束模拟人类中央凹感受野，提高复杂拓扑结构的采样鲁棒性；2. 混合流形-欧几里得约束扩散算法：融合流形测地线约束与欧几里得尺度，确保拓扑一致的显著性传播。

Result: 该框架通过缓解"拓扑短路"和混叠效应，提供了一个与自然人类感知一致的高保真3D注意力获取范式，为3D网格显著性研究提供了更准确和鲁棒的基线。

Conclusion: 提出的框架解决了现有3D网格显著性标注方法的局限性，通过更符合人类感知机制的采样和传播方法，为VR环境中的人为中心视觉建模提供了可靠的3D网格显著性标注方案。

Abstract: Reliable 3D mesh saliency ground truth (GT) is essential for human-centric visual modeling in virtual reality (VR). However, current 3D mesh saliency GT acquisition methods are generally consistent with 2D image methods, ignoring the differences between 3D geometry topology and 2D image array. Current VR eye-tracking pipelines rely on single ray sampling and Euclidean smoothing, triggering texture attention and signal leakage across gaps. This paper proposes a robust framework to address these limitations. We first introduce a view cone sampling (VCS) strategy, which simulates the human foveal receptive field via Gaussian-distributed ray bundles to improve sampling robustness for complex topologies. Furthermore, a hybrid Manifold-Euclidean constrained diffusion (HCD) algorithm is developed, fusing manifold geodesic constraints with Euclidean scales to ensure topologically-consistent saliency propagation. By mitigating "topological short-circuits" and aliasing, our framework provides a high-fidelity 3D attention acquisition paradigm that aligns with natural human perception, offering a more accurate and robust baseline for 3D mesh saliency research.

</details>


### [12] [Foreground-Aware Dataset Distillation via Dynamic Patch Selection](https://arxiv.org/abs/2601.02727)
*Longzhen Li,Guang Li,Ren Togo,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CV

TL;DR: 提出了一种前景感知的数据集蒸馏方法，通过内容自适应增强补丁选择，在保持关键前景信息的同时减少冗余背景内容


<details>
  <summary>Details</summary>
Motivation: 传统优化方法计算成本高、内存受限且生成不现实的噪声图像，而非优化方法使用刚性补丁选择策略可能丢弃主要对象的关键信息

Method: 利用Grounded SAM2识别前景对象并计算每张图像的前景占用率，推导类别级补丁决策阈值，设计动态补丁选择策略，根据前景占比选择最具信息量的补丁或直接调整完整图像大小

Result: 在多个基准测试上的实验表明，该方法相比现有方法持续提升蒸馏性能，生成更具信息性和代表性的蒸馏数据集，并增强不同架构和图像组合的鲁棒性

Conclusion: 提出的前景感知数据集蒸馏方法通过内容自适应补丁选择，有效解决了传统方法的关键信息丢失问题，在保持计算效率的同时显著提升了蒸馏质量

Abstract: In this paper, we propose a foreground-aware dataset distillation method that enhances patch selection in a content-adaptive manner. With the rising computational cost of training large-scale deep models, dataset distillation has emerged as a promising approach for constructing compact synthetic datasets that retain the knowledge of their large original counterparts. However, traditional optimization-based methods often suffer from high computational overhead, memory constraints, and the generation of unrealistic, noise-like images with limited architectural generalization. Recent non-optimization methods alleviate some of these issues by constructing distilled data from real image patches, but the used rigid patch selection strategies can still discard critical information about the main objects. To solve this problem, we first leverage Grounded SAM2 to identify foreground objects and compute per-image foreground occupancy, from which we derive a category-wise patch decision threshold. Guided by these thresholds, we design a dynamic patch selection strategy that, for each image, either selects the most informative patch from multiple candidates or directly resizes the full image when the foreground dominates. This dual-path mechanism preserves more key information about the main objects while reducing redundant background content. Extensive experiments on multiple benchmarks show that the proposed method consistently improves distillation performance over existing approaches, producing more informative and representative distilled datasets and enhancing robustness across different architectures and image compositions.

</details>


### [13] [Unveiling and Bridging the Functional Perception Gap in MLLMs: Atomic Visual Alignment and Hierarchical Evaluation via PET-Bench](https://arxiv.org/abs/2601.02737)
*Zanting Ye,Xiaolong Niu,Xuanbin Wu,Xu Han,Shengyuan Liu,Jing Hao,Zhihao Peng,Hao Sun,Jieqin Lv,Fanghu Wang,Yanchao Huang,Hubing Wu,Yixuan Yuan,Habib Zaidi,Arman Rahmim,Yefeng Zheng,Lijun Lu*

Main category: cs.CV

TL;DR: 该论文发现当前多模态大语言模型在功能成像（特别是PET扫描）中存在功能性感知差距，提出了PET-Bench基准测试，揭示了思维链提示的幻觉陷阱，并提出原子视觉对齐方法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在解剖模态的异常检测和报告生成方面表现出色，但它们在功能成像（如PET扫描）中的能力尚未得到充分探索。作者发现当前视觉编码器无法独立于形态学先验解码功能性示踪剂生物分布，存在功能性感知差距。

Method: 1. 引入PET-Bench，首个大规模功能成像基准，包含52,308个分层QA对，来自9,732个多中心、多示踪剂PET研究；2. 评估19个最先进的多模态大语言模型；3. 提出原子视觉对齐（AVA）微调策略，强制模型在高级诊断推理前掌握低级功能性感知。

Result: 评估揭示了关键的思维链幻觉陷阱：标准思维链提示会解耦语言生成与视觉证据，产生临床流畅但事实无根据的诊断。AVA方法有效弥合了感知差距，将思维链从幻觉来源转变为稳健推理工具，诊断准确率提升高达14.83%。

Conclusion: 该研究首次系统量化了多模态大语言模型在功能成像中的感知差距，揭示了思维链提示的潜在风险，并提出有效的解决方案。AVA方法通过强制低级视觉对齐，显著提升了PET图像诊断的准确性和可靠性。

Abstract: While Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in tasks such as abnormality detection and report generation for anatomical modalities, their capability in functional imaging remains largely unexplored. In this work, we identify and quantify a fundamental functional perception gap: the inability of current vision encoders to decode functional tracer biodistribution independent of morphological priors. Identifying Positron Emission Tomography (PET) as the quintessential modality to investigate this disconnect, we introduce PET-Bench, the first large-scale functional imaging benchmark comprising 52,308 hierarchical QA pairs from 9,732 multi-site, multi-tracer PET studies. Extensive evaluation of 19 state-of-the-art MLLMs reveals a critical safety hazard termed the Chain-of-Thought (CoT) hallucination trap. We observe that standard CoT prompting, widely considered to enhance reasoning, paradoxically decouples linguistic generation from visual evidence in PET, producing clinically fluent but factually ungrounded diagnoses. To resolve this, we propose Atomic Visual Alignment (AVA), a simple fine-tuning strategy that enforces the mastery of low-level functional perception prior to high-level diagnostic reasoning. Our results demonstrate that AVA effectively bridges the perception gap, transforming CoT from a source of hallucination into a robust inference tool and improving diagnostic accuracy by up to 14.83%. Code and data are available at https://github.com/yezanting/PET-Bench.

</details>


### [14] [D$^3$R-DETR: DETR with Dual-Domain Density Refinement for Tiny Object Detection in Aerial Images](https://arxiv.org/abs/2601.02747)
*Zixiao Wen,Zhen Yang,Xianjie Bao,Lei Zhang,Xiantai Xiang,Wenshuai Li,Yuhan Liu*

Main category: cs.CV

TL;DR: D³R-DETR：一种基于DETR的双域密度细化检测器，专门用于遥感图像中的微小目标检测，通过融合空间域和频域信息来提升检测精度。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中的微小目标检测至关重要，但这些目标像素信息极其有限且密度变化显著，导致主流基于Transformer的检测器收敛缓慢且查询-目标匹配不准确。

Method: 提出D³R-DETR（DETR-based detector with Dual-Domain Density Refinement），通过融合空间域和频域信息来细化低层特征图，利用其丰富的细节预测更准确的目标密度图，从而精确地定位微小目标。

Result: 在AI-TOD-v2数据集上的大量实验表明，D³R-DETR在微小目标检测方面优于现有的最先进检测器。

Conclusion: D³R-DETR通过双域密度细化有效解决了遥感图像中微小目标检测的挑战，在精度上超越了现有方法。

Abstract: Detecting tiny objects plays a vital role in remote sensing intelligent interpretation, as these objects often carry critical information for downstream applications. However, due to the extremely limited pixel information and significant variations in object density, mainstream Transformer-based detectors often suffer from slow convergence and inaccurate query-object matching. To address these challenges, we propose D$^3$R-DETR, a novel DETR-based detector with Dual-Domain Density Refinement. By fusing spatial and frequency domain information, our method refines low-level feature maps and utilizes their rich details to predict more accurate object density map, thereby guiding the model to precisely localize tiny objects. Extensive experiments on the AI-TOD-v2 dataset demonstrate that D$^3$R-DETR outperforms existing state-of-the-art detectors for tiny object detection.

</details>


### [15] [Towards Zero-Shot Point Cloud Registration Across Diverse Scales, Scenes, and Sensor Setups](https://arxiv.org/abs/2601.02759)
*Hyungtae Lim,Minkyun Seo,Luca Carlone,Jaesik Park*

Main category: cs.CV

TL;DR: BUFFER-X是一个无需训练的点云配准框架，通过几何引导的超参数估计、分布感知的最远点采样和补丁级坐标归一化实现零样本泛化，在12个数据集上验证了跨域配准能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的点云配准方法在零样本泛化方面存在困难，通常需要针对新环境进行超参数调整或重新训练。论文识别了三个关键限制：固定用户定义参数无法适应不同尺度、学习的关键点检测器跨域迁移性差、绝对坐标会放大数据集间的尺度不匹配。

Method: 提出BUFFER-X框架，包含三个核心创新：(1) 几何引导的超参数自动估计，(2) 分布感知的最远点采样替代学习型检测器，(3) 补丁级坐标归一化确保尺度一致性。采用分层多尺度匹配在局部、中间和全局感受野提取对应关系。还提出了BUFFER-X-Lite版本，通过早期退出策略和快速位姿求解器减少43%计算时间。

Result: 在包含12个数据集的综合基准测试中评估，涵盖物体尺度、室内和室外场景，包括异构LiDAR配置间的跨传感器配准。结果表明该方法无需手动调整或测试域先验知识即可有效泛化。

Conclusion: BUFFER-X通过训练无关的框架解决了点云配准的零样本泛化问题，在多种环境和传感器配置下表现出强大的跨域适应能力，为实际应用提供了高效可靠的解决方案。

Abstract: Some deep learning-based point cloud registration methods struggle with zero-shot generalization, often requiring dataset-specific hyperparameter tuning or retraining for new environments. We identify three critical limitations: (a) fixed user-defined parameters (e.g., voxel size, search radius) that fail to generalize across varying scales, (b) learned keypoint detectors exhibit poor cross-domain transferability, and (c) absolute coordinates amplify scale mismatches between datasets. To address these three issues, we present BUFFER-X, a training-free registration framework that achieves zero-shot generalization through: (a) geometric bootstrapping for automatic hyperparameter estimation, (b) distribution-aware farthest point sampling to replace learned detectors, and (c) patch-level coordinate normalization to ensure scale consistency. Our approach employs hierarchical multi-scale matching to extract correspondences across local, middle, and global receptive fields, enabling robust registration in diverse environments. For efficiency-critical applications, we introduce BUFFER-X-Lite, which reduces total computation time by 43% (relative to BUFFER-X) through early exit strategies and fast pose solvers while preserving accuracy. We evaluate on a comprehensive benchmark comprising 12 datasets spanning object-scale, indoor, and outdoor scenes, including cross-sensor registration between heterogeneous LiDAR configurations. Results demonstrate that our approach generalizes effectively without manual tuning or prior knowledge of test domains. Code: https://github.com/MIT-SPARK/BUFFER-X.

</details>


### [16] [AnyDepth: Depth Estimation Made Easy](https://arxiv.org/abs/2601.02760)
*Zeyu Ren,Zeyu Zhang,Wukai Li,Qingxiang Liu,Hao Tang*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级、数据中心的零样本单目深度估计框架，采用DINOv3作为视觉编码器，设计了Simple Depth Transformer（SDT）作为紧凑型解码器，并提出了基于质量的数据过滤策略，在减少参数85%-89%的同时提高了精度。


<details>
  <summary>Details</summary>
Motivation: 当前单目深度估计方法依赖大规模数据集和复杂解码器，限制了效率和泛化能力。需要开发更轻量、数据高效且具有良好泛化性能的零样本深度估计方法。

Method: 1. 采用DINOv3作为视觉编码器获取高质量密集特征；2. 设计Simple Depth Transformer（SDT）作为紧凑型解码器，采用单路径特征融合和上采样过程，减少跨尺度特征融合计算开销；3. 提出基于质量的数据过滤策略，筛选有害样本，减少数据集规模同时提高训练质量。

Result: 在五个基准测试上的广泛实验表明，该框架在精度上超越了DPT，同时将参数数量减少了约85%-89%，实现了更高的准确性和效率。

Conclusion: 这项工作强调了平衡模型设计和数据质量对于实现高效且可泛化的零样本深度估计的重要性，为轻量级深度估计提供了有效解决方案。

Abstract: Monocular depth estimation aims to recover the depth information of 3D scenes from 2D images. Recent work has made significant progress, but its reliance on large-scale datasets and complex decoders has limited its efficiency and generalization ability. In this paper, we propose a lightweight and data-centric framework for zero-shot monocular depth estimation. We first adopt DINOv3 as the visual encoder to obtain high-quality dense features. Secondly, to address the inherent drawbacks of the complex structure of the DPT, we design the Simple Depth Transformer (SDT), a compact transformer-based decoder. Compared to the DPT, it uses a single-path feature fusion and upsampling process to reduce the computational overhead of cross-scale feature fusion, achieving higher accuracy while reducing the number of parameters by approximately 85%-89%. Furthermore, we propose a quality-based filtering strategy to filter out harmful samples, thereby reducing dataset size while improving overall training quality. Extensive experiments on five benchmarks demonstrate that our framework surpasses the DPT in accuracy. This work highlights the importance of balancing model design and data quality for achieving efficient and generalizable zero-shot depth estimation. Code: https://github.com/AIGeeksGroup/AnyDepth. Website: https://aigeeksgroup.github.io/AnyDepth.

</details>


### [17] [ClearAIR: A Human-Visual-Perception-Inspired All-in-One Image Restoration](https://arxiv.org/abs/2601.02763)
*Xu Zhang,Huan Zhang,Guoli Wang,Qian Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: ClearAIR是一个基于人类视觉感知启发的全合一图像修复框架，采用分层粗到细的修复策略，通过MLLM质量评估、区域感知任务识别和内部线索重用机制，显著提升复杂退化图像的修复质量。


<details>
  <summary>Details</summary>
Motivation: 现有全合一图像修复方法过度依赖退化特定表示，容易导致过度平滑和伪影问题。需要一种更智能的方法来准确处理现实世界中的复杂复合退化。

Method: 1. 基于MLLM的图像质量评估：利用多模态大语言模型进行整体评估，通过跨模态理解准确表征复杂退化
2. 区域感知与任务识别：使用语义交叉注意力生成粗粒度语义提示，结合退化感知模块捕获区域特定退化特征
3. 内部线索重用机制：以自监督方式挖掘和利用图像自身内在信息，增强细节修复

Result: 实验结果表明，ClearAIR在多种合成和真实世界数据集上均取得了优越性能，显著提升了图像修复质量。

Conclusion: ClearAIR通过模仿人类视觉感知的分层处理策略，结合整体评估、区域感知和内部线索重用，有效解决了现有全合一图像修复方法的局限性，为复杂退化图像的修复提供了创新解决方案。

Abstract: All-in-One Image Restoration (AiOIR) has advanced significantly, offering promising solutions for complex real-world degradations. However, most existing approaches rely heavily on degradation-specific representations, often resulting in oversmoothing and artifacts. To address this, we propose ClearAIR, a novel AiOIR framework inspired by Human Visual Perception (HVP) and designed with a hierarchical, coarse-to-fine restoration strategy. First, leveraging the global priority of early HVP, we employ a Multimodal Large Language Model (MLLM)-based Image Quality Assessment (IQA) model for overall evaluation. Unlike conventional IQA, our method integrates cross-modal understanding to more accurately characterize complex, composite degradations. Building upon this overall assessment, we then introduce a region awareness and task recognition pipeline. A semantic cross-attention, leveraging semantic guidance unit, first produces coarse semantic prompts. Guided by this regional context, a degradation-aware module implicitly captures region-specific degradation characteristics, enabling more precise local restoration. Finally, to recover fine details, we propose an internal clue reuse mechanism. It operates in a self-supervised manner to mine and leverage the intrinsic information of the image itself, substantially enhancing detail restoration. Experimental results show that ClearAIR achieves superior performance across diverse synthetic and real-world datasets.

</details>


### [18] [AbductiveMLLM: Boosting Visual Abductive Reasoning Within MLLMs](https://arxiv.org/abs/2601.02771)
*Boyu Chang,Qi Wang,Xi Guo,Zhixiong Nan,Yazhou Yao,Tianfei Zhou*

Main category: cs.CV

TL;DR: AbductiveMLLM：一种模仿人类双重认知模式的视觉溯因推理框架，通过REASONER和IMAGINER两个协同组件，在语言和视觉领域分别进行推理和想象，显著提升多模态大语言模型的溯因推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型虽然在通用多模态推理方面表现出色，但在视觉溯因推理任务上仍远不及人类。人类在溯因推理时通常结合语言推理和视觉想象两种认知模式，而现有MLLMs缺乏这种双重模式的协同机制，导致在解释不完整视觉观察时表现不佳。

Method: 提出AbductiveMLLM框架，包含两个协同组件：1) REASONER：在语言领域工作，先用盲LLM探索广泛的可能解释空间，然后基于跨模态因果对齐修剪视觉不一致的假设，将剩余假设作为先验知识引导MLLM推理；2) IMAGINER：模仿人类视觉思维，基于输入视频和REASONER的输出嵌入，使用文本到图像扩散模型"想象"与语言解释对应的合理视觉场景，增强MLLM的上下文基础。两个组件以端到端方式联合训练。

Result: 在标准视觉溯因推理基准测试中，AbductiveMLLM取得了最先进的性能，一致优于传统解决方案和先进的多模态大语言模型。

Conclusion: 通过模仿人类语言推理和视觉想象的双重认知模式，AbductiveMLLM有效提升了多模态大语言模型的视觉溯因推理能力，为AI系统处理不完整视觉观察的解释任务提供了新的解决方案。

Abstract: Visual abductive reasoning (VAR) is a challenging task that requires AI systems to infer the most likely explanation for incomplete visual observations. While recent MLLMs develop strong general-purpose multimodal reasoning capabilities, they fall short in abductive inference, as compared to human beings. To bridge this gap, we draw inspiration from the interplay between verbal and pictorial abduction in human cognition, and propose to strengthen abduction of MLLMs by mimicking such dual-mode behavior. Concretely, we introduce AbductiveMLLM comprising of two synergistic components: REASONER and IMAGINER. The REASONER operates in the verbal domain. It first explores a broad space of possible explanations using a blind LLM and then prunes visually incongruent hypotheses based on cross-modal causal alignment. The remaining hypotheses are introduced into the MLLM as targeted priors, steering its reasoning toward causally coherent explanations. The IMAGINER, on the other hand, further guides MLLMs by emulating human-like pictorial thinking. It conditions a text-to-image diffusion model on both the input video and the REASONER's output embeddings to "imagine" plausible visual scenes that correspond to verbal explanation, thereby enriching MLLMs' contextual grounding. The two components are trained jointly in an end-to-end manner. Experiments on standard VAR benchmarks show that AbductiveMLLM achieves state-of-the-art performance, consistently outperforming traditional solutions and advanced MLLMs.

</details>


### [19] [DreamStyle: A Unified Framework for Video Stylization](https://arxiv.org/abs/2601.02785)
*Mengtian Li,Jinshu Chen,Songtao Zhao,Wanquan Feng,Pengqi Tu,Qian He*

Main category: cs.CV

TL;DR: DreamStyle是一个统一的视频风格化框架，支持文本引导、风格图像引导和首帧引导三种风格条件，通过精心设计的数据收集流程和基于LoRA的特定token上矩阵训练，解决了现有方法风格不一致和时间闪烁的问题。


<details>
  <summary>Details</summary>
Motivation: 视频风格化作为视频生成模型的重要下游任务尚未得到充分探索。现有方法通常局限于单一类型的风格条件（文本、风格图像或风格化首帧），限制了应用范围，同时缺乏高质量数据集导致风格不一致和时间闪烁问题。

Method: 基于基础的图像到视频（I2V）模型构建，采用精心设计的数据收集流程获取高质量配对视频数据，使用低秩适应（LoRA）配合特定token的上矩阵训练，减少不同条件token之间的混淆。

Result: 定性和定量评估表明，DreamStyle在所有三种视频风格化任务中都表现出色，在风格一致性和视频质量方面优于竞争对手。

Conclusion: DreamStyle提供了一个统一的视频风格化框架，成功解决了现有方法在风格条件多样性和数据质量方面的限制，实现了更灵活、准确和一致的多条件视频风格化。

Abstract: Video stylization, an important downstream task of video generation models, has not yet been thoroughly explored. Its input style conditions typically include text, style image, and stylized first frame. Each condition has a characteristic advantage: text is more flexible, style image provides a more accurate visual anchor, and stylized first frame makes long-video stylization feasible. However, existing methods are largely confined to a single type of style condition, which limits their scope of application. Additionally, their lack of high-quality datasets leads to style inconsistency and temporal flicker. To address these limitations, we introduce DreamStyle, a unified framework for video stylization, supporting (1) text-guided, (2) style-image-guided, and (3) first-frame-guided video stylization, accompanied by a well-designed data curation pipeline to acquire high-quality paired video data. DreamStyle is built on a vanilla Image-to-Video (I2V) model and trained using a Low-Rank Adaptation (LoRA) with token-specific up matrices that reduces the confusion among different condition tokens. Both qualitative and quantitative evaluations demonstrate that DreamStyle is competent in all three video stylization tasks, and outperforms the competitors in style consistency and video quality.

</details>


### [20] [StableDPT: Temporal Stable Monocular Video Depth Estimation](https://arxiv.org/abs/2601.02793)
*Ivan Sobko,Hayko Riemenschneider,Markus Gross,Christopher Schroers*

Main category: cs.CV

TL;DR: 本文提出StableDPT方法，通过添加时间模块将单图像深度估计模型适配到视频处理，提高时间稳定性并减少闪烁伪影


<details>
  <summary>Details</summary>
Motivation: 将单图像深度估计模型直接应用于视频序列会导致显著的时间不稳定性和闪烁伪影，需要专门针对视频处理的解决方案

Method: 基于现成的ViT编码器和增强的DPT头部，在头部添加时间层，使用高效的交叉注意力机制整合整个视频序列中关键帧的信息，并提出处理任意长度视频的推理策略

Result: 在多个基准数据集上评估显示，该方法提高了时间一致性，具有竞争力的最先进性能，并且在真实场景中处理速度提高了2倍以上

Conclusion: StableDPT通过集成时间模块成功将图像深度估计模型适配到视频处理，实现了更准确、时间稳定的深度预测，同时避免了传统重叠窗口方法的尺度不对齐和冗余计算问题

Abstract: Applying single image Monocular Depth Estimation (MDE) models to video sequences introduces significant temporal instability and flickering artifacts. We propose a novel approach that adapts any state-of-the-art image-based (depth) estimation model for video processing by integrating a new temporal module - trainable on a single GPU in a few days. Our architecture StableDPT builds upon an off-the-shelf Vision Transformer (ViT) encoder and enhances the Dense Prediction Transformer (DPT) head. The core of our contribution lies in the temporal layers within the head, which use an efficient cross-attention mechanism to integrate information from keyframes sampled across the entire video sequence. This allows the model to capture global context and inter-frame relationships leading to more accurate and temporally stable depth predictions. Furthermore, we propose a novel inference strategy for processing videos of arbitrary length avoiding the scale misalignment and redundant computations associated with overlapping windows used in other methods. Evaluations on multiple benchmark datasets demonstrate improved temporal consistency, competitive state-of-the-art performance and on top 2x faster processing in real-world scenarios.

</details>


### [21] [Topology-aware Pathological Consistency Matching for Weakly-Paired IHC Virtual Staining](https://arxiv.org/abs/2601.02806)
*Mingzhou Jiang,Jiaying Zhou,Nan Zeng,Mickael Li,Qijie Tang,Chao He,Huazhu Fu,Honghui He*

Main category: cs.CV

TL;DR: 该论文提出了一种拓扑感知的H&E到IHC虚拟染色框架，通过拓扑感知一致性匹配和拓扑约束病理匹配机制，解决相邻切片空间错位问题，实现高质量虚拟染色。


<details>
  <summary>Details</summary>
Motivation: IHC染色在癌症临床诊断中至关重要，但过程复杂、耗时且昂贵，限制了其广泛应用。虚拟染色技术可将H&E图像转换为IHC图像，但使用相邻切片作为ground truth会导致弱配对数据，存在空间错位和局部变形问题，阻碍有效的监督学习。

Method: 提出拓扑感知的虚拟染色框架，包含两个核心机制：1) 拓扑感知一致性匹配(TACM)：利用图对比学习和拓扑扰动学习鲁棒的匹配模式，确保结构一致性；2) 拓扑约束病理匹配(TCPM)：基于节点重要性对齐病理阳性区域，增强病理一致性。

Result: 在两个基准数据集上的四个染色任务中进行广泛实验，结果表明该方法优于现有最先进方法，实现了更高的生成质量和临床相关性。

Conclusion: 提出的拓扑感知框架有效解决了H&E到IHC虚拟染色中的空间错位问题，通过拓扑感知机制实现了高质量、临床相关的虚拟染色，为临床诊断提供了成本效益高的替代方案。

Abstract: Immunohistochemical (IHC) staining provides crucial molecular characterization of tissue samples and plays an indispensable role in the clinical examination and diagnosis of cancers. However, compared with the commonly used Hematoxylin and Eosin (H&E) staining, IHC staining involves complex procedures and is both time-consuming and expensive, which limits its widespread clinical use. Virtual staining converts H&E images to IHC images, offering a cost-effective alternative to clinical IHC staining. Nevertheless, using adjacent slides as ground truth often results in weakly-paired data with spatial misalignment and local deformations, hindering effective supervised learning. To address these challenges, we propose a novel topology-aware framework for H&E-to-IHC virtual staining. Specifically, we introduce a Topology-aware Consistency Matching (TACM) mechanism that employs graph contrastive learning and topological perturbations to learn robust matching patterns despite spatial misalignments, ensuring structural consistency. Furthermore, we propose a Topology-constrained Pathological Matching (TCPM) mechanism that aligns pathological positive regions based on node importance to enhance pathological consistency. Extensive experiments on two benchmarks across four staining tasks demonstrate that our method outperforms state-of-the-art approaches, achieving superior generation quality with higher clinical relevance.

</details>


### [22] [SketchThinker-R1: Towards Efficient Sketch-Style Reasoning in Large Multimodal Models](https://arxiv.org/abs/2601.02825)
*Ruiyang Zhang,Dongzhan Zhou,Zhedong Zheng*

Main category: cs.CV

TL;DR: SketchThinker-R1通过引入草图式推理，在保持准确性的同时将推理token成本降低64%以上，提升多模态模型推理效率


<details>
  <summary>Details</summary>
Motivation: 现有大型多模态模型采用逐步推理方式导致计算开销大（token成本高、响应时间长），而人类采用草图式推理（简洁、目标导向）更高效，受此启发提出新方法

Method: 三阶段方法：1)草图模式冷启动：将标准长推理转换为草图式推理并微调基础模型；2)训练SketchJudge奖励模型：评估推理过程，给草图式推理更高评分；3)草图思维强化学习：在SketchJudge监督下进一步泛化草图式推理能力

Result: 在四个基准测试中，SketchThinker-R1实现推理token成本降低超过64%，同时保持最终答案准确性；定性分析显示草图式推理更关注问题解决中的关键线索

Conclusion: SketchThinker-R1成功将人类草图式推理能力引入多模态模型，显著提升推理效率而不牺牲准确性，为高效多模态推理提供了新方向

Abstract: Despite the empirical success of extensive, step-by-step reasoning in large multimodal models, long reasoning processes inevitably incur substantial computational overhead, i.e., in terms of higher token costs and increased response time, which undermines inference efficiency. In contrast, humans often employ sketch-style reasoning: a concise, goal-directed cognitive process that prioritizes salient information and enables efficient problem-solving. Inspired by this cognitive efficiency, we propose SketchThinker-R1, which incentivizes sketch-style reasoning ability in large multimodal models. Our method consists of three primary stages. In the Sketch-Mode Cold Start stage, we convert standard long reasoning process into sketch-style reasoning and finetune base multimodal model, instilling initial sketch-style reasoning capability. Next, we train SketchJudge Reward Model, which explicitly evaluates thinking process of model and assigns higher scores to sketch-style reasoning. Finally, we conduct Sketch-Thinking Reinforcement Learning under supervision of SketchJudge to further generalize sketch-style reasoning ability. Experimental evaluation on four benchmarks reveals that our SketchThinker-R1 achieves over 64% reduction in reasoning token cost without compromising final answer accuracy. Qualitative analysis further shows that sketch-style reasoning focuses more on key cues during problem solving.

</details>


### [23] [DGA-Net: Enhancing SAM with Depth Prompting and Graph-Anchor Guidance for Camouflaged Object Detection](https://arxiv.org/abs/2601.02831)
*Yuetong Li,Qing Zhang,Yilin Zhao,Gongyang Li,Zeming Liu*

Main category: cs.CV

TL;DR: DGA-Net是一个专门用于伪装目标检测的框架，通过新颖的"深度提示"范式来利用深度线索，在SAM基础上引入跨模态图增强和锚点引导细化模块，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有伪装目标检测方法主要依赖稀疏提示（如点或框），未能充分利用深度线索。为了充分挖掘深度信息在COD中的潜力，需要开发能够构建和传播密集深度提示的新机制。

Method: 提出DGA-Net框架，采用"深度提示"范式：1）跨模态图增强模块（CGE），在异质图中融合RGB语义和深度几何信息形成统一指导信号；2）锚点引导细化模块（AGR），创建全局锚点并通过非局部路径将指导信号从深层传播到浅层，解决特征层次中的信息衰减问题。

Result: 定量和定性实验结果表明，DGA-Net在伪装目标检测任务上超越了现有的最先进方法。

Conclusion: 通过深度提示范式和两个核心模块的设计，DGA-Net能够有效利用深度线索，实现精确一致的伪装目标分割，为COD任务提供了新的解决方案。

Abstract: To fully exploit depth cues in Camouflaged Object Detection (COD), we present DGA-Net, a specialized framework that adapts the Segment Anything Model (SAM) via a novel ``depth prompting" paradigm. Distinguished from existing approaches that primarily rely on sparse prompts (e.g., points or boxes), our method introduces a holistic mechanism for constructing and propagating dense depth prompts. Specifically, we propose a Cross-modal Graph Enhancement (CGE) module that synthesizes RGB semantics and depth geometric within a heterogeneous graph to form a unified guidance signal. Furthermore, we design an Anchor-Guided Refinement (AGR) module. To counteract the inherent information decay in feature hierarchies, AGR forges a global anchor and establishes direct non-local pathways to broadcast this guidance from deep to shallow layers, ensuring precise and consistent segmentation. Quantitative and qualitative experimental results demonstrate that our proposed DGA-Net outperforms the state-of-the-art COD methods.

</details>


### [24] [Breaking Self-Attention Failure: Rethinking Query Initialization for Infrared Small Target Detection](https://arxiv.org/abs/2601.02837)
*Yuteng Liu,Duanni Meng,Maoxun Yuan,Xingxing Wei*

Main category: cs.CV

TL;DR: SEF-DETR是一个针对红外小目标检测的新框架，通过频率引导的补丁筛选、动态嵌入增强和可靠性一致性感知融合三个组件，解决了DETR类方法在红外小目标检测中性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测面临信噪比低、目标尺寸小、背景复杂等挑战。虽然基于DETR的检测器受益于全局上下文建模，但在红外小目标检测中表现出明显的性能下降。研究发现这是由于自注意力机制导致目标相关嵌入被主导的背景特征淹没，造成不可靠的查询初始化和不准确的目标定位。

Method: 提出SEF-DETR框架，包含三个核心组件：1) 频率引导的补丁筛选(FPS)：利用局部补丁的傅里叶频谱构建目标相关密度图，抑制背景主导特征；2) 动态嵌入增强(DEE)：以目标感知方式增强多尺度表示；3) 可靠性一致性感知融合(RCF)：通过强制空间-频率一致性和可靠性进一步细化对象查询。

Result: 在三个公开的红外小目标检测数据集上进行广泛实验，SEF-DETR相比最先进方法实现了优越的检测性能，为红外小目标检测任务提供了鲁棒高效的解决方案。

Conclusion: SEF-DETR通过改进查询初始化机制，有效解决了DETR类方法在红外小目标检测中的性能瓶颈，通过频率分析和多组件协同优化，显著提升了检测准确性和鲁棒性。

Abstract: Infrared small target detection (IRSTD) faces significant challenges due to the low signal-to-noise ratio (SNR), small target size, and complex cluttered backgrounds. Although recent DETR-based detectors benefit from global context modeling, they exhibit notable performance degradation on IRSTD. We revisit this phenomenon and reveal that the target-relevant embeddings of IRST are inevitably overwhelmed by dominant background features due to the self-attention mechanism, leading to unreliable query initialization and inaccurate target localization. To address this issue, we propose SEF-DETR, a novel framework that refines query initialization for IRSTD. Specifically, SEF-DETR consists of three components: Frequency-guided Patch Screening (FPS), Dynamic Embedding Enhancement (DEE), and Reliability-Consistency-aware Fusion (RCF). The FPS module leverages the Fourier spectrum of local patches to construct a target-relevant density map, suppressing background-dominated features. DEE strengthens multi-scale representations in a target-aware manner, while RCF further refines object queries by enforcing spatial-frequency consistency and reliability. Extensive experiments on three public IRSTD datasets demonstrate that SEF-DETR achieves superior detection performance compared to state-of-the-art methods, delivering a robust and efficient solution for infrared small target detection task.

</details>


### [25] [Towards Agnostic and Holistic Universal Image Segmentation with Bit Diffusion](https://arxiv.org/abs/2601.02881)
*Jakob Lønborg Christensen,Morten Rieger Hannemose,Anders Bjorholm Dahl,Vedrana Andersen Dahl*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的通用图像分割框架，通过整体预测方式实现与掩码无关的分割，改进了离散数据处理的扩散模型适配方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像分割方法主要依赖掩码框架，缺乏对分割不确定性的原则性建模能力。本文旨在开发一种不依赖掩码框架的通用分割方法，通过扩散模型实现整体分割预测。

Method: 提出了基于扩散模型的通用分割框架，采用位置感知调色板和2D格雷码排序改进离散数据处理，使用tanh激活函数处理离散数据，优化了sigmoid损失权重和x-prediction预测类型。

Result: 虽然当前模型尚未超越领先的掩码架构，但显著缩小了性能差距，并引入了掩码模型缺乏的原则性模糊建模能力。位置感知调色板和2D格雷码排序提升了性能，sigmoid损失权重在各种预测类型中都表现最佳。

Conclusion: 扩散模型为通用图像分割提供了有前景的替代方案，具备独特的模糊建模能力。结合大规模预训练或可提示条件，该方法有望开发出具有竞争力的分割模型。

Abstract: This paper introduces a diffusion-based framework for universal image segmentation, making agnostic segmentation possible without depending on mask-based frameworks and instead predicting the full segmentation in a holistic manner. We present several key adaptations to diffusion models, which are important in this discrete setting. Notably, we show that a location-aware palette with our 2D gray code ordering improves performance. Adding a final tanh activation function is crucial for discrete data. On optimizing diffusion parameters, the sigmoid loss weighting consistently outperforms alternatives, regardless of the prediction type used, and we settle on x-prediction. While our current model does not yet surpass leading mask-based architectures, it narrows the performance gap and introduces unique capabilities, such as principled ambiguity modeling, that these models lack. All models were trained from scratch, and we believe that combining our proposed improvements with large-scale pretraining or promptable conditioning could lead to competitive models.

</details>


### [26] [TA-Prompting: Enhancing Video Large Language Models for Dense Video Captioning via Temporal Anchors](https://arxiv.org/abs/2601.02908)
*Wei-Yuan Cheng,Kai-Po Chang,Chi-Pin Huang,Fu-En Yang,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: 本文提出TA-Prompting方法，通过时间锚点增强视频大语言模型，解决现有方法在未修剪视频中难以精确定位事件边界的问题，并引入事件连贯性采样策略生成高质量密集视频描述。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在未修剪视频中难以精确定位事件边界，导致生成的描述缺乏准确的时间基础。为了解决这个问题，需要开发能够精确本地化事件并实现时间感知视频事件理解的方法。

Method: 提出TA-Prompting方法：1) 使用时间锚点学习精确定位事件边界；2) 通过时间锚点提示视频大语言模型进行时间感知的视频事件理解；3) 在推理阶段引入事件连贯性采样策略，从任意数量的事件中选择具有足够时间连贯性和跨模态相似性的描述。

Result: 在基准数据集上的广泛实验表明，TA-Prompting方法在密集视频描述、时刻检索和TemporalQA等时间理解任务上优于现有最先进的视频大语言模型，取得了优越的性能。

Conclusion: TA-Prompting通过时间锚点增强了视频大语言模型的事件定位能力，结合事件连贯性采样策略，显著提升了密集视频描述和时间理解任务的性能，为解决视频事件边界精确定位问题提供了有效方案。

Abstract: Dense video captioning aims to interpret and describe all temporally localized events throughout an input video. Recent state-of-the-art methods leverage large language models (LLMs) to provide detailed moment descriptions for video data. However, existing VideoLLMs remain challenging in identifying precise event boundaries in untrimmed videos, causing the generated captions to be not properly grounded. In this paper, we propose TA-Prompting, which enhances VideoLLMs via Temporal Anchors that learn to precisely localize events and prompt the VideoLLMs to perform temporal-aware video event understanding. During inference, in order to properly determine the output caption sequence from an arbitrary number of events presented within a video, we introduce an event coherent sampling strategy to select event captions with sufficient coherence across temporal events and cross-modal similarity with the given video. Through extensive experiments on benchmark datasets, we show that our TA-Prompting is favorable against state-of-the-art VideoLLMs, yielding superior performance on dense video captioning and temporal understanding tasks including moment retrieval and temporalQA.

</details>


### [27] [Zoom-IQA: Image Quality Assessment with Reliable Region-Aware Reasoning](https://arxiv.org/abs/2601.02918)
*Guoqiang Liang,Jianyi Wang,Zhonghua Wu,Shangchen Zhou*

Main category: cs.CV

TL;DR: Zoom-IQA是一个基于视觉语言模型的图像质量评估方法，通过模拟关键认知行为（不确定性感知、区域推理和迭代优化）来提升评估的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有图像质量评估方法要么只预测数值分数而没有解释，要么提供低层次描述但缺乏精确分数。基于推理的视觉语言模型虽然能同时生成质量描述和分数，但由于视觉和文本线索整合能力有限，存在推理不可靠的问题。

Method: 提出Zoom-IQA模型，采用两阶段训练：1）在Grounded-Rationale-IQA数据集上进行监督微调，让模型将评估基于关键区域；2）使用强化学习进行动态策略探索，通过KL-Coverage正则化器防止推理和评分多样性崩溃，并采用渐进重采样策略缓解标注偏差。

Result: 大量实验表明Zoom-IQA在鲁棒性、可解释性和泛化能力方面都有提升。在图像修复等下游任务中的应用进一步证明了其有效性。

Conclusion: Zoom-IQA通过模拟人类认知行为，解决了现有VLM-based IQA方法推理不可靠的问题，在图像质量评估任务中取得了更好的性能。

Abstract: Image Quality Assessment (IQA) is a long-standing problem in computer vision. Previous methods typically focus on predicting numerical scores without explanation or provide low-level descriptions lacking precise scores. Recent reasoning-based vision language models (VLMs) have shown strong potential for IQA, enabling joint generation of quality descriptions and scores. However, we notice that existing VLM-based IQA methods tend to exhibit unreliable reasoning due to their limited capability of integrating visual and textual cues. In this work, we introduce Zoom-IQA, a VLM-based IQA model to explicitly emulate key cognitive behaviors: uncertainty awareness, region reasoning, and iterative refinement. Specifically, we present a two-stage training pipeline: 1) supervised fine-tuning (SFT) on our Grounded-Rationale-IQA (GR-IQA) dataset to teach the model to ground its assessments in key regions; and 2) reinforcement learning (RL) for dynamic policy exploration, primarily stabilized by our KL-Coverage regularizer to prevent reasoning and scoring diversity collapse, and supported by a Progressive Re-sampling Strategy to mitigate annotation bias. Extensive experiments show that Zoom-IQA achieves improved robustness, explainability, and generalization. The application to downstream tasks, such as image restoration, further demonstrates the effectiveness of Zoom-IQA.

</details>


### [28] [DCG ReID: Disentangling Collaboration and Guidance Fusion Representations for Multi-modal Vehicle Re-Identification](https://arxiv.org/abs/2601.02924)
*Aihua Zheng,Ya Gao,Shihao Li,Chenglong Li,Jin Tang*

Main category: cs.CV

TL;DR: DCG-ReID提出了一种解耦协作与引导融合表示方法，通过动态置信度解耦权重机制和两种场景特定融合策略，解决多模态车辆重识别中平衡与不平衡质量分布数据的冲突融合需求。


<details>
  <summary>Details</summary>
Motivation: 多模态车辆重识别面临模态质量分布不确定性的挑战，由于模态间固有差异导致平衡和不平衡质量分布数据具有不同的融合需求。现有方法使用单一融合模型处理所有多模态数据，忽视了两种数据类型的差异需求，难以解耦类内一致性和模态间异质性之间的冲突。

Method: 提出DCG-ReID方法：1) 设计动态置信度解耦权重机制，通过交互衍生的模态置信度动态重新加权三模态贡献，构建解耦融合框架；2) 开发两种场景特定融合策略：针对平衡质量分布的协作融合模块挖掘成对共识特征，针对不平衡分布的引导融合模块实现模态判别差异的差异化放大。

Result: 在三个多模态重识别基准数据集（WMVeID863、MSVR310、RGBNT100）上的大量实验验证了该方法的有效性。

Conclusion: DCG-ReID通过解耦协作与引导融合表示，有效解决了多模态车辆重识别中平衡与不平衡质量分布数据的冲突融合需求，提升了多模态联合决策性能。

Abstract: Multi-modal vehicle Re-Identification (ReID) aims to leverage complementary information from RGB, Near Infrared (NIR), and Thermal Infrared (TIR) modalities to retrieve the same vehicle. The challenges of multi-modal vehicle ReID arise from the uncertainty of modality quality distribution induced by inherent discrepancies across modalities, resulting in distinct conflicting fusion requirements for data with balanced and unbalanced quality distributions. Existing methods handle all multi-modal data within a single fusion model, overlooking the different needs of the two data types and making it difficult to decouple the conflict between intra-class consistency and inter-modal heterogeneity. To this end, we propose Disentangle Collaboration and Guidance Fusion Representations for Multi-modal Vehicle ReID (DCG-ReID). Specifically, to disentangle heterogeneous quality-distributed modal data without mutual interference, we first design the Dynamic Confidence-based Disentangling Weighting (DCDW) mechanism: dynamically reweighting three-modal contributions via interaction-derived modal confidence to build a disentangled fusion framework. Building on DCDW, we develop two scenario-specific fusion strategies: (1) for balanced quality distributions, Collaboration Fusion Module (CFM) mines pairwise consensus features to capture shared discriminative information and boost intra-class consistency; (2) for unbalanced distributions, Guidance Fusion Module (GFM) implements differential amplification of modal discriminative disparities to reinforce dominant modality advantages, guide auxiliary modalities to mine complementary discriminative info, and mitigate inter-modal divergence to boost multi-modal joint decision performance. Extensive experiments on three multi-modal ReID benchmarks (WMVeID863, MSVR310, RGBNT100) validate the effectiveness of our method. Code will be released upon acceptance.

</details>


### [29] [PrismVAU: Prompt-Refined Inference System for Multimodal Video Anomaly Understanding](https://arxiv.org/abs/2601.02927)
*Iñaki Erregue,Kamal Nasrollahi,Sergio Escalera*

Main category: cs.CV

TL;DR: PrismVAU是一个轻量级实时视频异常理解系统，使用单一现成MLLM进行异常评分、解释和提示优化，无需微调或外部模块


<details>
  <summary>Details</summary>
Motivation: 现有VAU方法依赖微调的多模态大语言模型或外部模块（如视频字幕生成器），导致昂贵的标注、复杂的训练流程和高推理开销，需要更轻量高效的解决方案

Method: 采用两阶段互补架构：1) 粗粒度异常评分模块通过文本锚点相似性计算帧级异常分数；2) MLLM精炼模块通过系统和用户提示对异常进行上下文理解。文本锚点和提示通过弱监督自动提示工程框架优化

Result: 在标准VAD基准测试中，PrismVAU实现了有竞争力的检测性能并提供可解释的异常解释，无需指令微调、帧级标注、外部模块或密集处理

Conclusion: PrismVAU是一个高效实用的实时视频异常理解解决方案，通过单一现成MLLM实现异常检测和解释，降低了计算成本和标注需求

Abstract: Video Anomaly Understanding (VAU) extends traditional Video Anomaly Detection (VAD) by not only localizing anomalies but also describing and reasoning about their context. Existing VAU approaches often rely on fine-tuned multimodal large language models (MLLMs) or external modules such as video captioners, which introduce costly annotations, complex training pipelines, and high inference overhead. In this work, we introduce PrismVAU, a lightweight yet effective system for real-time VAU that leverages a single off-the-shelf MLLM for anomaly scoring, explanation, and prompt optimization. PrismVAU operates in two complementary stages: (1) a coarse anomaly scoring module that computes frame-level anomaly scores via similarity to textual anchors, and (2) an MLLM-based refinement module that contextualizes anomalies through system and user prompts. Both textual anchors and prompts are optimized with a weakly supervised Automatic Prompt Engineering (APE) framework. Extensive experiments on standard VAD benchmarks demonstrate that PrismVAU delivers competitive detection performance and interpretable anomaly explanations -- without relying on instruction tuning, frame-level annotations, and external modules or dense processing -- making it an efficient and practical solution for real-world applications.

</details>


### [30] [HybridSolarNet: A Lightweight and Explainable EfficientNet-CBAM Architecture for Real-Time Solar Panel Fault Detection](https://arxiv.org/abs/2601.02928)
*Md. Asif Hossain,G M Mota-Tahrin Tayef,Nabil Subhan*

Main category: cs.CV

TL;DR: 提出HybridSolarNet模型，结合EfficientNet-B0和CBAM注意力模块，用于无人机太阳能板故障检测，在保持轻量化的同时达到92.37%准确率，适合边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 太阳能板人工检测成本高、易出错，无人机监测需求迫切。现有深度学习方法要么模型过大不适合边缘计算，要么因无效学习技术导致准确率估计偏差。

Method: 提出HybridSolarNet模型，集成EfficientNet-B0和CBAM注意力模块。采用分割后增强策略避免数据泄露，引入焦点损失和余弦退火。在Kaggle太阳能板图像数据集上进行5折分层交叉验证。

Result: 平均准确率达到92.37%±0.41，F1分数0.9226±0.39，存储仅需16.3MB（比VGG19小32倍），GPU推理速度54.9FPS。CBAM提升准确率1.53%，焦点损失有效处理类别不平衡。

Conclusion: HybridSolarNet在保持轻量化的同时实现了高精度太阳能板故障检测，适合实时无人机部署。Grad-CAM可视化显示模型能聚焦实际故障区域而非无关区域。

Abstract: Manual inspections for solar panel systems are a tedious, costly, and error-prone task, making it desirable for Unmanned Aerial Vehicle (UAV) based monitoring. Though deep learning models have excellent fault detection capabilities, almost all methods either are too large and heavy for edge computing devices or involve biased estimation of accuracy due to ineffective learning techniques. We propose a new solar panel fault detection model called HybridSolarNet. It integrates EfficientNet-B0 with Convolutional Block Attention Module (CBAM). We implemented it on the Kaggle Solar Panel Images competition dataset with a tight split-before-augmentation protocol. It avoids leakage in accuracy estimation. We introduced focal loss and cosine annealing. Ablation analysis validates that accuracy boosts due to added benefits from CBAM (+1.53%) and that there are benefits from recognition of classes with imbalanced samples via focal loss. Overall average accuracy on 5-fold stratified cross-validation experiments on the given competition dataset topped 92.37% +/- 0.41 and an F1-score of 0.9226 +/- 0.39 compared to baselines like VGG19, requiring merely 16.3 MB storage, i.e., 32 times less. Its inference speed measured at 54.9 FPS with GPU support makes it a successful candidate for real-time UAV implementation. Moreover, visualization obtained from Grad-CAM illustrates that HybridSolarNet focuses on actual locations instead of irrelevant ones.

</details>


### [31] [VTONQA: A Multi-Dimensional Quality Assessment Dataset for Virtual Try-on](https://arxiv.org/abs/2601.02945)
*Xinyi Wei,Sijing Wu,Zitong Xu,Yunhao Li,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 该论文提出了VTONQA——首个专门为虚拟试穿(VTON)设计的多维质量评估数据集，包含8,132张图像和24,396个主观评分，用于评估VTON生成图像的质量。


<details>
  <summary>Details</summary>
Motivation: 随着电子商务和数字时尚的快速发展，基于图像的虚拟试穿(VTON)越来越受关注。然而，现有VTON模型经常出现服装变形和身体不一致等伪影，迫切需要可靠的VTON生成图像质量评估方法。

Method: 构建了VTONQA数据集，包含8,132张由11个代表性VTON模型生成的图像，以及24,396个跨三个评估维度（服装贴合度、身体兼容性和整体质量）的平均意见分数(MOSs)。基于该数据集，对VTON模型和多种图像质量评估(IQA)指标进行了基准测试。

Result: 揭示了现有方法的局限性，展示了所提出数据集的价值。VTONQA数据集和相应的基准测试为感知对齐评估提供了坚实基础。

Conclusion: VTONQA数据集和基准测试将有助于质量评估方法的发展和VTON模型的进步，为感知对齐评估提供可靠基础。

Abstract: With the rapid development of e-commerce and digital fashion, image-based virtual try-on (VTON) has attracted increasing attention. However, existing VTON models often suffer from artifacts such as garment distortion and body inconsistency, highlighting the need for reliable quality evaluation of VTON-generated images. To this end, we construct VTONQA, the first multi-dimensional quality assessment dataset specifically designed for VTON, which contains 8,132 images generated by 11 representative VTON models, along with 24,396 mean opinion scores (MOSs) across three evaluation dimensions (i.e., clothing fit, body compatibility, and overall quality). Based on VTONQA, we benchmark both VTON models and a diverse set of image quality assessment (IQA) metrics, revealing the limitations of existing methods and highlighting the value of the proposed dataset. We believe that the VTONQA dataset and corresponding benchmarks will provide a solid foundation for perceptually aligned evaluation, benefiting both the development of quality assessment methods and the advancement of VTON models.

</details>


### [32] [LAMS-Edit: Latent and Attention Mixing with Schedulers for Improved Content Preservation in Diffusion-Based Image and Style Editing](https://arxiv.org/abs/2601.02987)
*Wingwa Fu,Takayuki Okatani*

Main category: cs.CV

TL;DR: LAMS-Edit是一个基于扩散模型的文本到图像编辑框架，通过混合反转过程中的潜在表示和注意力图，在内容保留和编辑应用之间取得平衡，支持区域掩码精确编辑和LoRA风格迁移。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的文本到图像编辑面临两个主要挑战：1）如何在保持原始内容的同时有效应用编辑；2）如何处理真实图像的编辑。这些挑战限制了编辑的精确性和实用性。

Method: 提出LAMS-Edit框架，利用反转过程中的中间状态（潜在表示和注意力图），在编辑图像生成时通过加权插值混合这些状态，使用调度器控制混合比例。该方法与Prompt-to-Prompt（P2P）结合，支持区域掩码精确编辑和LoRA风格迁移。

Result: 大量实验表明，LAMS-Edit能够有效平衡内容保留和编辑应用，在文本到图像编辑任务中表现出色，特别是在真实图像编辑方面具有优势。

Conclusion: LAMS-Edit通过利用反转过程的中间状态，提供了一个可扩展的框架，能够有效解决扩散模型在文本到图像编辑中的内容保留与编辑应用平衡问题，支持精确编辑和风格迁移。

Abstract: Text-to-Image editing using diffusion models faces challenges in balancing content preservation with edit application and handling real-image editing. To address these, we propose LAMS-Edit, leveraging intermediate states from the inversion process--an essential step in real-image editing--during edited image generation. Specifically, latent representations and attention maps from both processes are combined at each step using weighted interpolation, controlled by a scheduler. This technique, Latent and Attention Mixing with Schedulers (LAMS), integrates with Prompt-to-Prompt (P2P) to form LAMS-Edit--an extensible framework that supports precise editing with region masks and enables style transfer via LoRA. Extensive experiments demonstrate that LAMS-Edit effectively balances content preservation and edit application.

</details>


### [33] [ULS+: Data-driven Model Adaptation Enhances Lesion Segmentation](https://arxiv.org/abs/2601.02988)
*Rianne Weber,Niels Rocholl,Max de Grauw,Mathias Prokop,Ewoud Smit,Alessa Hering*

Main category: cs.CV

TL;DR: ULS+是通用病灶分割模型的增强版本，通过整合新数据集和减小输入图像尺寸，在CT扫描中实现了更高的病灶分割精度和更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 原始ULS模型在CT扫描中基于点击点进行全身病灶分割，但自发布以来出现了多个新的公共数据集，这些数据集可以进一步提升模型性能。

Method: ULS+整合了新增的公共数据集，并采用了更小的输入图像尺寸，通过数据驱动的更新和临床验证循环来改进模型。

Result: 在ULS23挑战赛测试数据和Longitudinal-CT数据集子集上，ULS+在Dice分数和点击点位置鲁棒性方面均显著优于原始ULS模型，并在ULS23挑战赛测试阶段排行榜上排名第一。

Conclusion: ULS+通过持续的数据驱动更新和临床验证，为构建鲁棒且临床相关的病灶分割模型奠定了基础。

Abstract: In this study, we present ULS+, an enhanced version of the Universal Lesion Segmentation (ULS) model. The original ULS model segments lesions across the whole body in CT scans given volumes of interest (VOIs) centered around a click-point. Since its release, several new public datasets have become available that can further improve model performance. ULS+ incorporates these additional datasets and uses smaller input image sizes, resulting in higher accuracy and faster inference.
  We compared ULS and ULS+ using the Dice score and robustness to click-point location on the ULS23 Challenge test data and a subset of the Longitudinal-CT dataset. In all comparisons, ULS+ significantly outperformed ULS. Additionally, ULS+ ranks first on the ULS23 Challenge test-phase leaderboard. By maintaining a cycle of data-driven updates and clinical validation, ULS+ establishes a foundation for robust and clinically relevant lesion segmentation models.

</details>


### [34] [Towards Faithful Reasoning in Comics for Small MLLMs](https://arxiv.org/abs/2601.02991)
*Chengcheng Feng,Haojie Yin,Yucheng Jin,Kaizhu Huang*

Main category: cs.CV

TL;DR: 该论文针对漫画视觉问答(CVQA)任务，提出了一种新的推理框架，解决了传统思维链(CoT)提示在CVQA中性能下降的问题，特别是在小规模多模态大语言模型中。


<details>
  <summary>Details</summary>
Motivation: 漫画视觉问答(CVQA)对多模态大语言模型(MLLMs)提出了独特挑战，因为它依赖于符号抽象、叙事逻辑和幽默，与传统VQA任务不同。虽然思维链(CoT)提示被广泛用于增强MLLM推理能力，但直接应用于CVQA时性能反而下降，特别是在小规模模型中。

Method: 提出了一种新颖的漫画推理框架，结合模块化CoT生成、基于GRPO的强化微调以及新颖的结构化奖励机制，旨在为小型MLLMs生成更忠实和可迁移的推理链。

Result: 在五个具有挑战性的基准测试中，提出的3B模型优于最先进的方法，插件实验在不同MLLMs上带来了平均12.1%的额外改进。

Conclusion: 该研究不仅解决了CVQA中CoT的性能问题，还将方法扩展到更广泛的幽默中心和抽象视觉推理任务，包括表情包理解和社论漫画解读，为小型MLLMs在复杂视觉推理任务中的应用提供了有效解决方案。

Abstract: Comic-based visual question answering (CVQA) poses distinct challenges to multimodal large language models (MLLMs) due to its reliance on symbolic abstraction, narrative logic, and humor, which differ from conventional VQA tasks. Although Chain-of-Thought (CoT) prompting is widely used to enhance MLLM reasoning, surprisingly, its direct application to CVQA often degrades performance, especially in small-scale models. Our theoretical and empirical analyses reveal that standard CoT in CVQA suffers from state entanglement, spurious transitions, and exploration inefficiency, with small models particularly vulnerable in resource-constrained settings. To address these issues, we propose a novel comic reasoning framework, designed to produce more faithful and transferable reasoning chains in small MLLMs. Specifically, our framework combines modular CoT generation with GRPO-based reinforcement fine-tuning and a novel structured reward. Beyond comic VQA, we further evaluate our approach on a broader class of humor-centric and abstract visual reasoning tasks, including meme understanding and editorial cartoon interpretation. Across five challenging benchmarks, our 3B model outperforms state-of-the-art methods, and plug-in experiments yield an additional average improvement of $\mathbf{12.1\%}$ across different MLLMs.

</details>


### [35] [Towards Efficient 3D Object Detection for Vehicle-Infrastructure Collaboration via Risk-Intent Selection](https://arxiv.org/abs/2601.03001)
*Li Wang,Boqi Li,Hang Chen,Xingjian Wu,Yichen Wang,Jiewen Tan,Xinyu Zhang,Huaping Liu*

Main category: cs.CV

TL;DR: RiSe框架通过风险意图选择性检测，将VICP从识别可见区域转向优先处理风险关键区域，在保持检测精度的同时将通信量降至完整特征共享的0.71%


<details>
  <summary>Details</summary>
Motivation: 车辆-基础设施协同感知在自动驾驶中至关重要，但通信带宽与特征冗余之间的权衡是关键瓶颈。现有方法依赖空间压缩或静态置信度图，会低效传输非关键背景区域的空间冗余特征

Method: 提出Risk-intent Selective detection (RiSe)框架，包含：1) 基于势场理论的潜在场-轨迹相关模型(PTCM)定量评估运动学风险；2) 利用自车运动先验的意图驱动区域预测模块(IDAPM)主动预测和过滤关键BEV区域；3) 语义选择性融合方案，仅从高交互区域传输高保真特征

Result: 在DeepAccident数据集上的实验表明，该方法将通信量降至完整特征共享的0.71%，同时保持最先进的检测精度，在带宽效率和感知性能之间建立了有竞争力的帕累托前沿

Conclusion: RiSe通过从识别可见区域转向优先处理风险关键区域的范式转变，实现了车辆-基础设施协同感知中通信带宽与感知性能的有效平衡，为实际部署提供了可行方案

Abstract: Vehicle-Infrastructure Collaborative Perception (VICP) is pivotal for resolving occlusion in autonomous driving, yet the trade-off between communication bandwidth and feature redundancy remains a critical bottleneck. While intermediate fusion mitigates data volume compared to raw sharing, existing frameworks typically rely on spatial compression or static confidence maps, which inefficiently transmit spatially redundant features from non-critical background regions. To address this, we propose Risk-intent Selective detection (RiSe), an interaction-aware framework that shifts the paradigm from identifying visible regions to prioritizing risk-critical ones. Specifically, we introduce a Potential Field-Trajectory Correlation Model (PTCM) grounded in potential field theory to quantitatively assess kinematic risks. Complementing this, an Intention-Driven Area Prediction Module (IDAPM) leverages ego-motion priors to proactively predict and filter key Bird's-Eye-View (BEV) areas essential for decision-making. By integrating these components, RiSe implements a semantic-selective fusion scheme that transmits high-fidelity features only from high-interaction regions, effectively acting as a feature denoiser. Extensive experiments on the DeepAccident dataset demonstrate that our method reduces communication volume to 0.71\% of full feature sharing while maintaining state-of-the-art detection accuracy, establishing a competitive Pareto frontier between bandwidth efficiency and perception performance.

</details>


### [36] [SA-ResGS: Self-Augmented Residual 3D Gaussian Splatting for Next Best View Selection](https://arxiv.org/abs/2601.03024)
*Kim Jun-Seong,Tae-Hyun Oh,Eduardo Pérez-Pellitero,Youngkyoon Jang*

Main category: cs.CV

TL;DR: SA-ResGS是一种用于主动场景重建中下一最佳视角选择的新框架，通过自增强点云和残差学习策略，提升不确定性量化的稳定性和监督效果。


<details>
  <summary>Details</summary>
Motivation: 解决主动场景重建中下一最佳视角选择时的不确定性量化不稳定问题，以及稀疏宽基线视角下高斯模型监督不足的挑战。

Method: 1. 通过训练视图和光栅化外推视图之间的三角测量生成自增强点云（SA-Points），实现高效场景覆盖估计；2. 针对3D高斯溅射引入首个残差学习策略，结合不确定性驱动过滤和dropout/硬负样本采样，增强高不确定性高斯的梯度流。

Result: 在主动视角选择实验中，SA-ResGS在重建质量和视角选择鲁棒性方面均优于最先进的基线方法。

Conclusion: SA-ResGS通过物理基础的视角选择策略和不确定性感知的残差监督方案，有效解决了宽基线探索和稀疏视图模糊性在NBV规划中的冲突效应，提升了不确定性量化的稳定性和场景重建质量。

Abstract: We propose Self-Augmented Residual 3D Gaussian Splatting (SA-ResGS), a novel framework to stabilize uncertainty quantification and enhancing uncertainty-aware supervision in next-best-view (NBV) selection for active scene reconstruction. SA-ResGS improves both the reliability of uncertainty estimates and their effectiveness for supervision by generating Self-Augmented point clouds (SA-Points) via triangulation between a training view and a rasterized extrapolated view, enabling efficient scene coverage estimation. While improving scene coverage through physically guided view selection, SA-ResGS also addresses the challenge of under-supervised Gaussians, exacerbated by sparse and wide-baseline views, by introducing the first residual learning strategy tailored for 3D Gaussian Splatting. This targeted supervision enhances gradient flow in high-uncertainty Gaussians by combining uncertainty-driven filtering with dropout- and hard-negative-mining-inspired sampling. Our contributions are threefold: (1) a physically grounded view selection strategy that promotes efficient and uniform scene coverage; (2) an uncertainty-aware residual supervision scheme that amplifies learning signals for weakly contributing Gaussians, improving training stability and uncertainty estimation across scenes with diverse camera distributions; (3) an implicit unbiasing of uncertainty quantification as a consequence of constrained view selection and residual supervision, which together mitigate conflicting effects of wide-baseline exploration and sparse-view ambiguity in NBV planning. Experiments on active view selection demonstrate that SA-ResGS outperforms state-of-the-art baselines in both reconstruction quality and view selection robustness.

</details>


### [37] [Motion Blur Robust Wheat Pest Damage Detection with Dynamic Fuzzy Feature Fusion](https://arxiv.org/abs/2601.03046)
*Han Zhang,Yanwei Wang,Fang Li,Hongjun Wang*

Main category: cs.CV

TL;DR: DFRCP是一种动态模糊鲁棒卷积金字塔，作为YOLOv11的插件升级，用于运动模糊条件下的目标检测。它通过结合多尺度特征和引入动态鲁棒切换单元来增强特征金字塔，在边缘设备上实现高效的模糊鲁棒检测。


<details>
  <summary>Details</summary>
Motivation: 相机抖动引起的运动模糊会产生重影伪影，严重降低边缘设备上的目标检测性能。现有方法要么将模糊视为噪声而丢失判别性结构，要么应用全图像恢复增加延迟，限制了在资源受限设备上的部署。

Method: 提出DFRCP作为YOLOv11的插件升级，通过结合大尺度和中尺度特征并保留原生表示来增强特征金字塔。引入动态鲁棒切换单元，自适应地注入模糊特征以增强抖动下的全局感知。模糊特征通过旋转和非线性插值多尺度特征合成，然后通过透明度卷积合并，学习原始特征和模糊特征之间的内容自适应权衡。开发了CUDA并行旋转和插值内核，避免边界溢出并提供400倍以上的加速。

Result: 在约3,500张图像的私有小麦害虫损害数据集上进行训练，使用两种模糊机制进行三倍增强：均匀图像宽运动模糊和边界框限制的旋转模糊。在模糊测试集上，配备DFRCP的YOLOv11比YOLOv11基线准确率提高约10.4%，仅增加适度的训练时间开销。

Conclusion: DFRCP有效解决了运动模糊对目标检测的影响，在保持边缘设备部署可行性的同时显著提升检测精度，减少了数据收集后手动筛选的需求。

Abstract: Motion blur caused by camera shake produces ghosting artifacts that substantially degrade edge side object detection. Existing approaches either suppress blur as noise and lose discriminative structure, or apply full image restoration that increases latency and limits deployment on resource constrained devices. We propose DFRCP, a Dynamic Fuzzy Robust Convolutional Pyramid, as a plug in upgrade to YOLOv11 for blur robust detection. DFRCP enhances the YOLOv11 feature pyramid by combining large scale and medium scale features while preserving native representations, and by introducing Dynamic Robust Switch units that adaptively inject fuzzy features to strengthen global perception under jitter. Fuzzy features are synthesized by rotating and nonlinearly interpolating multiscale features, then merged through a transparency convolution that learns a content adaptive trade off between original and fuzzy cues. We further develop a CUDA parallel rotation and interpolation kernel that avoids boundary overflow and delivers more than 400 times speedup, making the design practical for edge deployment. We train with paired supervision on a private wheat pest damage dataset of about 3,500 images, augmented threefold using two blur regimes, uniform image wide motion blur and bounding box confined rotational blur. On blurred test sets, YOLOv11 with DFRCP achieves about 10.4 percent higher accuracy than the YOLOv11 baseline with only a modest training time overhead, reducing the need for manual filtering after data collection.

</details>


### [38] [On the Intrinsic Limits of Transformer Image Embeddings in Non-Solvable Spatial Reasoning](https://arxiv.org/abs/2601.03048)
*Siyi Lyu,Quan Liu,Feng Yan*

Main category: cs.CV

TL;DR: ViT在空间推理任务（如心理旋转）上存在系统性失败，作者认为这不是数据规模问题，而是架构内在电路复杂度的限制。他们从计算复杂度理论证明，对于非可解群（如3D旋转群），保持结构保持嵌入需要NC^1复杂度，而恒定深度ViT仅能达到TC^0复杂度，存在根本性能力边界。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在语义识别方面表现出色，但在空间推理任务（如心理旋转）上存在系统性失败。传统观点常将此归因于数据规模不足，但作者认为这源于架构内在的电路复杂度限制。

Method: 将空间理解形式化为学习群同态：将图像序列映射到保持底层变换群代数结构的潜在空间。通过计算复杂度理论分析，证明对于非可解群（如SO(3)），保持结构保持嵌入的计算复杂度下界为NC^1-完全，而恒定深度ViT的计算能力严格受限于TC^0。

Result: 在TC^0 ⊊ NC^1的假设下，建立了复杂度边界：恒定深度ViT从根本上缺乏有效捕捉非可解空间结构所需的逻辑深度。通过潜在空间探测验证了这一复杂度差距，显示随着组合深度增加，ViT表示在非可解任务上出现结构崩溃。

Conclusion: ViT在空间推理任务上的局限性不是数据问题，而是架构固有的计算复杂度限制。恒定深度ViT无法有效处理非可解群的空间结构，这为设计更强大的空间推理模型提供了理论指导。

Abstract: Vision Transformers (ViTs) excel in semantic recognition but exhibit systematic failures in spatial reasoning tasks such as mental rotation. While often attributed to data scale, we propose that this limitation arises from the intrinsic circuit complexity of the architecture. We formalize spatial understanding as learning a Group Homomorphism: mapping image sequences to a latent space that preserves the algebraic structure of the underlying transformation group. We demonstrate that for non-solvable groups (e.g., the 3D rotation group $\mathrm{SO}(3)$), maintaining such a structure-preserving embedding is computationally lower-bounded by the Word Problem, which is $\mathsf{NC^1}$-complete. In contrast, we prove that constant-depth ViTs with polynomial precision are strictly bounded by $\mathsf{TC^0}$. Under the conjecture $\mathsf{TC^0} \subsetneq \mathsf{NC^1}$, we establish a complexity boundary: constant-depth ViTs fundamentally lack the logical depth to efficiently capture non-solvable spatial structures. We validate this complexity gap via latent-space probing, demonstrating that ViT representations suffer a structural collapse on non-solvable tasks as compositional depth increases.

</details>


### [39] [Fine-Grained Generalization via Structuralizing Concept and Feature Space into Commonality, Specificity and Confounding](https://arxiv.org/abs/2601.03056)
*Zhen Wang,Jiaojiao Zhao,Qilong Wang,Yongfeng Dong,Wenlong Yu*

Main category: cs.CV

TL;DR: CFSG模型通过将概念和特征空间显式解耦为共同、特定和混杂三个结构化组件，并引入自适应机制动态调整各组件比例，有效解决了细粒度域泛化中模型对细微线索过度敏感的问题，在三个单源基准数据集上平均性能提升9.87%。


<details>
  <summary>Details</summary>
Motivation: 细粒度域泛化比传统域泛化更具挑战性，因为细粒度识别任务中存在微妙的类间差异和相对明显的类内变化。在域偏移下，模型对细粒度线索变得过度敏感，导致关键特征被抑制，性能显著下降。认知研究表明，人类通过利用共同和特定属性来分类对象，但当前深度学习模型尚未有效融入这一机制。

Method: 提出概念-特征结构化泛化（CFSG）模型，将概念和特征空间显式解耦为三个结构化组件：共同、特定和混杂部分。引入自适应机制动态调整各组件比例以减轻不同程度分布偏移的负面影响。在最终预测中，为每对组件分配显式权重。

Result: 在三个单源基准数据集上的广泛实验表明，CFSG相比基线模型平均性能提升9.87%，优于现有最先进方法平均3.08%。可解释性分析验证了CFSG有效整合了多粒度结构化知识，并证实特征结构化促进了概念结构化的出现。

Conclusion: CFSG模型通过模仿人类认知机制，将概念和特征空间结构化解耦，并引入自适应调整机制，有效解决了细粒度域泛化中的挑战，显著提升了模型性能，为细粒度识别任务提供了新的解决方案。

Abstract: Fine-Grained Domain Generalization (FGDG) presents greater challenges than conventional domain generalization due to the subtle inter-class differences and relatively pronounced intra-class variations inherent in fine-grained recognition tasks. Under domain shifts, the model becomes overly sensitive to fine-grained cues, leading to the suppression of critical features and a significant drop in performance. Cognitive studies suggest that humans classify objects by leveraging both common and specific attributes, enabling accurate differentiation between fine-grained categories. However, current deep learning models have yet to incorporate this mechanism effectively. Inspired by this mechanism, we propose Concept-Feature Structuralized Generalization (CFSG). This model explicitly disentangles both the concept and feature spaces into three structured components: common, specific, and confounding segments. To mitigate the adverse effects of varying degrees of distribution shift, we introduce an adaptive mechanism that dynamically adjusts the proportions of common, specific, and confounding components. In the final prediction, explicit weights are assigned to each pair of components. Extensive experiments on three single-source benchmark datasets demonstrate that CFSG achieves an average performance improvement of 9.87% over baseline models and outperforms existing state-of-the-art methods by an average of 3.08%. Additionally, explainability analysis validates that CFSG effectively integrates multi-granularity structured knowledge and confirms that feature structuralization facilitates the emergence of concept structuralization.

</details>


### [40] [Understanding Multi-Agent Reasoning with Large Language Models for Cartoon VQA](https://arxiv.org/abs/2601.03073)
*Tong Wu,Thanet Markchom*

Main category: cs.CV

TL;DR: 该论文提出了一个专门用于卡通图像视觉问答的多智能体LLM框架，通过视觉、语言和批评三个智能体的协作来解决卡通图像中视觉抽象和叙事上下文理解的问题。


<details>
  <summary>Details</summary>
Motivation: 标准的大型语言模型在自然图像上训练，难以处理卡通图像中夸张的视觉抽象和叙事驱动的上下文，这限制了卡通视觉问答的性能。

Method: 提出一个多智能体LLM框架，包含三个专门化智能体：视觉智能体（处理视觉特征）、语言智能体（处理语言理解）和批评智能体（评估和整合信息），它们协作进行结构化推理。

Result: 在Pororo和Simpsons两个卡通VQA数据集上进行了系统评估，实验结果表明该框架有效，并详细分析了每个智能体对最终预测的贡献。

Conclusion: 该多智能体框架为卡通VQA任务提供了有效的解决方案，并深入揭示了LLM基多智能体在卡通视觉问答和多模态推理中的行为机制。

Abstract: Visual Question Answering (VQA) for stylised cartoon imagery presents challenges, such as interpreting exaggerated visual abstraction and narrative-driven context, which are not adequately addressed by standard large language models (LLMs) trained on natural images. To investigate this issue, a multi-agent LLM framework is introduced, specifically designed for VQA tasks in cartoon imagery. The proposed architecture consists of three specialised agents: visual agent, language agent and critic agent, which work collaboratively to support structured reasoning by integrating visual cues and narrative context. The framework was systematically evaluated on two cartoon-based VQA datasets: Pororo and Simpsons. Experimental results provide a detailed analysis of how each agent contributes to the final prediction, offering a deeper understanding of LLM-based multi-agent behaviour in cartoon VQA and multimodal inference.

</details>


### [41] [LesionTABE: Equitable AI for Skin Lesion Detection](https://arxiv.org/abs/2601.03090)
*Rocio Mexia Diaz,Yasmin Greenway,Petru Manescu*

Main category: cs.CV

TL;DR: LesionTABE框架结合对抗性去偏和皮肤病学基础模型嵌入，在皮肤病变诊断中显著提升公平性指标超过25%，同时提高整体诊断准确率。


<details>
  <summary>Details</summary>
Motivation: AI在皮肤病学临床应用中面临的主要障碍是偏见问题，特别是在深色肤色上诊断模型表现不佳，这阻碍了AI的公平临床采用。

Method: 提出LesionTABE框架，结合对抗性去偏技术和皮肤病学特定的基础模型嵌入，通过对抗训练减少肤色相关的偏见。

Result: 在涵盖恶性和炎症性病变的多个数据集上评估，相比ResNet-152基线，公平性指标提升超过25%，优于现有去偏方法，同时提高整体诊断准确率。

Conclusion: 基础模型去偏是实现公平临床AI应用的重要一步，LesionTABE框架展示了在皮肤病学中减少偏见同时保持诊断性能的潜力。

Abstract: Bias remains a major barrier to the clinical adoption of AI in dermatology, as diagnostic models underperform on darker skin tones. We present LesionTABE, a fairness-centric framework that couples adversarial debiasing with dermatology-specific foundation model embeddings. Evaluated across multiple datasets covering both malignant and inflammatory conditions, LesionTABE achieves over a 25\% improvement in fairness metrics compared to a ResNet-152 baseline, outperforming existing debiasing methods while simultaneously enhancing overall diagnostic accuracy. These results highlight the potential of foundation model debiasing as a step towards equitable clinical AI adoption.

</details>


### [42] [Text-Guided Layer Fusion Mitigates Hallucination in Multimodal LLMs](https://arxiv.org/abs/2601.03100)
*Chenchen Lin,Sanbao Su,Rachel Luo,Yuxiao Chen,Yan Wang,Marco Pavone,Fei Miao*

Main category: cs.CV

TL;DR: TGIF是一种轻量级模块，通过文本引导的跨层融合，动态组合视觉编码器的多层特征来减少MLLM的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型主要依赖视觉编码器的单一高层特征，未能充分利用编码器丰富的视觉层次信息，导致模型容易产生视觉未接地的幻觉，过度依赖语言先验而非图像证据

Method: 提出TGIF（文本引导跨层融合）模块，将视觉编码器的各层视为深度方向的"专家"，根据查询提示动态预测视觉特征的融合权重，采用直接外部融合原则，无需更新视觉编码器，计算开销小

Result: 在LLaVA-1.5-7B中集成TGIF后，在幻觉检测、OCR和VQA基准测试上获得一致改进，同时在ScienceQA、GQA和MMBench上保持或提升性能

Conclusion: 查询条件化、层次感知的特征融合是增强现代MLLM视觉接地性和减少幻觉的有效方法

Abstract: Multimodal large language models (MLLMs) typically rely on a single late-layer feature from a frozen vision encoder, leaving the encoder's rich hierarchy of visual cues under-utilized. MLLMs still suffer from visually ungrounded hallucinations, often relying on language priors rather than image evidence. While many prior mitigation strategies operate on the text side, they leave the visual representation unchanged and do not exploit the rich hierarchy of features encoded across vision layers. Existing multi-layer fusion methods partially address this limitation but remain static, applying the same layer mixture regardless of the query. In this work, we introduce TGIF (Text-Guided Inter-layer Fusion), a lightweight module that treats encoder layers as depth-wise "experts" and predicts a prompt-dependent fusion of visual features. TGIF follows the principle of direct external fusion, requires no vision-encoder updates, and adds minimal overhead. Integrated into LLaVA-1.5-7B, TGIF provides consistent improvements across hallucination, OCR, and VQA benchmarks, while preserving or improving performance on ScienceQA, GQA, and MMBench. These results suggest that query-conditioned, hierarchy-aware fusion is an effective way to strengthen visual grounding and reduce hallucination in modern MLLMs.

</details>


### [43] [Unified Thinker: A General Reasoning Modular Core for Image Generation](https://arxiv.org/abs/2601.03127)
*Sashuai Zhou,Qiang Zhou,Jijin Hu,Hanqing Yang,Yue Cao,Junpeng Ma,Yinchao Ma,Jun Song,Tiezheng Ge,Cheng Yu,Bo Zheng,Zhou Zhao*

Main category: cs.CV

TL;DR: Unified Thinker提出了一种任务无关的推理架构，通过将推理模块与图像生成器解耦，专门处理逻辑密集型指令，显著提升了图像生成的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在处理逻辑密集型指令时存在推理-执行差距，闭源系统（如Nano Banana）已展示出强大的推理驱动图像生成能力，而开源模型在这方面存在明显不足。作者认为缩小这一差距需要可执行的推理能力，而不仅仅是更好的视觉生成器。

Method: 提出Unified Thinker架构，将专用的Thinker模块与图像Generator解耦，实现推理模块的独立升级。采用两阶段训练范式：首先为Thinker构建结构化规划接口，然后应用强化学习，基于像素级反馈来优化策略，确保规划更注重视觉正确性而非文本合理性。

Result: 在文本到图像生成和图像编辑任务上的广泛实验表明，Unified Thinker显著提升了图像推理和生成质量。

Conclusion: 通过将推理模块与生成器解耦，并采用两阶段训练方法，Unified Thinker有效缩小了当前生成模型在逻辑密集型指令处理方面的推理-执行差距，为通用图像生成提供了任务无关的推理架构。

Abstract: Despite impressive progress in high-fidelity image synthesis, generative models still struggle with logic-intensive instruction following, exposing a persistent reasoning--execution gap. Meanwhile, closed-source systems (e.g., Nano Banana) have demonstrated strong reasoning-driven image generation, highlighting a substantial gap to current open-source models. We argue that closing this gap requires not merely better visual generators, but executable reasoning: decomposing high-level intents into grounded, verifiable plans that directly steer the generative process. To this end, we propose Unified Thinker, a task-agnostic reasoning architecture for general image generation, designed as a unified planning core that can plug into diverse generators and workflows. Unified Thinker decouples a dedicated Thinker from the image Generator, enabling modular upgrades of reasoning without retraining the entire generative model. We further introduce a two-stage training paradigm: we first build a structured planning interface for the Thinker, then apply reinforcement learning to ground its policy in pixel-level feedback, encouraging plans that optimize visual correctness over textual plausibility. Extensive experiments on text-to-image generation and image editing show that Unified Thinker substantially improves image reasoning and generation quality.

</details>


### [44] [LSP-DETR: Efficient and Scalable Nuclei Segmentation in Whole Slide Images](https://arxiv.org/abs/2601.03163)
*Matěj Pekár,Vít Musil,Rudolf Nenutil,Petr Holub,Tomáš Brázdil*

Main category: cs.CV

TL;DR: LSP-DETR是一个用于细胞核实例分割的端到端框架，使用轻量级Transformer处理大尺寸图像，通过星形多边形表示和径向距离损失函数实现高效重叠核分割，无需后处理。


<details>
  <summary>Details</summary>
Motivation: 全切片图像的计算病理学中，精确且可扩展的细胞核实例分割面临重大计算挑战。现有方法依赖基于补丁的处理和昂贵的后处理进行实例分离，牺牲了上下文信息和效率。

Method: 提出LSP-DETR框架，使用具有线性复杂度的轻量级Transformer处理更大图像而无需额外计算成本。将细胞核表示为星形多边形，并引入新颖的径向距离损失函数，使重叠核的分割自然出现，无需显式重叠标注或手工后处理。

Result: 在PanNuke和MoNuSeg数据集上的评估显示，该方法在不同组织类型上具有强泛化能力和最先进的效率，LSP-DETR比次快领先方法快五倍以上。

Conclusion: LSP-DETR为计算病理学中的细胞核实例分割提供了一个高效、可扩展的端到端解决方案，克服了现有方法在计算效率和上下文保留方面的局限性。

Abstract: Precise and scalable instance segmentation of cell nuclei is essential for computational pathology, yet gigapixel Whole-Slide Images pose major computational challenges. Existing approaches rely on patch-based processing and costly post-processing for instance separation, sacrificing context and efficiency. We introduce LSP-DETR (Local Star Polygon DEtection TRansformer), a fully end-to-end framework that uses a lightweight transformer with linear complexity to process substantially larger images without additional computational cost. Nuclei are represented as star-convex polygons, and a novel radial distance loss function allows the segmentation of overlapping nuclei to emerge naturally, without requiring explicit overlap annotations or handcrafted post-processing. Evaluations on PanNuke and MoNuSeg show strong generalization across tissues and state-of-the-art efficiency, with LSP-DETR being over five times faster than the next-fastest leading method. Code and models are available at https://github.com/RationAI/lsp-detr.

</details>


### [45] [DiffBench Meets DiffAgent: End-to-End LLM-Driven Diffusion Acceleration Code Generation](https://arxiv.org/abs/2601.03178)
*Jiajun jiao,Haowei Zhu,Puyuan Yang,Jianghui Wang,Ji Liu,Ziqiong Liu,Dong Li,Yuejian Fang,Junhai Yong,Bin Wang,Emad Barsoum*

Main category: cs.CV

TL;DR: 本文提出了一个基于大语言模型的自动化框架，用于生成和评估扩散模型加速代码。该框架包括DiffBench基准测试和DiffAgent智能体，能够自动生成最优加速策略并迭代优化代码。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像和视频生成方面取得了显著成功，但其多步推理过程带来了巨大的计算开销，阻碍了实际部署。虽然加速扩散模型至关重要，但如何有效结合多种模型加速技术仍然是一个重大挑战。

Method: 提出了一个由大语言模型驱动的自动化框架：1) DiffBench - 一个全面的基准测试，实现了跨不同扩散架构、优化组合和部署场景的三阶段自动化评估流程；2) DiffAgent - 一个智能体，为任意扩散模型生成最优加速策略和代码，采用闭环工作流程，包括规划组件、调试组件和代码生成组件，同时使用遗传算法从执行环境中提取性能反馈来指导后续代码优化。

Result: 大量实验表明，DiffBench能够对生成的代码进行全面评估，并且DiffAgent在生成有效的扩散加速策略方面显著优于现有的大语言模型。

Conclusion: 该研究提出了一个创新的自动化框架，通过结合基准测试和智能体技术，有效解决了扩散模型加速策略生成和评估的挑战，为扩散模型的实时部署提供了重要支持。

Abstract: Diffusion models have achieved remarkable success in image and video generation. However, their inherently multiple step inference process imposes substantial computational overhead, hindering real-world deployment. Accelerating diffusion models is therefore essential, yet determining how to combine multiple model acceleration techniques remains a significant challenge. To address this issue, we introduce a framework driven by large language models (LLMs) for automated acceleration code generation and evaluation. First, we present DiffBench, a comprehensive benchmark that implements a three stage automated evaluation pipeline across diverse diffusion architectures, optimization combinations and deployment scenarios. Second, we propose DiffAgent, an agent that generates optimal acceleration strategies and codes for arbitrary diffusion models. DiffAgent employs a closed-loop workflow in which a planning component and a debugging component iteratively refine the output of a code generation component, while a genetic algorithm extracts performance feedback from the execution environment to guide subsequent code refinements. We provide a detailed explanation of the DiffBench construction and the design principles underlying DiffAgent. Extensive experiments show that DiffBench offers a thorough evaluation of generated codes and that DiffAgent significantly outperforms existing LLMs in producing effective diffusion acceleration strategies.

</details>


### [46] [AnatomiX, an Anatomy-Aware Grounded Multimodal Large Language Model for Chest X-Ray Interpretation](https://arxiv.org/abs/2601.03191)
*Anees Ur Rehman Hashmi,Numan Saeed,Christoph Lippert*

Main category: cs.CV

TL;DR: AnatomiX是一个专门为胸部X光解剖学基础解释设计的多任务多模态大语言模型，采用两阶段方法，在解剖学推理方面表现优异，相比现有方法在多个任务上性能提升超过25%。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态医学大语言模型在胸部X光解释中虽然取得了进展，但在空间推理和解剖学理解方面仍面临挑战。现有的基础技术虽然提高了整体性能，但往往无法建立真正的解剖学对应关系，导致医学领域中的解剖学理解错误。

Method: AnatomiX采用两阶段方法：首先识别解剖结构并提取其特征，然后利用大语言模型执行多种下游任务，包括短语定位、报告生成、视觉问答和图像理解。该方法受到放射学工作流程的启发。

Result: 在多个基准测试上的广泛实验表明，AnatomiX实现了卓越的解剖学推理能力，在解剖学定位、短语定位、基础诊断和基础描述任务上，相比现有方法性能提升超过25%。

Conclusion: AnatomiX通过明确设计用于解剖学基础的胸部X光解释，有效解决了现有模型在解剖学理解方面的不足，为医学影像分析提供了更准确和可靠的解决方案。

Abstract: Multimodal medical large language models have shown impressive progress in chest X-ray interpretation but continue to face challenges in spatial reasoning and anatomical understanding. Although existing grounding techniques improve overall performance, they often fail to establish a true anatomical correspondence, resulting in incorrect anatomical understanding in the medical domain. To address this gap, we introduce AnatomiX, a multitask multimodal large language model explicitly designed for anatomically grounded chest X-ray interpretation. Inspired by the radiological workflow, AnatomiX adopts a two stage approach: first, it identifies anatomical structures and extracts their features, and then leverages a large language model to perform diverse downstream tasks such as phrase grounding, report generation, visual question answering, and image understanding. Extensive experiments across multiple benchmarks demonstrate that AnatomiX achieves superior anatomical reasoning and delivers over 25% improvement in performance on anatomy grounding, phrase grounding, grounded diagnosis and grounded captioning tasks compared to existing approaches. Code and pretrained model are available at https://github.com/aneesurhashmi/anatomix

</details>


### [47] [UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision](https://arxiv.org/abs/2601.03193)
*Ruiyan Han,Zhen Fang,XinYu Sun,Yuchen Ma,Ziheng Wang,Yu Zeng,Zehui Chen,Lin Chen,Wenxuan Huang,Wei-Jie Xu,Yi Cao,Feng Zhao*

Main category: cs.CV

TL;DR: UniCorn是一个自改进框架，通过将统一多模态模型划分为提议者、求解者和评判者三个角色，通过自我博弈生成高质量交互，并将潜在理解提炼为显式生成信号，显著提升了文本到图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型在跨模态理解方面取得了显著成功，但在利用内部知识进行高质量生成方面存在显著差距。作者将这种差异形式化为传导性失语症现象，即模型能准确解释多模态输入，但难以将这种理解转化为忠实且可控的合成。

Method: 提出UniCorn自改进框架，无需外部数据或教师监督。将单个统一多模态模型划分为三个协作角色：提议者、求解者和评判者，通过自我博弈生成高质量交互，并采用认知模式重建将潜在理解提炼为显式生成信号。同时引入UniCycle基准，基于文本到图像到文本重建循环验证多模态一致性恢复。

Result: 在六个通用图像生成基准测试中，UniCorn相比基础模型实现了全面且显著的改进。在TIIF(73.8)、DPG(86.8)、CompBench(88.5)和UniCycle上达到SOTA性能，同时在WISE上提升+5.0，在OneIG上提升+6.5。

Conclusion: 该方法显著增强了文本到图像生成能力，同时保持了强大的理解能力，证明了完全自监督精炼在统一多模态智能中的可扩展性。

Abstract: While Unified Multimodal Models (UMMs) have achieved remarkable success in cross-modal comprehension, a significant gap persists in their ability to leverage such internal knowledge for high-quality generation. We formalize this discrepancy as Conduction Aphasia, a phenomenon where models accurately interpret multimodal inputs but struggle to translate that understanding into faithful and controllable synthesis. To address this, we propose UniCorn, a simple yet elegant self-improvement framework that eliminates the need for external data or teacher supervision. By partitioning a single UMM into three collaborative roles: Proposer, Solver, and Judge, UniCorn generates high-quality interactions via self-play and employs cognitive pattern reconstruction to distill latent understanding into explicit generative signals. To validate the restoration of multimodal coherence, we introduce UniCycle, a cycle-consistency benchmark based on a Text to Image to Text reconstruction loop. Extensive experiments demonstrate that UniCorn achieves comprehensive and substantial improvements over the base model across six general image generation benchmarks. Notably, it achieves SOTA performance on TIIF(73.8), DPG(86.8), CompBench(88.5), and UniCycle while further delivering substantial gains of +5.0 on WISE and +6.5 on OneIG. These results highlight that our method significantly enhances T2I generation while maintaining robust comprehension, demonstrating the scalability of fully self-supervised refinement for unified multimodal intelligence.

</details>


### [48] [LTX-2: Efficient Joint Audio-Visual Foundation Model](https://arxiv.org/abs/2601.03233)
*Yoav HaCohen,Benny Brazowski,Nisan Chiprut,Yaki Bitterman,Andrew Kvochko,Avishai Berkowitz,Daniel Shalem,Daphna Lifschitz,Dudu Moshe,Eitan Porat,Eitan Richardson,Guy Shiran,Itay Chachy,Jonathan Chetboun,Michael Finkelson,Michael Kupchick,Nir Zabari,Nitzan Guetta,Noa Kotler,Ofir Bibi,Ori Gordon,Poriya Panet,Roi Benita,Shahar Armon,Victor Kulikov,Yaron Inger,Yonatan Shiftan,Zeev Melumian,Zeev Farbman*

Main category: cs.CV

TL;DR: LTX-2是一个开源的基础模型，能够生成高质量、时间同步的视听内容，通过非对称双流Transformer架构实现统一的视听生成。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频扩散模型虽然能生成引人注目的视频序列，但缺乏音频提供的语义、情感和氛围线索，这限制了生成内容的沉浸感和表现力。

Method: 采用非对称双流Transformer架构，包含140亿参数的视频流和50亿参数的音频流，通过双向视听交叉注意力层连接，使用时间位置嵌入和跨模态AdaLN进行共享时间步调节。引入多语言文本编码器和模态感知的无分类器引导机制。

Result: 模型在开源系统中实现了最先进的视听质量和提示遵循度，同时以更低的计算成本和推理时间达到了与专有模型相当的结果。不仅能生成语音，还能产生丰富的连贯音频轨道。

Conclusion: LTX-2作为一个开源的基础模型，能够高效地生成高质量、时间同步的视听内容，在视听质量、提示遵循度和计算效率方面都表现出色，为视听生成领域提供了强大的开源解决方案。

Abstract: Recent text-to-video diffusion models can generate compelling video sequences, yet they remain silent -- missing the semantic, emotional, and atmospheric cues that audio provides. We introduce LTX-2, an open-source foundational model capable of generating high-quality, temporally synchronized audiovisual content in a unified manner. LTX-2 consists of an asymmetric dual-stream transformer with a 14B-parameter video stream and a 5B-parameter audio stream, coupled through bidirectional audio-video cross-attention layers with temporal positional embeddings and cross-modality AdaLN for shared timestep conditioning. This architecture enables efficient training and inference of a unified audiovisual model while allocating more capacity for video generation than audio generation. We employ a multilingual text encoder for broader prompt understanding and introduce a modality-aware classifier-free guidance (modality-CFG) mechanism for improved audiovisual alignment and controllability. Beyond generating speech, LTX-2 produces rich, coherent audio tracks that follow the characters, environment, style, and emotion of each scene -- complete with natural background and foley elements. In our evaluations, the model achieves state-of-the-art audiovisual quality and prompt adherence among open-source systems, while delivering results comparable to proprietary models at a fraction of their computational cost and inference time. All model weights and code are publicly released.

</details>


### [49] [InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields](https://arxiv.org/abs/2601.03252)
*Hao Yu,Haotong Lin,Jiawei Wang,Jiaxin Li,Yida Wang,Xueyang Zhang,Yue Wang,Xiaowei Zhou,Ruizhen Hu,Sida Peng*

Main category: cs.CV

TL;DR: InfiniDepth提出了一种基于神经隐式场的深度估计方法，能够预测任意分辨率的连续深度值，解决了传统方法在离散图像网格上的限制。


<details>
  <summary>Details</summary>
Motivation: 现有深度估计方法局限于在离散图像网格上预测深度，这种表示限制了其扩展到任意输出分辨率的能力，并阻碍了几何细节的恢复。

Method: 通过简单的局部隐式解码器，将深度表示为神经隐式场，可以在连续2D坐标上查询深度，实现任意分辨率和细粒度深度估计。

Result: 在合成和真实世界基准测试中，InfiniDepth在相对和度量深度估计任务上均达到最先进性能，特别是在细节丰富区域表现优异；同时在大视角变化下的新视角合成任务中也产生高质量结果。

Conclusion: 神经隐式场表示深度的方法能够实现任意分辨率和细粒度深度估计，在多个任务中表现出色，为深度估计提供了更灵活和准确的解决方案。

Abstract: Existing depth estimation methods are fundamentally limited to predicting depth on discrete image grids. Such representations restrict their scalability to arbitrary output resolutions and hinder the geometric detail recovery. This paper introduces InfiniDepth, which represents depth as neural implicit fields. Through a simple yet effective local implicit decoder, we can query depth at continuous 2D coordinates, enabling arbitrary-resolution and fine-grained depth estimation. To better assess our method's capabilities, we curate a high-quality 4K synthetic benchmark from five different games, spanning diverse scenes with rich geometric and appearance details. Extensive experiments demonstrate that InfiniDepth achieves state-of-the-art performance on both synthetic and real-world benchmarks across relative and metric depth estimation tasks, particularly excelling in fine-detail regions. It also benefits the task of novel view synthesis under large viewpoint shifts, producing high-quality results with fewer holes and artifacts.

</details>


### [50] [Muses: Designing, Composing, Generating Nonexistent Fantasy 3D Creatures without Training](https://arxiv.org/abs/2601.03256)
*Hexiao Lu,Xiaokun Sun,Zeyu Cai,Hao Guo,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: Muses是首个无需训练的前馈式3D生物生成方法，通过骨骼引导的体素组装实现高质量3D生物创作


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖部件感知优化、手动组装或2D图像生成，难以产生逼真连贯的3D资产，主要挑战在于复杂的部件级操作和有限的域外生成能力

Method: 1) 通过图约束推理构建具有连贯布局和尺度的创意3D骨架；2) 在结构化潜在空间中进行骨架引导的体素组装，整合不同对象的区域；3) 在骨骼条件下进行图像引导的外观建模，生成风格一致的和谱纹理

Result: 大量实验证明Muses在视觉保真度和文本描述对齐方面达到最先进水平，并在灵活的3D对象编辑方面展现出潜力

Conclusion: Muses通过骨骼表示将3D内容创作形式化为结构感知的设计-组合-生成流程，实现了无需训练的高质量3D生物生成

Abstract: We present Muses, the first training-free method for fantastic 3D creature generation in a feed-forward paradigm. Previous methods, which rely on part-aware optimization, manual assembly, or 2D image generation, often produce unrealistic or incoherent 3D assets due to the challenges of intricate part-level manipulation and limited out-of-domain generation. In contrast, Muses leverages the 3D skeleton, a fundamental representation of biological forms, to explicitly and rationally compose diverse elements. This skeletal foundation formalizes 3D content creation as a structure-aware pipeline of design, composition, and generation. Muses begins by constructing a creatively composed 3D skeleton with coherent layout and scale through graph-constrained reasoning. This skeleton then guides a voxel-based assembly process within a structured latent space, integrating regions from different objects. Finally, image-guided appearance modeling under skeletal conditions is applied to generate a style-consistent and harmonious texture for the assembled shape. Extensive experiments establish Muses' state-of-the-art performance in terms of visual fidelity and alignment with textual descriptions, and potential on flexible 3D object editing. Project page: https://luhexiao.github.io/Muses.github.io/.

</details>


<div id='nucl-th'></div>

# nucl-th [[Back]](#toc)

### [51] [Collision energy and system size dependence of longitudinal flow decorrelation in heavy-ion collisions at RHIC energies](https://arxiv.org/abs/2601.02691)
*Gaoguo Yan,Maowu Nie,Zhenyu Chen,Li Yi,Jiangyong Jia*

Main category: nucl-th

TL;DR: 该研究使用AMPT模型系统研究了重离子碰撞中纵向流解关联现象对碰撞能量和系统尺寸的依赖性，发现两种解关联分量均随赝快度线性减小，并表现出显著的碰撞能量和系统尺寸依赖性。


<details>
  <summary>Details</summary>
Motivation: 在重离子碰撞中，初始碰撞几何及其涨落驱动了末态强子在横向平面上的集体膨胀。然而，纵向涨落会引起事件平面扭曲和流幅度不对称性，统称为纵向流解关联现象。理解这一现象对于三维建模重离子碰撞的初始阶段和演化过程至关重要。

Method: 使用多相输运（AMPT）模型，系统研究Au+Au碰撞在$\sqrt{s_{\mathrm{NN}}}$ = 19.6, 27, 54.4, 200 GeV以及等压碰撞（Zr+Zr和Ru+Ru）在$\sqrt{s_{\mathrm{NN}}}$ = 200 GeV下的纵向流解关联现象。通过线性参数化$r_n(η) = 1-2F_nη$中的斜率参数$F_n$来量化解关联强度。

Result: 发现了两种不同的解关联分量：$r_n(η)$（包含流幅度不对称性和事件平面扭曲）和$R_n(η)$（仅来自事件平面扭曲）。两者都随赝快度η线性减小，并表现出显著的碰撞能量和系统尺寸依赖性。$F_2$和$F_3$都表现出明显的幂律标度行为，遵循关系$F_n \propto log \sqrt{s_{NN}}$。

Conclusion: 这些结果为相对论性重离子碰撞初始阶段的三维建模和演化过程提供了有价值的见解，揭示了纵向流解关联现象的系统性规律，有助于更好地理解重离子碰撞中的集体动力学行为。

Abstract: In heavy-ion collisions, the initial collision geometry and its fluctuations drive the collective expansion of final-state hadrons in the transverse plane. However, longitudinal fluctuations induce event-plane twist and flow magnitude asymmetries, collectively known as longitudinal flow decorrelation. Using a multi-phase transport (AMPT) model, we systematically investigate the dependence of collision energy and system size of this phenomenon with Au+Au collisions at $\sqrt{s_{\mathrm{NN}}}$ = 19.6, 27, 54.4, 200 GeV and isobar collisions (Zr+Zr and Ru+Ru) at $\sqrt{s_{\mathrm{NN}}}$ = 200 GeV. The results reveal two distinct decorrelation components: $r_n(η)$, which includes flow magnitude asymmetry and event-plane twist, and $R_n(η)$ which arises purely from event-plane twist. Both $r_n(η)$ and $R_n(η)$ decrease linearly with $η$ and exhibit a significant dependence on collision energy and the size of the system. Through the slope parameters $F_n$ in the linear parametrization $r_n(η) = 1-2F_nη$, we can quantify the strength of decorrelation. We further observe that both $F_2$ and $F_3$ demonstrate a pronounced power-law scaling behavior with collision energy, following the relation $F_n \propto log \sqrt{s_{NN}}$. These results provide valuable insights into the three-dimensional modeling of the initial stage and the evolution of relativistic heavy-ion collisions.

</details>


### [52] [A Universal Upper Bound on the Pressure-to-Energy Density Ratio in Neutron Stars](https://arxiv.org/abs/2601.02980)
*Bao-Jun Cai,Bao-An Li,Yu-Gang Ma*

Main category: nucl-th

TL;DR: 该论文改进了中子星中心状态方程参数φ的理论上限，结合因果性和质量球稳定性约束，得到φ≲0.385的新界限，并验证了中子星致密度的普适标度关系。


<details>
  <summary>Details</summary>
Motivation: 研究中子星中心压力与能量密度之比φ的理论上限，这一参数决定了宇宙中可见物质能达到的最大密度极限。由于广义相对论中状态方程的非线性结构，该界限远低于狭义相对论的朴素极限（φ=1）。

Method: 采用IPAD-TOV框架，结合狭义相对论的因果性约束和基于质量演化模式的质量球稳定性条件，自洽地推导φ的理论上限。使用284个现实状态方程模型验证中子星致密度的标度关系。

Result: 得到改进的理论上限φ≲0.385，略高于先前仅基于因果性的界限φ≲0.374。验证了中子星致密度的普适标度关系，该界限适用于包含一级相变、奇异自由度、连续交叉行为和退禁闭夸克核的各种状态方程。

Conclusion: 结合因果性和稳定性约束得到的φ≲0.385界限为研究广义相对论强场引力压缩下的超致密冷物质微观物理提供了新的、与状态方程无关的理论窗口。

Abstract: The equation-of-state (EOS) parameter $φ\equiv P/\varepsilon$, defined as the ratio of pressure to energy density, encapsulates the fundamental response of matter under extreme compression. Its value at the center of the most massive neutron star (NS), $\x \equiv φ_{\rm c} = P_{\rm c}/\varepsilon_{\rm c}$, sets a universal upper bound on the maximum denseness attainable by any form of visible matter anywhere in the Universe. Remarkably, owing to the intrinsically nonlinear structure of the EOS in General Relativity (GR), this bound is forced to lie far below the naive Special Relativity (SR) limit of unity. In this work, we refine the theoretical upper bound on $\x$ in a self-consistent manner by incorporating, in addition to the causality constraint from SR, the mass-sphere stability condition associated with the mass evolution pattern in the vicinity of the NS center. This condition is formulated within the intrinsic-and-perturbative analysis of the dimensionless Tolman--Oppenheimer--Volkoff equations (IPAD-TOV) framework. The combined constraints yield an improved bound, $\x \lesssim 0.385$, which is slightly above but fully consistent with the previously derived causal-only limit, $\x \lesssim 0.374$. We further derive an improved scaling relation for NS compactness and verify its universality across a broad set of 284 realistic EOSs, including models with first-order phase transitions, exotic degrees of freedom, continuous crossover behavior, and deconfined quark cores. The resulting bound on $\x$ thus provides a new, EOS-independent window into the microphysics of cold superdense matter compressed by strong-field gravity in GR.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [53] [ProSoftArena: Benchmarking Hierarchical Capabilities of Multimodal Agents in Professional Software Environments](https://arxiv.org/abs/2601.02399)
*Jiaxin Ai,Yukang Feng,Fanrui Zhang,Jianwen Sun,Zizhen Li,Chuanhao Li,Yifan Chang,Wenxiao Wu,Ruoxi Wang,Mingliang Zhai,Kaipeng Zhang*

Main category: cs.SE

TL;DR: ProSoftArena是一个专门评估多模态智能体在专业软件环境中表现的基准测试平台，包含436个跨6个学科13个专业应用的真实任务，采用执行评估和人工参与范式，结果显示当前最佳智能体在L2任务上仅24.4%成功率，L3多软件工作流完全失败。


<details>
  <summary>Details</summary>
Motivation: 现有多模态智能体基准主要局限于浏览器和基础桌面应用，无法评估专业软件工作流中的表现，而这些工作流在真实世界的科学和工业实践中占据主导地位。

Method: 1) 建立首个针对专业软件使用的智能体能力层次结构；2) 构建包含436个真实工作和研究任务的基准，涵盖6个学科和13个核心专业应用；3) 创建可执行的真实计算机环境，采用基于执行的评估框架；4) 独特地融入人工参与评估范式。

Result: 实验显示，即使表现最佳的智能体在L2任务上仅达到24.4%的成功率，在L3多软件工作流任务上完全失败。深入分析为当前智能体局限性和更有效的设计原则提供了宝贵见解。

Conclusion: ProSoftArena填补了专业软件环境评估的空白，揭示了当前多模态智能体在复杂专业工作流中的严重局限性，为构建更强大的专业软件智能体铺平了道路。

Abstract: Multimodal agents are making rapid progress on general computer-use tasks, yet existing benchmarks remain largely confined to browsers and basic desktop applications, falling short in professional software workflows that dominate real-world scientific and industrial practice. To close this gap, we introduce ProSoftArena, a benchmark and platform specifically for evaluating multimodal agents in professional software environments. We establish the first capability hierarchy tailored to agent use of professional software and construct a benchmark of 436 realistic work and research tasks spanning 6 disciplines and 13 core professional applications. To ensure reliable and reproducible assessment, we build an executable real-computer environment with an execution-based evaluation framework and uniquely incorporate a human-in-the-loop evaluation paradigm. Extensive experiments show that even the best-performing agent attains only a 24.4\% success rate on L2 tasks and completely fails on L3 multi-software workflow. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents in professional software settings. This project is available at: https://prosoftarena.github.io.

</details>


### [54] [Talks that Builds: Exploring Communication factors for the Success of Emerging Professional in Product Teams](https://arxiv.org/abs/2601.02421)
*Nyan Lin Zaw*

Main category: cs.SE

TL;DR: 研究填补了组织沟通文献中对年轻新兴专业人士（18-27岁）团队成功因素的研究空白，发现传统因素部分适用，同时识别出好奇心、地理位置邻近、文档记录、资源获取等新因素对团队成功的影响。


<details>
  <summary>Details</summary>
Motivation: 现有组织沟通研究主要关注27岁以上、拥有5年以上经验的成熟专业人士，缺乏对年轻新兴专业人士（18-27岁）团队的研究。本研究旨在填补这一文献空白，探索影响年轻产品团队成功的因素。

Method: 研究考察了年轻专业人士（18-27岁）组成的产品团队，通过分析团队成功因素，识别出哪些传统因素仍然适用，哪些变得不那么相关，并发现了新的影响因素。

Result: 研究发现：1）部分传统成功因素仍然适用；2）一些传统因素变得不那么相关；3）识别出新的成功因素包括：好奇心、地理位置邻近、文档记录、资源获取。这些新因素显著影响团队生产力和项目成果。

Conclusion: 本研究填补了年轻新兴专业人士团队成功因素的研究空白，揭示了好奇心、地理位置邻近、文档记录和资源获取等新因素对团队成功的重要性，为理解年轻团队动态提供了新的理论视角。

Abstract: This paper recognizes that most organizational communication study focuses on established professionals aged above 27 with more than five years of experience. In contrast, this study examines product teams with younger emerging professionals aged 18-27 and explores which factors influence their success. While some established factors still apply, others become less relevant, and new ones such as curiosity, locational proximity, documentation, access to resources were identified in the study. Overall, this study fills a gap in the literature on how these newer factors shape team productivity and project outcomes based on the success rate of the product the team developed.

</details>


### [55] [WebCoderBench: Benchmarking Web Application Generation with Comprehensive and Interpretable Evaluation Metrics](https://arxiv.org/abs/2601.02430)
*Chenxu Liu,Yingjie Fu,Wei Yang,Ying Zhang,Tao Xie*

Main category: cs.SE

TL;DR: WebCoderBench是首个基于真实用户需求、可泛化且可解释的网页应用生成基准，包含1572个真实用户需求，提供24个细粒度评估指标，实验显示目前没有模型在所有指标上占主导地位。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在网页应用代码生成领域缺乏合适的基准，现有基准存在以下问题：缺乏真实用户需求、评估指标依赖真实实现或测试用例、评估结果难以解释。需要建立一个真实收集、可泛化且可解释的基准来推动LLM在网页应用生成领域的发展。

Method: 1. 收集1572个真实用户需求，涵盖多种模态和表达风格；2. 设计24个细粒度评估指标，覆盖9个评估维度；3. 结合基于规则和LLM作为评判者的评估范式；4. 采用人类偏好对齐的指标权重，生成可解释的总体评分。

Result: 在12个代表性LLM和2个LLM智能体的实验中，没有模型在所有评估指标上占据主导地位，这为LLM开发者提供了针对性优化的机会，以开发更强大的版本。

Conclusion: WebCoderBench填补了网页应用生成基准的空白，为LLM开发者提供了针对性的优化方向，有助于推动LLM在网页应用生成领域的进一步发展。

Abstract: Web applications (web apps) have become a key arena for large language models (LLMs) to demonstrate their code generation capabilities and commercial potential. However, building a benchmark for LLM-generated web apps remains challenging due to the need for real-world user requirements, generalizable evaluation metrics without relying on ground-truth implementations or test cases, and interpretable evaluation results. To address these challenges, we introduce WebCoderBench, the first real-world-collected, generalizable, and interpretable benchmark for web app generation. WebCoderBench comprises 1,572 real user requirements, covering diverse modalities and expression styles that reflect realistic user intentions. WebCoderBench provides 24 fine-grained evaluation metrics across 9 perspectives, combining rule-based and LLM-as-a-judge paradigm for fully automated, objective, and general evaluation. Moreover, WebCoderBench adopts human-preference-aligned weights over metrics to yield interpretable overall scores. Experiments across 12 representative LLMs and 2 LLM-based agents show that there exists no dominant model across all evaluation metrics, offering an opportunity for LLM developers to optimize their models in a targeted manner for a more powerful version.

</details>


### [56] [Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection](https://arxiv.org/abs/2601.02438)
*Yun Bian,Yi Chen,HaiQuan Wang,ShiHao Li,Zhe Cui*

Main category: cs.SE

TL;DR: TaCCS-DFA是一个用于软件漏洞检测的多模态融合框架，通过Fisher信息实现任务导向的互补融合，在保持低计算开销的同时显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态方法通常假设添加模态必然带来额外信息，但实际上序列和图表示可能存在冗余，且图模态质量波动可能稀释主导模态的判别信号，需要更智能的融合策略。

Method: 提出TaCCS-DFA框架：1)使用Fisher信息作为几何度量识别对分类决策敏感的特征方向；2)在线估计低秩主Fisher子空间，将跨模态注意力限制在任务敏感方向；3)自适应门控机制动态调整每个样本的图模态贡献以抑制噪声传播。

Result: 在BigVul、Devign和ReVeal数据集上表现优异。以CodeT5为骨干时，在高度不平衡的BigVul数据集上达到87.80%的F1分数，比强基线Vul-LMGNNs提升6.3个百分点，同时保持低校准误差和计算开销。

Conclusion: TaCCS-DFA通过任务导向的互补融合有效解决了多模态冗余和噪声问题，在软件漏洞检测任务中实现了性能显著提升，理论分析表明其风险边界比传统全谱注意力更紧。

Abstract: Software vulnerability detection is a critical task for securing software systems and can be formulated as a binary classification problem: given a code snippet, determine whether it contains a vulnerability. Existing multimodal approaches typically fuse Natural Code Sequence (NCS) representations from pretrained language models with Code Property Graph (CPG) representations from graph neural networks, often under the implicit assumption that adding a modality necessarily yields extra information. In practice, sequence and graph representations can be redundant, and fluctuations in the quality of the graph modality can dilute the discriminative signal of the dominant modality. To address this, we propose TaCCS-DFA, a framework that introduces Fisher information as a geometric measure of how sensitive feature directions are to the classification decision, enabling task-oriented complementary fusion. TaCCS-DFA online estimates a low-rank principal Fisher subspace and restricts cross-modal attention to task-sensitive directions, thereby retrieving structural features from CPG that complement the sequence modality; meanwhile, an adaptive gating mechanism dynamically adjusts the contribution of the graph modality for each sample to suppress noise propagation. Our analysis shows that, under an isotropic perturbation assumption, the proposed mechanism admits a tighter risk bound than conventional full-spectrum attention. Experiments on BigVul, Devign, and ReVeal show that TaCCS-DFA achieves strong performance across multiple backbones. With CodeT5 as the backbone, TaCCS-DFA reaches an F1 score of 87.80\% on the highly imbalanced BigVul dataset, improving over a strong baseline Vul-LMGNNs by 6.3 percentage points while maintaining low calibration error and computational overhead.

</details>


### [57] [Enhancing Debugging Skills with AI-Powered Assistance: A Real-Time Tool for Debugging Support](https://arxiv.org/abs/2601.02504)
*Elizaveta Artser,Daniil Karol,Anna Potriasaeva,Aleksei Rostovskii,Katsiaryna Dzialets,Ekaterina Koshchenko,Xiaotian Su,April Yi Wang,Anastasiia Birillo*

Main category: cs.SE

TL;DR: 论文提出了一种集成到IDE中的AI驱动调试助手，通过实时分析代码、建议断点和提供上下文提示来支持编程教育和软件开发中的调试过程。


<details>
  <summary>Details</summary>
Motivation: 调试是编程教育和软件开发中的关键技能，但在计算机科学课程中经常被忽视。为了解决这个问题，需要开发有效的工具来支持调试教学和实践。

Method: 开发了一个集成到IDE中的AI驱动调试助手，采用RAG（检索增强生成）与LLMs（大语言模型）结合、程序切片和自定义启发式方法，通过减少LLM调用次数来提高效率和准确性。

Result: 通过三级评估（技术分析、用户体验研究和课堂测试）验证了该调试助手的有效性，突出了其在调试教学方面的潜力。

Conclusion: 该AI驱动的调试助手展示了在编程教育和软件开发中支持调试技能发展的潜力，通过智能辅助工具可以弥补传统课程中调试教学的不足。

Abstract: Debugging is a crucial skill in programming education and software development, yet it is often overlooked in CS curricula. To address this, we introduce an AI-powered debugging assistant integrated into an IDE. It offers real-time support by analyzing code, suggesting breakpoints, and providing contextual hints. Using RAG with LLMs, program slicing, and custom heuristics, it enhances efficiency by minimizing LLM calls and improving accuracy. A three-level evaluation - technical analysis, UX study, and classroom tests - highlights its potential for teaching debugging.

</details>


### [58] [Green LLM Techniques in Action: How Effective Are Existing Techniques for Improving the Energy Efficiency of LLM-Based Applications in Industry?](https://arxiv.org/abs/2601.02512)
*Pelin Rabia Kuran,Rumbidzai Chitakunye,Vincenzo Stoico,Ilja Heitlager,Justus Bogner*

Main category: cs.SE

TL;DR: 该研究分析了在工业环境中应用四种技术来减少大型语言模型能耗的效果，发现Prompt优化和2位量化能显著降低能耗但严重影响准确性，只有小型与大型模型协作技术能在不明显损害其他质量的前提下实现显著节能。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在工业规模上的广泛应用，其巨大的能耗问题日益受到关注。虽然已有多种技术被提出来解决这一问题，但缺乏关于这些技术在LLM工业应用中实际效果的实证证据。本研究旨在填补这一空白，通过在实际工业环境中测试不同优化技术的效果。

Method: 研究分析了Schuberg Philis公司（荷兰IT服务公司）在工业环境中的聊天机器人应用。选择了四种技术：小型与大型模型协作、提示优化、量化和批处理，将其应用于该应用并创建了八个变体。通过实验比较这些变体与未优化基线的能耗、准确性和响应时间。

Result: 结果显示，提示优化和2位量化等技术能显著降低能耗（有时高达90%），但这些技术对准确性产生了负面影响，在实践中不可接受。唯一能在不明显损害其他质量的前提下实现显著节能的技术是通过Nvidia的Prompt Task and Complexity Classifier（NPCC）与提示复杂度阈值的小型与大型模型协作。

Conclusion: 减少基于LLM应用的能耗在实践中并不困难，但提高其能效（即在降低能耗的同时不损害其他质量）仍然具有挑战性。小型与大型模型协作技术是实现这一目标的可行方法，研究为朝着这一目标迈进提供了实用见解。

Abstract: The rapid adoption of large language models (LLMs) has raised concerns about their substantial energy consumption, especially when deployed at industry scale. While several techniques have been proposed to address this, limited empirical evidence exists regarding the effectiveness of applying them to LLM-based industry applications. To fill this gap, we analyzed a chatbot application in an industrial context at Schuberg Philis, a Dutch IT services company. We then selected four techniques, namely Small and Large Model Collaboration, Prompt Optimization, Quantization, and Batching, applied them to the application in eight variations, and then conducted experiments to study their impact on energy consumption, accuracy, and response time compared to the unoptimized baseline.
  Our results show that several techniques, such as Prompt Optimization and 2-bit Quantization, managed to reduce energy use significantly, sometimes by up to 90%. However, these techniques especially impacted accuracy negatively, to a degree that is not acceptable in practice. The only technique that achieved significant and strong energy reductions without harming the other qualities substantially was Small and Large Model Collaboration via Nvidia's Prompt Task and Complexity Classifier (NPCC) with prompt complexity thresholds. This highlights that reducing the energy consumption of LLM-based applications is not difficult in practice. However, improving their energy efficiency, i.e., reducing energy use without harming other qualities, remains challenging. Our study provides practical insights to move towards this goal.

</details>


### [59] [On the Effectiveness of Proposed Techniques to Reduce Energy Consumption in RAG Systems: A Controlled Experiment](https://arxiv.org/abs/2601.02522)
*Zhinuan,Guo,Chushu Gao,Justus Bogner*

Main category: cs.SE

TL;DR: 本研究通过控制实验评估了五种降低RAG系统能耗的技术，发现相似度检索阈值优化和嵌入维度减少能在不损失准确性的情况下显著降低能耗和延迟，而向量索引等技术虽然节能但可能导致准确性大幅下降。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习（特别是RAG系统）能耗问题日益突出，虽然已有绿色ML技术研究，但这些技术在RAG系统中的实证评估仍很缺乏。本研究旨在填补这一空白，为构建可持续的RAG应用提供指导。

Method: 使用合作方Software Improvement Group开发的类生产RAG系统，通过控制实验评估五种节能技术：提高相似度检索阈值、减少嵌入维度、应用向量索引、使用BM25S重排序等。在CRAG数据集上进行了9种配置、超过200小时的试验，测量能耗、延迟和准确性。

Result: 实验显示：1）多种技术可显著降低能耗（最高达60%）；2）但部分技术导致准确性不可接受的下降（如索引策略降低30%）；3）优化检索阈值和减少嵌入维度能在不损失准确性的情况下大幅降低能耗和延迟，是真正节能的技术。

Conclusion: 这是首个针对RAG系统节能设计技术的全面实证研究，为开发者和研究人员构建可持续RAG应用提供了具体指导。研究表明，通过精心选择技术组合，可以在保持性能的同时实现显著的节能效果。

Abstract: The rising energy demands of machine learning (ML), e.g., implemented in popular variants like retrieval-augmented generation (RAG) systems, have raised significant concerns about their environmental sustainability. While previous research has proposed green tactics for ML-enabled systems, their empirical evaluation within RAG systems remains largely unexplored. This study presents a controlled experiment investigating five practical techniques aimed at reducing energy consumption in RAG systems. Using a production-like RAG system developed at our collaboration partner, the Software Improvement Group, we evaluated the impact of these techniques on energy consumption, latency, and accuracy.
  Through a total of 9 configurations spanning over 200 hours of trials using the CRAG dataset, we reveal that techniques such as increasing similarity retrieval thresholds, reducing embedding sizes, applying vector indexing, and using a BM25S reranker can significantly reduce energy usage, up to 60% in some cases. However, several techniques also led to unacceptable accuracy decreases, e.g., by up to 30% for the indexing strategies. Notably, finding an optimal retrieval threshold and reducing embedding size substantially reduced energy consumption and latency with no loss in accuracy, making these two techniques truly energy-efficient. We present the first comprehensive, empirical study on energy-efficient design techniques for RAG systems, providing guidance for developers and researchers aiming to build sustainable RAG applications.

</details>


### [60] [PerspectiveCoach: Exploring LLMs for Developer Reflection](https://arxiv.org/abs/2601.02559)
*Lauren Olson,Emitzá Guzmán,Florian Kunneman*

Main category: cs.SE

TL;DR: PerspectiveCoach是一个基于大语言模型的对话工具，旨在通过结构化视角训练帮助开发者更好地理解边缘化用户的体验，提升软件设计中的伦理反思能力。


<details>
  <summary>Details</summary>
Motivation: 尽管软件开发中的伦理挑战日益受到关注，但从业者仍然缺乏能够帮助他们批判性地参与边缘化用户生活体验的结构化工具。现有工具不足以支持开发者深入反思软件设计决策如何影响边缘化社区。

Method: 开发了PerspectiveCoach这一基于大语言模型的对话工具，通过结构化视角训练引导开发者。进行了对照研究，18名前端开发者（性别平衡）使用该工具处理在线性别骚扰的真实案例。同时进行了补充性的人-人研究作为对比。采用定性分析和文本相似性分析评估效果。

Result: 定性分析显示参与者自我意识增强、视角拓宽、伦理表达更加细致。文本相似性分析表明，在人-工具研究中，参与者的重述保真度随尝试次数提高，能够捕捉用户关注点的表层和语义层面。然而，人-工具对话的重述基线低于人-人对话，突显了非人际和人际视角训练的情境差异。参与者对工具的可用性和相关性评价很高。

Conclusion: 这项工作为大语言模型驱动的终端用户视角训练提供了探索性设计，支持批判性伦理自我反思。研究结果为如何改进此类工具（如增强适应性、关注多元性）提供了实证见解，帮助从业者构建更具包容性和社会响应性的技术。

Abstract: Despite growing awareness of ethical challenges in software development, practitioners still lack structured tools that help them critically engage with the lived experiences of marginalized users. This paper presents PerspectiveCoach, a large language model (LLM)-powered conversational tool designed to guide developers through structured perspective-taking exercises and deepen critical reflection on how software design decisions affect marginalized communities. Through a controlled study with 18 front-end developers (balanced by sex), who interacted with the tool using a real case of online gender-based harassment, we examine how PerspectiveCoach supports ethical reasoning and engagement with user perspectives. Qualitative analysis revealed increased self-awareness, broadened perspectives, and more nuanced ethical articulation, while a complementary human-human study contextualized these findings. Text similarity analyses demonstrated that participants in the human-PerspectiveCoach study improved the fidelity of their restatements over multiple attempts, capturing both surface-level and semantic aspects of user concerns. However, human-PerspectiveCoach's restatements had a lower baseline than the human-human conversations, highlighting contextual differences in impersonal and interpersonal perspective-taking. Across the study, participants rated the tool highly for usability and relevance. This work contributes an exploratory design for LLM-powered end-user perspective-taking that supports critical, ethical self-reflection and offers empirical insights (i.e., enhancing adaptivity, centering plurality) into how such tools can help practitioners build more inclusive and socially responsive technologies.

</details>


### [61] [Compressed code: the hidden effects of quantization and distillation on programming tokens](https://arxiv.org/abs/2601.02563)
*Viacheslav Siniaev,Iaroslav Chelombitko,Aleksey Komissarov*

Main category: cs.SE

TL;DR: 该论文系统分析了LLM在代码生成中的token级机制，特别是压缩模型中的表现，提出了冷启动概率分析方法，并评估了不同优化技术对token表示和代码生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码生成方面表现出色，但其token级机制特别是压缩模型中的机制尚未得到充分探索，需要系统分析编程语言在LLM tokenizer中的编码方式。

Method: 通过分析词汇分布和关键词覆盖模式来表征编程语言在LLM tokenizer中的编码方式；引入新颖的冷启动概率分析方法；全面评估量化、蒸馏、模型缩放和任务特定微调等优化技术对token级表示和代码生成质量的影响。

Result: 实验通过全面的概率分布分析和评估指标，揭示了token级行为的关键见解，并为在各种优化约束下保持代码生成质量提供了经验验证的指导原则。

Conclusion: 这些发现不仅推进了对LLM代码生成的理论理解，还为生产环境中优化模型的实际实施提供了指导。

Abstract: Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.

</details>


### [62] [State of the Quantum Software Engineering Ecosystem](https://arxiv.org/abs/2601.02601)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 使用GPT-5分析量子软件工程生态系统现状，识别学术界和工业界在QSE领域的活跃机构与成功企业


<details>
  <summary>Details</summary>
Motivation: 研究量子软件工程生态系统的当前状态，特别关注学术界和工业界的成就、活动与参与，重点关注该领域成功的创业企业

Method: 采用新颖的研究方法，利用最先进的人工智能技术——大型语言模型（特别是GPT-5），通过ChatGPT工具进行分析，识别在QSE领域高度活跃且取得显著成果的机构和企业

Result: 识别出在量子软件工程领域具有高度活跃度且取得杰出成果的机构和企业，这些成果通过同行评审出版物或风险资本市场融资得到验证

Conclusion: 通过AI驱动的分析方法，系统性地评估了量子软件工程生态系统的现状，为理解该领域的发展趋势和成功模式提供了新的研究视角

Abstract: We study the current state of the Quantum Software Engineering (QSE) ecosystem, focusing on the achievements, activities, and engagements from academia and industry, with a special focus on successful entrepreneurial endeavors in this arena. Our research methodology is a novel one, featuring the state-of-the-art in Artificial Intelligence (AI), namely Large Language Models (LLMs), especially Generative Pretrained Transformers (GPT). We use one of such models, namely the OpenAI GPT-5 model, through the ChatGPT tool. The goal is to identify institutions and companies that are highly active and have achieved distinguished results in QSE, evidenced by peer-reviewed publications or raised capital in the venture capital market.

</details>


### [63] [TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs](https://arxiv.org/abs/2601.02632)
*Alireza Ezaz,Ghazal Khodabandeh,Majid Babaei,Naser Ezzati-Jivan*

Main category: cs.SE

TL;DR: TAAF框架结合时间索引知识图谱和LLM，将原始执行轨迹数据转化为可操作的洞察，显著提升轨迹分析准确率


<details>
  <summary>Details</summary>
Motivation: 操作系统内核或大型应用（如Chrome、MySQL）的执行轨迹数据量巨大且难以分析，现有工具依赖预定义分析，自定义洞察需要编写易出错且耗时的领域特定脚本

Method: 提出TAAF框架，结合时间索引、知识图谱和大型语言模型：1）从轨迹事件构建时间索引知识图谱，捕捉线程、CPU、系统资源等实体关系；2）使用LLM解释查询特定子图来回答自然语言问题

Result: 引入TraceQA-100基准测试（100个基于真实内核轨迹的问题），实验显示TAAF在三种LLM和多种时间设置下将答案准确率提升高达31.2%，特别是在多跳和因果推理任务中表现突出

Conclusion: TAAF减少了手动检查和深度系统专业知识的需求，分析了图基推理的优势和局限性，为下一代轨迹分析工具奠定了基础

Abstract: Execution traces are a critical source of information for understanding, debugging, and optimizing complex software systems. However, traces from OS kernels or large-scale applications like Chrome or MySQL are massive and difficult to analyze. Existing tools rely on predefined analyses, and custom insights often require writing domain-specific scripts, which is an error-prone and time-consuming task. This paper introduces TAAF (Trace Abstraction and Analysis Framework), a novel approach that combines time-indexing, knowledge graphs (KGs), and large language models (LLMs) to transform raw trace data into actionable insights. TAAF constructs a time-indexed KG from trace events to capture relationships among entities such as threads, CPUs, and system resources. An LLM then interprets query-specific subgraphs to answer natural-language questions, reducing the need for manual inspection and deep system expertise. To evaluate TAAF, we introduce TraceQA-100, a benchmark of 100 questions grounded in real kernel traces. Experiments across three LLMs and multiple temporal settings show that TAAF improves answer accuracy by up to 31.2%, particularly in multi-hop and causal reasoning tasks. We further analyze where graph-grounded reasoning helps and where limitations remain, offering a foundation for next-generation trace analysis tools.

</details>


### [64] [Enterprise Identity Integration for AI-Assisted Developer Services: Architecture, Implementation, and Case Study](https://arxiv.org/abs/2601.02698)
*Manideep Reddy Chinthareddy*

Main category: cs.SE

TL;DR: 本文提出了一种将OAuth 2.0和OpenID Connect集成到MCP开发者环境中的实用架构，以解决企业AI辅助开发工具的身份验证和访问控制问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI辅助开发服务在现代IDE中的普及，企业需要确保这些工具能够在现有的身份、访问控制和治理要求下运行。MCP协议虽然能让AI助手获取结构化内部上下文，但其规范仅提供最小授权模型，缺乏企业SSO集成指导。

Method: 提出了一种实用架构，将OAuth 2.0和OpenID Connect集成到MCP开发者环境中。具体包括：IDE扩展获取和呈现令牌的方法、MCP服务器通过身份提供者验证令牌的机制、以及如何使用范围和声明实施最小权限访问。通过使用Visual Studio Code、Python MCP服务器和OIDC兼容IdP的原型实现来验证可行性。

Result: 原型实现证明了该方法的可行性。通过案例研究评估了身份验证延迟、令牌验证开销、操作考虑因素和AI特定风险。该架构为组织采用AI辅助开发工具提供了可部署的模式。

Conclusion: 该方法为组织采用AI辅助开发工具提供了可部署的模式，同时保持了身份保证和可审计性，解决了企业环境中AI开发工具的安全和治理需求。

Abstract: AI-assisted developer services are increasingly embedded in modern IDEs, yet enterprises must ensure these tools operate within existing identity, access control, and governance requirements. The Model Context Protocol (MCP) enables AI assistants to retrieve structured internal context, but its specification provides only a minimal authorization model and lacks guidance on integrating enterprise SSO. This article presents a practical architecture that incorporates OAuth 2.0 and OpenID Connect (OIDC) into MCP-enabled developer environments. It describes how IDE extensions obtain and present tokens, how MCP servers validate them through an identity provider, and how scopes and claims can enforce least-privilege access. A prototype implementation using Visual Studio Code, a Python-based MCP server, and an OIDC-compliant IdP demonstrates feasibility. A case study evaluates authentication latency, token-validation overhead, operational considerations, and AI-specific risks. The approach provides a deployable pattern for organizations adopting AI-assisted developer tools while maintaining identity assurance and auditability.

</details>


### [65] [Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices](https://arxiv.org/abs/2601.02732)
*Lingzhe Zhang,Tong Jia,Yunpeng Zhai,Leyi Pan,Chiming Duan,Minghua He,Mengxi Jia,Ying Li*

Main category: cs.SE

TL;DR: AMER-RCL是一个基于智能体记忆增强的递归推理框架，用于微服务系统中的根因定位，通过模拟SRE专家的递归推理和多维扩展特性，显著提高了定位准确性和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有微服务系统根因定位方法存在两个主要问题：1）传统基于图和深度学习的方法依赖预定义模式，难以适应动态运维环境；2）现有LLM方法存在浅层症状推理和缺乏跨告警重用的问题，导致准确性不足和推理延迟高。研究通过分析SRE专家的根因分析行为，发现其具有递归性、多维扩展和跨模态推理三个关键特征。

Method: 提出AMER-RCL框架，包含两个核心组件：1）递归推理RCL引擎：采用多智能体框架，对每个告警执行递归推理，逐步细化候选原因；2）智能体记忆：在时间窗口内增量积累和重用先前告警的推理结果，减少冗余探索并降低推理延迟。

Result: 实验结果表明，AMER-RCL在定位准确性和推理效率方面均优于现有最先进方法，能够更有效地处理微服务系统中的故障根因定位问题。

Conclusion: 通过模拟SRE专家的递归推理模式并引入智能体记忆机制，AMER-RCL成功解决了现有根因定位方法的局限性，为复杂微服务系统的可靠性保障提供了有效的解决方案。

Abstract: As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.

</details>


### [66] [Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism](https://arxiv.org/abs/2601.02736)
*Lingzhe Zhang,Tong Jia,Yunpeng Zhai,Leyi Pan,Chiming Duan,Minghua He,Pei Xiao,Ying Li*

Main category: cs.SE

TL;DR: SpecRCA是一个用于微服务系统的推测式根因分析框架，采用"假设-验证"范式，通过假设草稿模块快速生成候选根因，并行验证器高效验证，在准确性和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 微服务系统因其资源弹性、松耦合架构和轻量部署成为云原生企业应用的支柱，但其内在复杂性和动态运行时交互不可避免地导致异常。确保系统可靠性依赖于有效的根因分析，需要及时、可解释地定位异常源并描述底层故障。现有基于大语言模型的RCA方法存在两个关键限制：探索多样性有限影响准确性，依赖大规模LLM导致推理缓慢。

Method: 提出SpecRCA框架，采用"假设-验证"范式：1) 假设草稿模块快速生成候选根因；2) 并行根因验证器高效验证候选根因。该方法旨在克服现有LLM-based方法的局限性。

Result: 在AIOps 2022数据集上的初步实验表明，SpecRCA在准确性和效率方面优于现有方法，展示了其在复杂微服务环境中作为可扩展、可解释RCA实用解决方案的潜力。

Conclusion: SpecRCA框架通过假设-验证范式有效解决了现有LLM-based根因分析方法的局限性，为复杂微服务环境提供了可扩展、可解释的实用解决方案。

Abstract: Microservice systems have become the backbone of cloud-native enterprise applications due to their resource elasticity, loosely coupled architecture, and lightweight deployment. Yet, the intrinsic complexity and dynamic runtime interactions of such systems inevitably give rise to anomalies. Ensuring system reliability therefore hinges on effective root cause analysis (RCA), which entails not only localizing the source of anomalies but also characterizing the underlying failures in a timely and interpretable manner. Recent advances in intelligent RCA techniques, particularly those powered by large language models (LLMs), have demonstrated promising capabilities, as LLMs reduce reliance on handcrafted features while offering cross-platform adaptability, task generalization, and flexibility. However, existing LLM-based methods still suffer from two critical limitations: (a) limited exploration diversity, which undermines accuracy, and (b) heavy dependence on large-scale LLMs, which results in slow inference. To overcome these challenges, we propose SpecRCA, a speculative root cause analysis framework for microservices that adopts a \textit{hypothesize-then-verify} paradigm. SpecRCA first leverages a hypothesis drafting module to rapidly generate candidate root causes, and then employs a parallel root cause verifier to efficiently validate them. Preliminary experiments on the AIOps 2022 dataset demonstrate that SpecRCA achieves superior accuracy and efficiency compared to existing approaches, highlighting its potential as a practical solution for scalable and interpretable RCA in complex microservice environments.

</details>


### [67] [CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation](https://arxiv.org/abs/2601.02868)
*Peiding Wang,Li Zhang,Fang Liu,Chongyang Tao,Yinghao Zhu*

Main category: cs.SE

TL;DR: CodeMEM是一个基于AST的动态内存管理系统，专门用于仓库级迭代代码生成，通过AST引导的LLM操作动态维护仓库上下文，并使用代码中心表示来管理交互历史，显著提升指令跟随性能并减少交互轮次。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在仓库级代码生成中面临两个主要问题：1）随着交互进行，仓库上下文需要持续保存和更新以整合新验证信息；2）扩大的会话历史增加了认知负担，导致遗忘和已解决错误的重新引入。现有内存管理方法受限于自然语言中心表示。

Method: 提出CodeMEM系统，包含两个核心组件：1）Code Context Memory - 通过AST引导的LLM操作动态维护和更新仓库上下文；2）Code Session Memory - 构建交互历史的代码中心表示，通过AST分析显式检测和缓解遗忘问题。

Result: 在CodeIF-Bench和CoderEval基准测试中，CodeMEM实现了最先进的性能：当前轮次指令跟随提升12.2%，会话级别提升11.5%，交互轮次减少2-3轮，同时保持有竞争力的推理延迟和token效率。

Conclusion: CodeMEM通过AST引导的动态内存管理有效解决了仓库级代码生成中的上下文维护和遗忘问题，显著提升了LLM在迭代代码生成中的性能表现，为开发者生产力提供了实质性增强。

Abstract: Large language models (LLMs) substantially enhance developer productivity in repository-level code generation through interactive collaboration. However, as interactions progress, repository context must be continuously preserved and updated to integrate newly validated information. Meanwhile, the expanding session history increases cognitive burden, often leading to forgetting and the reintroduction of previously resolved errors. Existing memory management approaches show promise but remain limited by natural language-centric representations. To overcome these limitations, we propose CodeMEM, an AST-guided dynamic memory management system tailored for repository-level iterative code generation. Specifically, CodeMEM introduces the Code Context Memory component that dynamically maintains and updates repository context through AST-guided LLM operations, along with the Code Session Memory that constructs a code-centric representation of interaction history and explicitly detects and mitigates forgetting through AST-based analysis. Experimental results on the instruction-following benchmark CodeIF-Bench and the code generation benchmark CoderEval demonstrate that CodeMEM achieves state-of-the-art performance, improving instruction following by 12.2% for the current turn and 11.5% for the session level, and reducing interaction rounds by 2-3, while maintaining competitive inference latency and token efficiency.

</details>


### [68] [Few-shot learning for security bug report identification](https://arxiv.org/abs/2601.02971)
*Muhammad Laiq*

Main category: cs.SE

TL;DR: 本文提出了一种基于少样本学习的SetFit框架，用于在标注数据稀缺的情况下有效识别安全漏洞报告，相比传统机器学习方法取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 安全漏洞报告需要及时识别以最小化软件系统的漏洞窗口。传统机器学习方法依赖大量标注数据，但在实践中安全漏洞报告数据集往往稀缺，导致模型性能不佳且在实际应用中受限。

Method: 采用SetFit框架，这是一种最先进的少样本学习方法，结合了句子转换器、对比学习和参数高效微调技术。模型在少量标注的漏洞报告数据集上进行训练，用于将报告分类为安全相关或非安全相关。

Result: 该方法在所有评估数据集上均优于传统机器学习基准方法，最佳AUC达到0.865，显示出SetFit在识别安全漏洞报告方面的有效性。

Conclusion: 基于SetFit的少样本学习为识别安全漏洞报告提供了一种有前景的替代方案，能够在标注数据稀缺的情况下高效开发模型，最小化标注工作量，适用于实际应用场景。

Abstract: Security bug reports require prompt identification to minimize the window of vulnerability in software systems. Traditional machine learning (ML) techniques for classifying bug reports to identify security bug reports rely heavily on large amounts of labeled data. However, datasets for security bug reports are often scarce in practice, leading to poor model performance and limited applicability in real-world settings. In this study, we propose a few-shot learning-based technique to effectively identify security bug reports using limited labeled data. We employ SetFit, a state-of-the-art few-shot learning framework that combines sentence transformers with contrastive learning and parameter-efficient fine-tuning. The model is trained on a small labeled dataset of bug reports and is evaluated on its ability to classify these reports as either security-related or non-security-related. Our approach achieves an AUC of 0.865, at best, outperforming traditional ML techniques (baselines) for all of the evaluated datasets. This highlights the potential of SetFit to effectively identify security bug reports. SetFit-based few-shot learning offers a promising alternative to traditional ML techniques to identify security bug reports. The approach enables efficient model development with minimal annotation effort, making it highly suitable for scenarios where labeled data is scarce.

</details>


### [69] [A Dataset of Low-Rated Applications from the Amazon Appstore for User Feedback Analysis](https://arxiv.org/abs/2601.03009)
*Nek Dil Khan,Javed Ali Khan,Darvesh Khan,Jianqiang Li,Mumrez Khan,Shah Fahad Khan*

Main category: cs.SE

TL;DR: 该研究创建了一个来自亚马逊软件应用商店64个低评分应用的79,821条用户评论数据集，其中6,000条评论被手动标注为六大问题类别，为基于机器学习的用户反馈自动分类提供资源。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注高评分应用，而低评分应用虽然能揭示有价值的改进见解，却往往被忽视。本研究旨在填补这一空白，通过分析低评分应用的用户反馈来识别常见问题，为软件质量改进提供数据支持。

Method: 从亚马逊软件应用商店收集64个低评分应用的79,821条用户评论，创建了一个专门的数据集。为了增强数据集实用性，研究人员手动标注了6,000条评论，将其分类到六个不同的问题类别：用户界面与用户体验、功能与特性、兼容性与设备特定性、性能与稳定性、客户支持与响应性、安全与隐私问题。

Result: 创建了一个包含79,821条原始评论和6,000条标注评论的公开数据集。该数据集能够捕捉用户识别的最常见问题，为开发基于机器学习的用户反馈自动分类方法提供了宝贵资源。数据集还支持探索软件演化相关活动，如缺失功能分析、讽刺检测和情感分析。

Conclusion: 该数据集为研究人员和开发者提供了理解低评分应用常见问题的关键工具，为基于用户反馈改进软件质量的数据驱动解决方案奠定了基础。公开提供标注和原始数据集将促进软件质量改进研究，并帮助软件供应商和研究人员探索各种软件演化相关活动。

Abstract: In todays digital landscape, end-user feedback plays a crucial role in the evolution of software applications, particularly in addressing issues that hinder user experience. While much research has focused on high-rated applications, low-rated applications often remain unexplored, despite their potential to reveal valuable insights. This study introduces a novel dataset curated from 64 low-rated applications sourced from the Amazon Software Appstore (ASA), containing 79,821 user reviews. The dataset is designed to capture the most frequent issues identified by users, which are critical for improving software quality. To further enhance the dataset utility, a subset of 6000 reviews was manually annotated to classify them into six district issue categories: user interface (UI) and user experience (UX), functionality and features, compatibility and device specificity, performance and stability, customer support and responsiveness, and security and privacy issues. This annotated dataset is a valuable resource for developing machine learning-based approaches aiming to automate the classification of user feedback into various issue types. Making both the annotated and raw datasets publicly available provides researchers and developers with a crucial tool to understand common issues in low-rated apps and inform software improvements. The comprehensive analysis and availability of this dataset lay the groundwork for data-derived solutions to improve software quality based on user feedback. Additionally, the dataset can provide opportunities for software vendors and researchers to explore various software evolution-related activities, including frequently missing features, sarcasm, and associated emotions, which will help better understand the reasons for comparatively low app ratings.

</details>


### [70] [NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments](https://arxiv.org/abs/2601.03251)
*Xue Qin,Matthew DiGiovanni*

Main category: cs.SE

TL;DR: NavAI是一个基于大语言模型的通用VR导航框架，在目标导向任务中达到89%的成功率，但完全依赖LLM在动态目标评估场景中存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有导航技术主要关注360度图像数据集和3D模拟器中的路径优化，无法直接应用于沉浸式VR环境，需要开发适用于VR的通用导航框架。

Method: 提出NavAI框架，基于大语言模型支持基本动作和复杂目标导向任务，在三个不同的VR环境中通过目标导向和探索性任务进行评估。

Result: NavAI在目标导向任务中达到89%的成功率，表现出高准确性，但分析显示完全依赖LLM在需要动态目标评估的场景中存在局限性。

Conclusion: NavAI展示了LLM在VR导航中的潜力，但完全依赖LLM存在限制，特别是在动态目标评估方面，需要未来研究进一步改进。

Abstract: Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [71] [LongDA: Benchmarking LLM Agents for Long-Document Data Analysis](https://arxiv.org/abs/2601.02598)
*Yiyang Li,Zheyuan Zhang,Tianyi Ma,Zehong Wang,Keerthiram Murugesan,Chuxu Zhang,Yanfang Ye*

Main category: cs.DL

TL;DR: LongDA是一个针对LLM智能体在文档密集型数据分析工作流中的评估基准，包含505个基于真实调查数据的分析查询，要求智能体从多份非结构化文档中检索信息并编写可执行代码。


<details>
  <summary>Details</summary>
Motivation: 现有基准假设模式和数据输入良好定义，但现实世界中导航长文档和复杂数据是主要瓶颈。需要评估LLM智能体在真实、高风险分析环境中的能力。

Method: 从17个美国国家调查中手动整理原始数据文件、长而异构的文档和专家撰写的出版物，提取505个基于真实分析实践的查询。开发LongTA工具增强智能体框架，支持文档访问、检索和代码执行。

Result: 实验显示即使最先进的模型之间也存在显著性能差距，突显了在现实高风险分析环境中应用LLM智能体面临的挑战。

Conclusion: LongDA基准揭示了LLM智能体在文档密集型数据分析中的局限性，为研究者在真实决策支持应用中需要考虑的挑战提供了重要见解。

Abstract: We introduce LongDA, a data analysis benchmark for evaluating LLM-based agents under documentation-intensive analytical workflows. In contrast to existing benchmarks that assume well-specified schemas and inputs, LongDA targets real-world settings in which navigating long documentation and complex data is the primary bottleneck. To this end, we manually curate raw data files, long and heterogeneous documentation, and expert-written publications from 17 publicly available U.S. national surveys, from which we extract 505 analytical queries grounded in real analytical practice. Solving these queries requires agents to first retrieve and integrate key information from multiple unstructured documents, before performing multi-step computations and writing executable code, which remains challenging for existing data analysis agents. To support the systematic evaluation under this setting, we develop LongTA, a tool-augmented agent framework that enables document access, retrieval, and code execution, and evaluate a range of proprietary and open-source models. Our experiments reveal substantial performance gaps even among state-of-the-art models, highlighting the challenges researchers should consider before applying LLM agents for decision support in real-world, high-stakes analytical settings.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [72] [GCRank: A Generative Contextual Comprehension Paradigm for Takeout Ranking Model](https://arxiv.org/abs/2601.02361)
*Ziheng Ni,Congcong Liu,Cai Shang,Yiming Sun,Junjie Li,Zhiwei Fang,Guangpeng Chen,Jian Li,Zehua Zhang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao*

Main category: cs.IR

TL;DR: 本文提出了一种新的生成式框架，将广告排名重新定义为上下文理解任务，通过统一架构建模异构信号，在食品外卖广告平台中显著提升了点击率和平台收入。


<details>
  <summary>Details</summary>
Motivation: 现有广告排名模型依赖碎片化模块和手工特征，难以理解复杂用户意图，特别是在食品外卖等基于位置的服务中，用户决策受到动态空间、时间和个体上下文的影响。

Method: 提出生成式上下文框架，包含两个核心组件：生成式上下文编码器（GCE）和生成式上下文融合（GCF）。GCE包含三个专门模块：个性化上下文增强器（PCE）用于用户特定建模，集体上下文增强器（CCE）用于群体级模式，动态上下文增强器（DCE）用于实时情境适应。GCF通过低秩适应无缝整合这些上下文表示。

Result: 在关键业务指标上取得显著提升，包括点击率和平台收入。该方法已成功部署在大规模食品外卖广告平台，展示了其实际应用价值。

Conclusion: 这项工作为生成式推荐提供了新视角，并突出了其在工业广告系统中的实际潜力，特别是在处理复杂上下文信息的基于位置服务中。

Abstract: The ranking stage serves as the central optimization and allocation hub in advertising systems, governing economic value distribution through eCPM and orchestrating the user-centric blending of organic and advertising content. Prevailing ranking models often rely on fragmented modules and hand-crafted features, limiting their ability to interpret complex user intent. This challenge is further amplified in location-based services such as food delivery, where user decisions are shaped by dynamic spatial, temporal, and individual contexts. To address these limitations, we propose a novel generative framework that reframes ranking as a context comprehension task, modeling heterogeneous signals in a unified architecture. Our architecture consists of two core components: the Generative Contextual Encoder (GCE) and the Generative Contextual Fusion (GCF). The GCE comprises three specialized modules: a Personalized Context Enhancer (PCE) for user-specific modeling, a Collective Context Enhancer (CCE) for group-level patterns, and a Dynamic Context Enhancer (DCE) for real-time situational adaptation. The GCF module then seamlessly integrates these contextual representations through low-rank adaptation. Extensive experiments confirm that our method achieves significant gains in critical business metrics, including click-through rate and platform revenue. We have successfully deployed our method on a large-scale food delivery advertising platform, demonstrating its substantial practical impact. This work pioneers a new perspective on generative recommendation and highlights its practical potential in industrial advertising systems.

</details>


### [73] [The Impact of LLM-Generated Reviews on Recommender Systems: Textual Shifts, Performance Effects, and Strategic Platform Control](https://arxiv.org/abs/2601.02362)
*Itzhak Ziv,Moshe Unger,Hilah Geva*

Main category: cs.IR

TL;DR: 研究探讨AI生成评论对推荐系统的影响，发现人类评论质量优于AI评论，人类训练模型能更好泛化到AI内容，平台控制AI评论生成策略对系统性能有重要影响。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的发展，推荐系统越来越多地接触到AI生成内容与人类创作内容并存的情况。本研究旨在探究AI生成评论如何影响推荐系统性能和商业结果，特别是在用户中心和平台中心两种不同引入途径下的影响。

Method: 使用TripAdvisor酒店评论的大规模数据集，利用大型语言模型生成合成评论，评估AI评论在推荐系统训练和部署阶段的影响。分析两种引入途径：用户中心（个人使用AI工具优化评论）和平台中心（平台直接从结构化元数据生成合成评论）。

Result: AI生成评论在多个文本维度上与人类评论存在系统性差异。虽然两种AI评论都能提升推荐系统性能（相对于无文本数据模型），但人类评论训练的模型始终表现更优。人类训练模型能稳健地泛化到AI内容，而AI训练模型在两种内容类型上都表现较差。基于语气的框架策略（鼓励性、建设性或批判性）能显著提升平台生成评论的效果。

Conclusion: 平台控制在管理AI生成评论的生成和整合方面具有战略重要性，确保合成内容能够补充推荐系统的稳健性和可持续商业价值。人类评论的质量优势凸显了真实用户数据的重要性。

Abstract: The rise of generative AI technologies is reshaping content-based recommender systems (RSes), which increasingly encounter AI-generated content alongside human-authored content. This study examines how the introduction of AI-generated reviews influences RS performance and business outcomes. We analyze two distinct pathways through which AI content can enter RSes: user-centric, in which individuals use AI tools to refine their reviews, and platform-centric, in which platforms generate synthetic reviews directly from structured metadata. Using a large-scale dataset of hotel reviews from TripAdvisor, we generate synthetic reviews using LLMs and evaluate their impact across the training and deployment phases of RSes. We find that AI-generated reviews differ systematically from human-authored reviews across multiple textual dimensions. Although both user- and platform-centric AI reviews enhance RS performance relative to models without textual data, models trained on human reviews consistently achieve superior performance, underscoring the quality of authentic human data. Human-trained models generalize robustly to AI content, whereas AI-trained models underperform on both content types. Furthermore, tone-based framing strategies (encouraging, constructive, or critical) substantially enhance platform-generated review effectiveness. Our findings highlight the strategic importance of platform control in governing the generation and integration of AI-generated reviews, ensuring that synthetic content complements recommendation robustness and sustainable business value.

</details>


### [74] [Towards Trustworthy LLM-Based Recommendation via Rationale Integration](https://arxiv.org/abs/2601.02364)
*Chung Park,Taesan Kim,Hyeongjun Yun,Dongjoon Hong,Junui Hong,Kijung Park,MinCheol Cho,Mira Myong,Jihoon Oh,Min sung Choi*

Main category: cs.IR

TL;DR: 本文提出了一种基于大语言模型的推荐系统LLM-Rec，不仅能预测推荐项目，还能生成逻辑合理的推荐理由，通过"理由优先"的指令调优方式提升推荐系统的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统主要关注准确性和短期参与度，忽视了透明度和可信度。虽然亚马逊、Instagram等平台开始提供推荐理由以增强用户信任和参与度，但现有系统大多将推荐理由视为事后补充。因此需要开发既能提供推荐又能生成逻辑合理理由的推荐系统。

Method: 提出LLM-Rec方法：1）利用自标注的理由数据集；2）采用"理由优先"的指令调优格式，模型先生成解释再输出推荐项目；3）使用思维链风格表示理由；4）在亚马逊评论数据集的时尚和科学领域进行实验验证。

Result: 在亚马逊评论数据集的时尚和科学领域实验中，LLM-Rec相比现有基线方法取得了显著改进，既增强了推荐系统的可解释性，又提升了推荐性能。

Conclusion: LLM-Rec通过生成逻辑合理的推荐理由，有效提升了推荐系统的透明度和可信度。公开发布包含用户历史、理由和推荐项目的数据集，以促进可重复性和未来研究。

Abstract: Traditional recommender systems (RS) have been primarily optimized for accuracy and short-term engagement, often overlooking transparency and trustworthiness. Recently, platforms such as Amazon and Instagram have begun providing recommendation rationales to users, acknowledging their critical role in fostering trust and enhancing engagement; however, most existing systems still treat them as post-hoc artifacts. We propose an LLM-based recommender (LLM-Rec) that not only predicts items but also generates logically grounded rationales. Our approach leverages a self-annotated rationale dataset and instruction tuning in a rationale-first format, where the model generates an explanation before outputting the recommended item. By adopting this strategy and representing rationales in a chain-of-thought (CoT) style, LLM-Rec strengthens both interpretability and recommendation performance. Experiments on the Fashion and Scientific domains of the Amazon Review dataset demonstrate significant improvements over well-established baselines. To encourage reproducibility and future research, we publicly release a rationale-augmented recommendation dataset containing user histories, rationales, and recommended items.

</details>


### [75] [TextBridgeGNN: Pre-training Graph Neural Network for Cross-Domain Recommendation via Text-Guided Transfer](https://arxiv.org/abs/2601.02366)
*Yiwen Chen,Yiqing Wu,Huishi Luo,Fuzhen Zhuang,Deqing Wang*

Main category: cs.IR

TL;DR: TextBridgeGNN是一个基于文本语义桥接的图推荐预训练框架，通过文本连接不同领域，实现知识迁移，无需昂贵的语言模型微调


<details>
  <summary>Details</summary>
Motivation: 传统基于ID嵌入的图推荐模型难以跨领域迁移，主要面临两个挑战：1) ID嵌入的非可迁移性（领域间ID空间隔离）；2) 异构交互图之间的结构不兼容。需要构建能够有效跨领域迁移的预训练图推荐模型

Method: 提出TextBridgeGNN框架，使用文本作为语义桥连接不同领域。预训练阶段：利用文本信息打破多领域数据孤岛，设计分层GNN学习领域特定和领域全局知识；微调阶段：提出相似性迁移机制，通过语义相关节点初始化目标领域ID嵌入，实现ID嵌入和图模式的迁移

Result: 实验表明TextBridgeGNN在跨领域、多领域和无训练设置下优于现有方法，能够有效整合预训练语言模型的语义与基于图的协同过滤，无需昂贵的语言模型微调或实时推理开销

Conclusion: TextBridgeGNN成功解决了图推荐模型的跨领域迁移问题，通过文本语义桥接实现了有效的知识迁移，为构建预训练图推荐模型提供了可行方案

Abstract: Graph-based recommendation has achieved great success in recent years. The classical graph recommendation model utilizes ID embedding to store essential collaborative information. However, this ID-based paradigm faces challenges in transferring to a new domain, making it hard to build a pre-trained graph recommendation model. This phenomenon primarily stems from two inherent challenges: (1) the non-transferability of ID embeddings due to isolated domain-specific ID spaces, and (2) structural incompatibility between heterogeneous interaction graphs across domains.
  To address these issues, we propose TextBridgeGNN, a pre-training and fine-tuning framework that can effectively transfer knowledge from a pre-trained GNN to downstream tasks. We believe the key lies in how to build the relationship between domains. Specifically, TextBridgeGNN uses text as a semantic bridge to connect domains through multi-level graph propagation. During the pre-training stage, textual information is utilized to break the data islands formed by multiple domains, and hierarchical GNNs are designed to learn both domain-specific and domain-global knowledge with text features, ensuring the retention of collaborative signals and the enhancement of semantics. During the fine-tuning stage, a similarity transfer mechanism is proposed. This mechanism initializes ID embeddings in the target domain by transferring from semantically related nodes, successfully transferring the ID embeddings and graph pattern.
  Experiments demonstrate that TextBridgeGNN outperforms existing methods in cross-domain, multi-domain, and training-free settings, highlighting its ability to integrate Pre-trained Language Model (PLM)-driven semantics with graph-based collaborative filtering without costly language model fine-tuning or real-time inference overhead.

</details>


### [76] [Improving News Recommendations through Hybrid Sentiment Modelling and Reinforcement Learning](https://arxiv.org/abs/2601.02372)
*Eunice Kingenga,Mike Wa Nkongolo*

Main category: cs.IR

TL;DR: 该研究开发了一个结合混合情感分析和强化学习的自适应情感感知新闻推荐框架，通过情感分类和Q学习优化推荐策略，提升个性化推荐效果。


<details>
  <summary>Details</summary>
Motivation: 传统新闻推荐系统在情感分析方面存在局限性，包括歧义处理、词典不一致和上下文理解不足，特别是在多源新闻环境中。现有模型通常将情感作为次要特征，难以适应用户的情感偏好。

Method: 研究开发了一个自适应情感感知新闻推荐框架，结合混合情感分析（VADER、AFINN、TextBlob和SentiWordNet）和强化学习（Q学习）。使用BBC新闻数据集，将文章分类为积极、消极或中性情感状态，并将这些状态嵌入Q学习架构中学习最优推荐策略。

Result: 结果表明，将混合情感建模与强化学习相结合，为用户中心的新闻推荐提供了一种可行、可解释和自适应的方法。该系统能有效识别和推荐情感匹配的文章，并通过迭代Q学习更新持续改进个性化效果。

Conclusion: 该研究提出的框架通过整合混合情感分析和强化学习，解决了传统新闻推荐系统在情感理解方面的局限性，为情感感知的个性化新闻推荐提供了有效解决方案。

Abstract: News recommendation systems rely on automated sentiment analysis to personalise content and enhance user engagement. Conventional approaches often struggle with ambiguity, lexicon inconsistencies, and limited contextual understanding, particularly in multi-source news environments. Existing models typically treat sentiment as a secondary feature, reducing their ability to adapt to users' affective preferences. To address these limitations, this study develops an adaptive, sentiment-aware news recommendation framework by integrating hybrid sentiment analysis with reinforcement learning. Using the BBC News dataset, a hybrid sentiment model combines VADER, AFINN, TextBlob, and SentiWordNet scores to generate robust article-level sentiment estimates. Articles are categorised as positive, negative, or neutral, and these sentiment states are embedded within a Q-learning architecture to guide the agent in learning optimal recommendation policies. The proposed system effectively identifies and recommends articles with aligned emotional profiles while continuously improving personalisation through iterative Q-learning updates. The results demonstrate that coupling hybrid sentiment modelling with reinforcement learning provides a feasible, interpretable, and adaptive approach for user-centred news recommendation.

</details>


### [77] [A Lay User Explainable Food Recommendation System Based on Hybrid Feature Importance Extraction and Large Language Models](https://arxiv.org/abs/2601.02374)
*Melissa Tessa,Diderot D. Cidjeu,Rachele Carli,Sarah Abchiche,Ahmad Aldarwishd,Igor Tchappi,Amro Najjar*

Main category: cs.IR

TL;DR: 使用LLM为食品推荐系统开发后处理解释方法，结合SHAP提取关键变量，生成动态、可信且全面的解释，提升用户信任和透明度


<details>
  <summary>Details</summary>
Motivation: 大型语言模型近年来发展迅速，应用广泛。食品推荐系统的结果需要更详细的解释来帮助普通用户理解，现有文献中的解释不够充分，需要更动态、可信和全面的解释方法来增强用户信任和系统透明度

Method: 采用后处理过程，结合大型语言模型和SHAP（SHapley Additive exPlanations）混合提取关键变量，为食品推荐系统的结果生成更详细的解释

Result: 相比文献中的现有方法，该方法能为普通用户提供更动态、可信和全面的解释，使复杂的推荐结果更容易理解

Conclusion: 通过结合LLM和SHAP的方法，成功开发出能增强食品推荐系统用户信任和透明度的解释机制，为普通用户提供了更好的理解体验

Abstract: Large Language Models (LLM) have experienced strong development in recent years, with varied applications. This paper uses LLMs to develop a post-hoc process that provides more elaborated explanations of the results of food recommendation systems. By combining LLM with a hybrid extraction of key variables using SHAP, we obtain dynamic, convincing and more comprehensive explanations to lay user, compared to those in the literature. This approach enhances user trust and transparency by making complex recommendation outcomes easier to understand for a lay user.

</details>


### [78] [TAG-HGT: A Scalable and Cost-Effective Framework for Inductive Cold-Start Academic Recommendation](https://arxiv.org/abs/2601.02381)
*Zhexiang Li*

Main category: cs.IR

TL;DR: TAG-HGT是一个神经符号框架，通过"语义优先、结构精炼"的解耦范式，利用冻结的大型语言模型作为离线语义工厂，将知识蒸馏到轻量级异构图Transformer中，解决了学术平台冷启动推荐中生成模型推理延迟高、计算成本大的问题。


<details>
  <summary>Details</summary>
Motivation: 工业学术平台面临冷启动推荐难题，每天有数千名新学者加入但无历史交互记录。现有生成图模型虽然语义能力强，但推理延迟高（每1000个请求超过13分钟）且计算成本巨大，无法部署到实时、百万级规模的实际应用中。

Method: 采用"语义优先、结构精炼"的解耦范式：1) 使用冻结的DeepSeek-V3 LLM作为离线语义工厂；2) 通过跨视图对比学习将LLM知识蒸馏到轻量级异构图Transformer中；3) 结合LLM提供的全局语义召回和结构信号提供的局部区分能力。

Result: 在OpenAlex数据集上，TAG-HGT达到SOTA系统召回率@10为91.97%，比纯结构基线提升20.7%。推理延迟降低5个数量级（从780秒降至1.73毫秒），推理成本从每1000次查询约1.50美元降至低于0.001美元，成本降低99.9%。

Conclusion: TAG-HGT成功解决了生成模型质量与工业可扩展性之间的差距，通过神经符号框架实现了高质量、低延迟、低成本的冷启动学术推荐，使高精度学术推荐民主化。

Abstract: Inductive cold-start recommendation remains the "Achilles' Heel" of industrial academic platforms, where thousands of new scholars join daily without historical interaction records. While recent Generative Graph Models (e.g., HiGPT, OFA) demonstrate promising semantic capabilities, their prohibitive inference latency (often exceeding 13 minutes per 1,000 requests) and massive computational costs render them practically undeployable for real-time, million-scale applications. To bridge this gap between generative quality and industrial scalability, we propose TAG-HGT, a cost-effective neuro-symbolic framework. Adopting a decoupled "Semantics-First, Structure-Refined" paradigm, TAG-HGT utilizes a frozen Large Language Model (DeepSeek-V3) as an offline semantic factory and distills its knowledge into a lightweight Heterogeneous Graph Transformer (HGT) via Cross-View Contrastive Learning (CVCL). We present a key insight: while LLM semantics provide necessary global recall, structural signals offer the critical local discrimination needed to distinguish valid collaborators from semantically similar but socially unreachable strangers in dense embedding spaces. Validated under a strict Time-Machine Protocol on the massive OpenAlex dataset, TAG-HGT achieves a SOTA System Recall@10 of 91.97%, outperforming structure-only baselines by 20.7%. Most significantly, from an industrial perspective, TAG-HGT reduces inference latency by five orders of magnitude ($4.5 \times 10^{5}\times$) compared to generative baselines (from 780s down to 1.73 ms), and slashes inference costs from $\sim$$1.50 to $<$$0.001 per 1k queries. This 99.9% cost reduction democratizes high-precision academic recommendation.

</details>


### [79] [Tree of Preferences for Diversified Recommendation](https://arxiv.org/abs/2601.02386)
*Hanyang Yuan,Ning Tang,Tongya Zheng,Jiarong Xu,Xintong Hu,Renhong Huang,Shunyu Liu,Jiacong Hu,Jiawei Chen,Mingli Song*

Main category: cs.IR

TL;DR: 该研究提出了一种利用大语言模型从数据偏差角度解决推荐系统多样性问题的新方法，通过构建偏好树结构挖掘用户未被充分探索的兴趣偏好，并生成合成交互数据来训练推荐模型。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统主要从观察到的用户反馈中推断用户偏好多样性，但由于数据偏差的存在，观察数据可能无法完全反映用户兴趣，导致未被充分探索的偏好被淹没或未显现，从而造成推荐多样性不足的问题。

Method: 1. 提出偏好树结构，从粗到细建模用户偏好；2. 利用大语言模型的零样本推理能力和世界知识，系统性地分析用户行为背后的逻辑，挖掘未被充分探索的偏好；3. 采用数据为中心的方法，识别匹配用户偏好的候选物品，生成反映未被探索偏好的合成交互；4. 将这些交互整合到通用推荐器中进行训练；5. 通过动态选择有影响力的用户来提升整体效率。

Result: 在多样性和相关性方面的广泛评估表明，该方法在大多数情况下优于现有方法，在其他情况下达到接近最优的性能，并且具有合理的推理延迟。

Conclusion: 该研究从数据偏差角度提出了解决推荐系统多样性问题的新框架，通过大语言模型挖掘用户未被充分探索的偏好，有效提升了推荐的多样性和相关性，为推荐系统研究提供了新的视角和方法。

Abstract: Diversified recommendation has attracted increasing attention from both researchers and practitioners, which can effectively address the homogeneity of recommended items. Existing approaches predominantly aim to infer the diversity of user preferences from observed user feedback. Nonetheless, due to inherent data biases, the observed data may not fully reflect user interests, where underexplored preferences can be overwhelmed or remain unmanifested. Failing to capture these preferences can lead to suboptimal diversity in recommendations. To fill this gap, this work aims to study diversified recommendation from a data-bias perspective. Inspired by the outstanding performance of large language models (LLMs) in zero-shot inference leveraging world knowledge, we propose a novel approach that utilizes LLMs' expertise to uncover underexplored user preferences from observed behavior, ultimately providing diverse and relevant recommendations. To achieve this, we first introduce Tree of Preferences (ToP), an innovative structure constructed to model user preferences from coarse to fine. ToP enables LLMs to systematically reason over the user's rationale behind their behavior, thereby uncovering their underexplored preferences. To guide diversified recommendations using uncovered preferences, we adopt a data-centric approach, identifying candidate items that match user preferences and generating synthetic interactions that reflect underexplored preferences. These interactions are integrated to train a general recommender for diversification. Moreover, we scale up overall efficiency by dynamically selecting influential users during optimization. Extensive evaluations of both diversity and relevance show that our approach outperforms existing methods in most cases and achieves near-optimal performance in others, with reasonable inference latency.

</details>


### [80] [A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance](https://arxiv.org/abs/2601.02428)
*Okan Bursa*

Main category: cs.IR

TL;DR: ARM（自适应RAG记忆）框架用动态记忆基质替代静态向量索引，通过选择性记忆和遗忘机制实现高效检索增强生成，在超高效模型（<2500万参数）中达到最佳效率。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统使用静态向量索引存在效率问题，需要更智能的记忆管理机制来平衡检索质量、延迟和内存效率。

Method: 引入动态记忆基质，基于认知巩固和遗忘原理：频繁检索的项目被巩固保护，很少使用的项目逐渐衰减；实现可配置、运行时可调的嵌入权重，并对无效设置具有鲁棒性。

Result: 在轻量级检索基准测试中，ARM仅用约2200万参数就达到接近SOTA性能（NDCG@5≈0.940，Recall@5=1.000）；Llama 3.1+静态RAG获得最高关键词覆盖率（67.2%），GPT-4o+动态选择性检索策略获得最快响应（平均8.2秒）和竞争性覆盖率（58.7%）。

Conclusion: ARM在保持竞争性准确度的同时，实现了自我调节的记忆增长和可解释的保留动态，无需重新训练生成器，为生产和研究RAG系统提供了质量、延迟和内存效率之间的实用权衡。

Abstract: We introduce \emph{Adaptive RAG Memory} (ARM), a retrieval-augmented generation (RAG) framework that replaces a static vector index with a \emph{dynamic} memory substrate governed by selective remembrance and decay. Frequently retrieved items are consolidated and protected from forgetting, while rarely used items gradually decay, inspired by cognitive consolidation and forgetting principles. On a lightweight retrieval benchmark, ARM reaches near state-of-the-art performance (e.g., NDCG@5 $\approx$ 0.940, Recall@5 $=1.000$) with only $\sim$22M parameters in the embedding layer, achieving the best efficiency among ultra-efficient models ($<$25M parameters). In addition, we compare static vs. dynamic RAG combinations across Llama 3.1 and GPT-4o. Llama 3.1 with static RAG achieves the highest key-term coverage (67.2\%) at moderate latency, while GPT-4o with a dynamic selective retrieval policy attains the fastest responses (8.2s on average) with competitive coverage (58.7\%). We further present an engineering optimization of the DynamicRAG implementation, making embedding weights configurable, adjustable at runtime, and robust to invalid settings.
  ARM yields competitive accuracy, self-regularizing memory growth, and interpretable retention dynamics without retraining the generator\color{black} and provides practical trade-off between quality, latency and memory efficiency for production and research RAG system.

</details>


### [81] [CREAM: Continual Retrieval on Dynamic Streaming Corpora with Adaptive Soft Memory](https://arxiv.org/abs/2601.02708)
*HuiJeong Son,Hyeongu Kang,Sunho Kim,Subeen Ho,SeongKu Kang,Dongha Lee,Susik Yoon*

Main category: cs.IR

TL;DR: CREAM是一个用于动态数据流信息检索的自监督持续学习框架，通过软记忆结构处理数据分布漂移，在无标签情况下实现对新主题的适应。


<details>
  <summary>Details</summary>
Motivation: 动态数据流中的信息检索面临数据分布漂移的挑战，现有基于记忆的持续学习方法依赖于固定查询集和真实相关文档，限制了向未见查询和文档的泛化能力，不适用于实际应用。

Method: 提出CREAM自监督框架，通过细粒度相似度估计、正则化聚类原型和分层核心集采样三种关键技术，将流式查询和文档的演化语义捕获到动态结构化的软记忆中。

Result: 在两个基准数据集上的实验表明，CREAM在无标签设置下表现出优越的适应性和检索准确性，在Success@5和Recall@10指标上平均超过最强方法27.79%和44.5%，性能与监督方法相当甚至更优。

Conclusion: CREAM框架能够在没有真实标签的情况下有效学习新语料库的未见主题，通过自监督方式实现动态数据流中的持续信息检索，具有实际应用价值。

Abstract: Information retrieval (IR) in dynamic data streams is emerging as a challenging task, as shifts in data distribution degrade the performance of AI-powered IR systems. To mitigate this issue, memory-based continual learning has been widely adopted for IR. However, existing methods rely on a fixed set of queries with ground-truth relevant documents, which limits generalization to unseen queries and documents, making them impractical for real-world applications. To enable more effective learning with unseen topics of a new corpus without ground-truth labels, we propose CREAM, a self-supervised framework for memory-based continual retrieval. CREAM captures the evolving semantics of streaming queries and documents into dynamically structured soft memory and leverages it to adapt to both seen and unseen topics in an unsupervised setting. We realize this through three key techniques: fine-grained similarity estimation, regularized cluster prototyping, and stratified coreset sampling. Experiments on two benchmark datasets demonstrate that CREAM exhibits superior adaptability and retrieval accuracy, outperforming the strongest method in a label-free setting by 27.79\% in Success@5 and 44.5\% in Recall@10 on average, and achieving performance comparable to or even exceeding that of supervised methods.

</details>


### [82] [Ahead of the Spread: Agent-Driven Virtual Propagation for Early Fake News Detection](https://arxiv.org/abs/2601.02750)
*Bincheng Gu,Min Gao,Junliang Yu,Zongwei Wang,Zhiyi Liu,Kai Shu,Hongyu Zhang*

Main category: cs.IR

TL;DR: AVOID提出了一种基于智能体驱动的虚拟传播方法，用于早期假新闻检测，通过模拟传播信号而非依赖实际观察到的传播数据来增强检测性能。


<details>
  <summary>Details</summary>
Motivation: 早期假新闻检测面临的主要挑战是在传播早期阶段缺乏可观察的传播信号。传统方法依赖内容分析或实际传播动态，但在早期阶段这些信号尚未形成，导致检测性能受限。

Method: AVOID将早期检测重新定义为证据生成的新范式，使用具有差异化角色和数据驱动人设的LLM智能体来主动模拟早期传播行为，无需真实传播数据。通过去噪引导的融合策略将模拟传播与内容语义对齐。

Result: 在基准数据集上的广泛实验表明，AVOID持续优于最先进的基线方法，验证了虚拟传播增强对早期假新闻检测的有效性和实用价值。

Conclusion: AVOID通过智能体驱动的虚拟传播方法，成功解决了早期假新闻检测中缺乏传播信号的问题，为早期检测提供了新的有效范式，具有重要的实际应用价值。

Abstract: Early detection of fake news is critical for mitigating its rapid dissemination on social media, which can severely undermine public trust and social stability. Recent advancements show that incorporating propagation dynamics can significantly enhance detection performance compared to previous content-only approaches. However, this remains challenging at early stages due to the absence of observable propagation signals. To address this limitation, we propose AVOID, an \underline{a}gent-driven \underline{v}irtual pr\underline{o}pagat\underline{i}on for early fake news \underline{d}etection. AVOID reformulates early detection as a new paradigm of evidence generation, where propagation signals are actively simulated rather than passively observed. Leveraging LLM-powered agents with differentiated roles and data-driven personas, AVOID realistically constructs early-stage diffusion behaviors without requiring real propagation data. The resulting virtual trajectories provide complementary social evidence that enriches content-based detection, while a denoising-guided fusion strategy aligns simulated propagation with content semantics. Extensive experiments on benchmark datasets demonstrate that AVOID consistently outperforms state-of-the-art baselines, highlighting the effectiveness and practical value of virtual propagation augmentation for early fake news detection. The code and data are available at https://github.com/Ironychen/AVOID.

</details>


### [83] [Netflix Artwork Personalization via LLM Post-training](https://arxiv.org/abs/2601.02764)
*Hyunji Nam,Sejoon Oh,Emma Kong,Yesu Feng,Moumita Bhattacharya*

Main category: cs.IR

TL;DR: 该论文探索使用大语言模型进行个性化艺术作品推荐，针对Netflix等娱乐平台用户的不同偏好，为同一标题选择最符合用户口味的视觉呈现，相比现有生产模型提升3-5%


<details>
  <summary>Details</summary>
Motivation: 娱乐平台用户偏好多样，同一标题的不同艺术作品（如强调家庭温情或激烈动作场景）对不同用户吸引力不同。现有的一刀切推荐方式无法满足个性化需求，需要根据用户偏好推荐最合适的视觉呈现。

Method: 对预训练的大语言模型（Llama 3.1 8B）进行后训练，使用11万数据点训练，在5千个保留的用户-标题对上评估，实现个性化艺术作品推荐。

Result: 后训练的LLMs相比Netflix生产模型取得了3-5%的改进，表明使用LLMs进行细粒度个性化推荐是一个有前景的方向。

Conclusion: 大语言模型能够有效实现个性化艺术作品推荐，根据用户偏好为同一标题选择最合适的视觉呈现，提高用户满意度和参与度。

Abstract: Large language models (LLMs) have demonstrated success in various applications of user recommendation and personalization across e-commerce and entertainment. On many entertainment platforms such as Netflix, users typically interact with a wide range of titles, each represented by an artwork. Since users have diverse preferences, an artwork that appeals to one type of user may not resonate with another with different preferences. Given this user heterogeneity, our work explores the novel problem of personalized artwork recommendations according to diverse user preferences. Similar to the multi-dimensional nature of users' tastes, titles contain different themes and tones that may appeal to different viewers. For example, the same title might feature both heartfelt family drama and intense action scenes. Users who prefer romantic content may like the artwork emphasizing emotional warmth between the characters, while those who prefer action thrillers may find high-intensity action scenes more intriguing. Rather than a one-size-fits-all approach, we conduct post-training of pre-trained LLMs to make personalized artwork recommendations, selecting the most preferred visual representation of a title for each user and thereby improving user satisfaction and engagement. Our experimental results with Llama 3.1 8B models (trained on a dataset of 110K data points and evaluated on 5K held-out user-title pairs) show that the post-trained LLMs achieve 3-5\% improvements over the Netflix production model, suggesting a promising direction for granular personalized recommendations using LLMs.

</details>


### [84] [COFFEE: COdesign Framework for Feature Enriched Embeddings in Ads-Ranking Systems](https://arxiv.org/abs/2601.02807)
*Sohini Roychowdhury,Doris Wang,Qian Ge,Joy Mu,Srihari Reddy*

Main category: cs.IR

TL;DR: 本文提出了一种三维框架来增强用户-广告表示，通过整合多源事件、延长用户历史、丰富事件属性，在不增加模型推理复杂度的情况下显著提升广告推荐效果。


<details>
  <summary>Details</summary>
Motivation: 商业广告推荐模型需要多样化和丰富的数据源来准确评估用户兴趣，特别是在用户与内容互动前后。虽然扩展的用户参与历史可以改善用户兴趣预测，但同样重要的是嵌入来自多个来源的活动序列，以确保用户和广告表示的新鲜度，遵循扩展法则原则。

Method: 提出一个新颖的三维框架：第一维度研究整合不同事件源的影响；第二维度考虑更长用户历史的好处；第三维度专注于通过额外事件属性和多模态嵌入来丰富数据。通过比较有机用户参与源（如内容浏览）与广告展示源来评估投资回报率。

Result: 该方法可以将广告展示源的AUC和扩展曲线斜率提升1.56到2倍，即使在线序列长度仅为100到10K。使用丰富的广告展示事件源时，点击率预测的AUC比基线生产广告推荐系统提高了0.56%，为更长和离线的用户-广告表示提供了改进的序列扩展分辨率。

Conclusion: 提出的三维源丰富框架能够有效增强用户-广告表示，在不增加模型推理或服务复杂度的情况下显著提升广告推荐性能，特别是在利用广告展示事件源时表现出更好的投资回报率。

Abstract: Diverse and enriched data sources are essential for commercial ads-recommendation models to accurately assess user interest both before and after engagement with content. While extended user-engagement histories can improve the prediction of user interests, it is equally important to embed activity sequences from multiple sources to ensure freshness of user and ad-representations, following scaling law principles. In this paper, we present a novel three-dimensional framework for enhancing user-ad representations without increasing model inference or serving complexity. The first dimension examines the impact of incorporating diverse event sources, the second considers the benefits of longer user histories, and the third focuses on enriching data with additional event attributes and multi-modal embeddings. We assess the return on investment (ROI) of our source enrichment framework by comparing organic user engagement sources, such as content viewing, with ad-impression sources. The proposed method can boost the area under curve (AUC) and the slope of scaling curves for ad-impression sources by 1.56 to 2 times compared to organic usage sources even for short online-sequence lengths of 100 to 10K. Additionally, click-through rate (CTR) prediction improves by 0.56% AUC over the baseline production ad-recommendation system when using enriched ad-impression event sources, leading to improved sequence scaling resolutions for longer and offline user-ad representations.

</details>


### [85] [HarmonRank: Ranking-aligned Multi-objective Ensemble for Live-streaming E-commerce Recommendation](https://arxiv.org/abs/2601.02955)
*Boyang Xia,Zhou Yu,Zhiliang Zhu,Hanxiao Sun,Biyun Han,Jun Wang,Runnan Liu,Wenwu Ou*

Main category: cs.IR

TL;DR: 本文提出HarmonRank框架，解决直播电商推荐中多目标排序的挑战，通过排名任务对齐和跨目标对齐优化，在快手平台实现显著效果提升


<details>
  <summary>Details</summary>
Motivation: 直播电商推荐与传统电商不同，需要平衡购买和用户-主播互动等多目标。现有集成模型使用多个独立的二元分类损失，存在两个固有局限：1）二元分类任务的优化方向与排序任务（以AUC评估）不一致；2）忽视了目标间的对齐关系（如评论和购买行为的部分依赖性）

Method: 提出HarmonRank多目标集成框架：1）针对排名任务对齐，将排序指标AUC表述为秩和问题，利用可微分排序技术进行面向排序的优化；2）针对跨目标对齐，将原始的一步集成范式改为两步关系感知集成方案

Result: 在两个工业数据集上的离线实验和在线实验表明，该方法显著优于现有最先进方法。该方法已在快手直播电商推荐平台（4亿日活用户）全面部署，贡献超过2%的购买增益

Conclusion: HarmonRank框架通过同时实现排名任务对齐和跨目标对齐，有效解决了直播电商推荐中的多目标排序问题，在实际工业应用中取得了显著效果

Abstract: Recommendation for live-streaming e-commerce is gaining increasing attention due to the explosive growth of the live streaming economy. Different from traditional e-commerce, live-streaming e-commerce shifts the focus from products to streamers, which requires ranking mechanism to balance both purchases and user-streamer interactions for long-term ecology. To trade off multiple objectives, a popular solution is to build an ensemble model to integrate multi-objective scores into a unified score. The ensemble model is usually supervised by multiple independent binary classification losses of all objectives. However, this paradigm suffers from two inherent limitations. First, the optimization direction of the binary classification task is misaligned with the ranking task (evaluated by AUC). Second, this paradigm overlooks the alignment between objectives, e.g., comment and buy behaviors are partially dependent which can be revealed in labels correlations. The model can achieve better trade-offs if it learns the aligned parts of ranking abilities among different objectives.
  To mitigate these limitations, we propose a novel multi-objective ensemble framework HarmonRank to fulfill both alignment to the ranking task and alignment among objectives. For alignment to ranking, we formulate ranking metric AUC as a rank-sum problem and utilize differentiable ranking techniques for ranking-oriented optimization. For inter-objective alignment, we change the original one-step ensemble paradigm to a two-step relation-aware ensemble scheme.
  Extensive offline experiments results on two industrial datasets and online experiments demonstrate that our approach significantly outperforms existing state-of-the-art methods. The proposed method has been fully deployed in Kuaishou's live-streaming e-commerce recommendation platform with 400 million DAUs, contributing over 2% purchase gain.

</details>


### [86] [Auditing Search Query Suggestion Bias Through Recursive Algorithm Interrogation](https://arxiv.org/abs/2601.02962)
*Fabian Haak,Philipp Schaer*

Main category: cs.IR

TL;DR: 本文提出了一种新的搜索查询建议偏见识别方法，通过递归算法询问技术创建建议树，访问更多潜意识的搜索建议，以解决现有方法数据基础有限的问题。


<details>
  <summary>Details</summary>
Motivation: 搜索查询建议在在线信息搜索中扮演重要角色，但相关研究较少。主要问题在于上下文稀疏性和数据基础有限（每个查询最多10个建议），这给识别搜索查询建议中的偏见带来了困难。

Method: 采用递归算法询问技术，创建搜索建议树，从而访问更多潜意识的搜索查询建议。这种方法扩展了偏见分析的数据基础，超越了传统方法仅考虑同一查询随时间变化的后续搜索建议。

Result: 基于新方法获取的搜索建议，研究了政治领域人物相关搜索中的主题群体偏见。

Conclusion: 提出的新方法通过递归算法询问和创建建议树，能够访问更多潜意识的搜索查询建议，为搜索查询建议的偏见分析提供了更深入的数据基础，有助于更有效地识别搜索建议中的偏见。

Abstract: Despite their important role in online information search, search query suggestions have not been researched as much as most other aspects of search engines. Although reasons for this are multi-faceted, the sparseness of context and the limited data basis of up to ten suggestions per search query pose the most significant problem in identifying bias in search query suggestions. The most proven method to reduce sparseness and improve the validity of bias identification of search query suggestions so far is to consider suggestions from subsequent searches over time for the same query. This work presents a new, alternative approach to search query bias identification that includes less high-level suggestions to deepen the data basis of bias analyses. We employ recursive algorithm interrogation techniques and create suggestion trees that enable access to more subliminal search query suggestions. Based on these suggestions, we investigate topical group bias in person-related searches in the political domain.

</details>


### [87] [Parallel Latent Reasoning for Sequential Recommendation](https://arxiv.org/abs/2601.03153)
*Jiakai Tang,Xu Chen,Wen Chen,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: PLR提出并行潜在推理框架，通过同时探索多个不同推理轨迹来解决序列推荐中稀疏行为序列的复杂用户偏好捕获问题，突破了传统深度级扩展的限制。


<details>
  <summary>Details</summary>
Motivation: 当前基于潜在推理的方法仅依赖单一轨迹的深度级扩展，随着推理深度增加会出现收益递减问题，无法有效捕获复杂用户偏好。

Method: PLR框架通过三个核心组件实现：1) 在连续潜在空间中使用可学习的触发令牌构建并行推理流；2) 通过全局推理正则化保持流间多样性；3) 通过混合推理流聚合自适应合成多流输出。

Result: 在三个真实世界数据集上的实验表明，PLR显著优于现有最先进基线方法，同时保持实时推理效率。理论分析进一步验证了并行推理在提升泛化能力方面的有效性。

Conclusion: PLR为序列推荐中的推理能力增强开辟了新途径，超越了现有的深度扩展方法，通过宽度级计算扩展实现了更有效的复杂用户偏好建模。

Abstract: Capturing complex user preferences from sparse behavioral sequences remains a fundamental challenge in sequential recommendation. Recent latent reasoning methods have shown promise by extending test-time computation through multi-step reasoning, yet they exclusively rely on depth-level scaling along a single trajectory, suffering from diminishing returns as reasoning depth increases. To address this limitation, we propose \textbf{Parallel Latent Reasoning (PLR)}, a novel framework that pioneers width-level computational scaling by exploring multiple diverse reasoning trajectories simultaneously. PLR constructs parallel reasoning streams through learnable trigger tokens in continuous latent space, preserves diversity across streams via global reasoning regularization, and adaptively synthesizes multi-stream outputs through mixture-of-reasoning-streams aggregation. Extensive experiments on three real-world datasets demonstrate that PLR substantially outperforms state-of-the-art baselines while maintaining real-time inference efficiency. Theoretical analysis further validates the effectiveness of parallel reasoning in improving generalization capability. Our work opens new avenues for enhancing reasoning capacity in sequential recommendation beyond existing depth scaling.

</details>


### [88] [Fine-tuning Small Language Models as Efficient Enterprise Search Relevance Labelers](https://arxiv.org/abs/2601.03211)
*Yue Kang,Zhuoyi Huang,Benji Schussheim,Diana Licon,Dina Atia,Shixing Cao,Jacob Danovitch,Kunho Kim,Billy Norcilien,Jonah Karpman,Mahmound Sayed,Mike Taylor,Tao Sun,Pavel Metrikov,Vipul Agarwal,Chris Quirk,Ye-Yi Wang,Nick Craswell,Irene Shaffer,Tianwei Chen,Sulaiman Vesal,Soundar Srinivasan*

Main category: cs.IR

TL;DR: 该论文提出了一种高效方法，通过合成数据生成和知识蒸馏，将小型语言模型微调为企业搜索中的相关性标注器，在保持质量的同时大幅提升吞吐量和成本效益。


<details>
  <summary>Details</summary>
Motivation: 企业搜索中构建高质量数据集面临核心挑战，因为获取标注数据困难。现有方法依赖大型语言模型进行相关性标注，但成本高、吞吐量低，难以满足企业级应用的大规模需求。

Method: 1. 使用LLM从种子文档合成真实的企业查询；2. 应用BM25检索困难负样本；3. 使用教师LLM分配相关性分数；4. 将生成的数据集蒸馏到小型语言模型中，创建紧凑的相关性标注器。

Result: 在923个企业查询-文档对的人工标注基准测试中，蒸馏后的小型语言模型与人类判断的一致性达到或超过了教师LLM。同时，吞吐量提高了17倍，成本效益提升了19倍。

Conclusion: 该方法实现了可扩展且成本效益高的企业级相关性标注，支持实际场景中的快速离线评估和迭代，为企业搜索应用提供了实用的解决方案。

Abstract: In enterprise search, building high-quality datasets at scale remains a central challenge due to the difficulty of acquiring labeled data. To resolve this challenge, we propose an efficient approach to fine-tune small language models (SLMs) for accurate relevance labeling, enabling high-throughput, domain-specific labeling comparable or even better in quality to that of state-of-the-art large language models (LLMs). To overcome the lack of high-quality and accessible datasets in the enterprise domain, our method leverages on synthetic data generation. Specifically, we employ an LLM to synthesize realistic enterprise queries from a seed document, apply BM25 to retrieve hard negatives, and use a teacher LLM to assign relevance scores. The resulting dataset is then distilled into an SLM, producing a compact relevance labeler. We evaluate our approach on a high-quality benchmark consisting of 923 enterprise query-document pairs annotated by trained human annotators, and show that the distilled SLM achieves agreement with human judgments on par with or better than the teacher LLM. Furthermore, our fine-tuned labeler substantially improves throughput, achieving 17 times increase while also being 19 times more cost-effective. This approach enables scalable and cost-effective relevance labeling for enterprise-scale retrieval applications, supporting rapid offline evaluation and iteration in real-world settings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [89] [Textual Explanations and Their Evaluations for Reinforcement Learning Policy](https://arxiv.org/abs/2601.02514)
*Ahmad Terra,Mohit Ahmed,Rafia Inam,Elena Fersman,Martin Törngren*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的可解释强化学习框架，通过LLM生成文本解释并转换为透明规则，结合专家知识和自动谓词生成器提高解释质量，在开源环境和电信用例中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然文本解释易于人类理解，但确保其正确性仍然是一个挑战，现有评估方法有限。需要一种系统方法来生成、改进和评估强化学习策略的文本解释。

Method: 提出一个XRL框架：1) 使用大型语言模型生成文本解释；2) 通过聚类技术识别频繁条件；3) 将条件转换为透明规则；4) 提出两种精炼技术改进解释质量；5) 结合专家知识和自动谓词生成器确定状态语义信息。

Result: 在三个开源环境和电信用例中进行实验，生成的透明规则在某些任务上能达到满意性能，改进了现有自主策略解释方法的局限性，实现了文本解释的系统化定量评估。

Conclusion: 该框架为XRL领域提供了有价值的见解，能够系统地生成、改进和评估文本解释，解决了现有方法的局限性，并在工业应用中展示了实用性。

Abstract: Understanding a Reinforcement Learning (RL) policy is crucial for ensuring that autonomous agents behave according to human expectations. This goal can be achieved using Explainable Reinforcement Learning (XRL) techniques. Although textual explanations are easily understood by humans, ensuring their correctness remains a challenge, and evaluations in state-of-the-art remain limited. We present a novel XRL framework for generating textual explanations, converting them into a set of transparent rules, improving their quality, and evaluating them. Expert's knowledge can be incorporated into this framework, and an automatic predicate generator is also proposed to determine the semantic information of a state. Textual explanations are generated using a Large Language Model (LLM) and a clustering technique to identify frequent conditions. These conditions are then converted into rules to evaluate their properties, fidelity, and performance in the deployed environment. Two refinement techniques are proposed to improve the quality of explanations and reduce conflicting information. Experiments were conducted in three open-source environments to enable reproducibility, and in a telecom use case to evaluate the industrial applicability of the proposed XRL framework. This framework addresses the limitations of an existing method, Autonomous Policy Explanation, and the generated transparent rules can achieve satisfactory performance on certain tasks. This framework also enables a systematic and quantitative evaluation of textual explanations, providing valuable insights for the XRL field.

</details>


### [90] [An Empirical Study of On-Device Translation for Real-Time Live-Stream Chat on Mobile Devices](https://arxiv.org/abs/2601.02641)
*Jeiyoon Park,Daehwan Lee,Changmin Yeo,Yongshin Han,Minseop Kim*

Main category: cs.AI

TL;DR: 该论文研究了设备端AI模型在实际部署中的关键问题，包括模型选择、资源消耗和领域适应能力，通过构建LiveChatBench基准测试在移动设备上进行实验。


<details>
  <summary>Details</summary>
Motivation: 尽管设备端AI模型效率高，但缺乏对其实际部署方面的研究，如设备CPU利用率和热条件等实际问题，需要解决这些关键问题才能在实际服务中部署设备端模型。

Method: 通过大量实验研究两个关键问题：1) 设备端模型选择及各模型的资源消耗；2) 设备端模型的领域适应能力和潜力。构建了LiveChatBench基准测试，包含1,000个韩英平行句对，在5个移动设备上进行实验。

Result: 实验表明，虽然服务大规模异质用户群需要考虑高度受限的部署环境和模型选择，但所提出的方法在针对性任务上达到了与GPT-5.1等商业模型相当的性能。

Conclusion: 研究结果为设备端AI社区提供了有意义的见解，表明设备端模型在实际部署中具有可行性，特别是在特定领域任务上可以达到商业模型的性能水平。

Abstract: Despite its efficiency, there has been little research on the practical aspects required for real-world deployment of on-device AI models, such as the device's CPU utilization and thermal conditions. In this paper, through extensive experiments, we investigate two key issues that must be addressed to deploy on-device models in real-world services: (i) the selection of on-device models and the resource consumption of each model, and (ii) the capability and potential of on-device models for domain adaptation. To this end, we focus on a task of translating live-stream chat messages and manually construct LiveChatBench, a benchmark consisting of 1,000 Korean-English parallel sentence pairs. Experiments on five mobile devices demonstrate that, although serving a large and heterogeneous user base requires careful consideration of highly constrained deployment settings and model selection, the proposed approach nevertheless achieves performance comparable to commercial models such as GPT-5.1 on the well-targeted task. We expect that our findings will provide meaningful insights to the on-device AI community.

</details>


### [91] [Learning from Prompt itself: the Hierarchical Attribution Prompt Optimization](https://arxiv.org/abs/2601.02683)
*Dongyu Chen,Jian Ma,Xianpeng Zhang,Lei Zhang,Haonan Lu,Chen Chen,Chuangchuang Wang,Kai Tang*

Main category: cs.AI

TL;DR: HAPO框架通过分层归因机制解决提示优化中的提示漂移问题，使用语义单元优化保持可解释性，支持多模态工作流，在图像QA和复杂任务分析中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前提示优化方法存在两个主要问题：1）提示漂移 - 新提示修复先前失败但损害先前成功任务的性能；2）从头生成提示会损害可解释性。需要一种既能高效优化又能保持可解释性的方法。

Method: 提出分层归因提示优化（HAPO）框架，包含三个创新：1）动态归因机制，针对训练数据和提示历史中的错误模式；2）语义单元优化，编辑功能性提示片段；3）多模态友好进展，支持端到端LLM和LLM-MLLM工作流。

Result: 在单/多图像QA（如OCRV2）和复杂任务分析（如BBH）等场景中，HAPO展示了增强的优化效率，优于可比较的自动提示优化方法，为可扩展的提示工程建立了可扩展范式。

Conclusion: HAPO框架通过分层归因和语义单元优化，有效解决了提示漂移和可解释性问题，为可扩展的提示工程提供了有效解决方案，支持多模态应用场景。

Abstract: Optimization is fundamental across numerous disciplines, typically following an iterative process of refining an initial solution to enhance performance. This principle is equally critical in prompt engineering, where designing effective prompts for large language models constitutes a complex optimization challenge. A structured optimization approach requires automated or semi-automated procedures to develop improved prompts, thereby reducing manual effort, improving performance, and yielding an interpretable process. However, current prompt optimization methods often induce prompt drift, where new prompts fix prior failures but impair performance on previously successful tasks. Additionally, generating prompts from scratch can compromise interpretability. To address these limitations, this study proposes the Hierarchical Attribution Prompt Optimization (HAPO) framework, which introduces three innovations: (1) a dynamic attribution mechanism targeting error patterns in training data and prompting history, (2) semantic-unit optimization for editing functional prompt segments, and (3) multimodal-friendly progression supporting both end-to-end LLM and LLM-MLLM workflows. Applied in contexts like single/multi-image QA (e.g., OCRV2) and complex task analysis (e.g., BBH), HAPO demonstrates enhanced optimization efficiency, outperforming comparable automated prompt optimization methods and establishing an extensible paradigm for scalable prompt engineering.

</details>


### [92] [Learning User Preferences Through Interaction for Long-Term Collaboration](https://arxiv.org/abs/2601.02702)
*Shuhaib Mehri,Priyanka Kargupta,Tal August,Dilek Hakkani-Tür*

Main category: cs.AI

TL;DR: MultiSessionCollab基准测试评估智能体在多轮会话中学习用户偏好并提升协作质量的能力，通过配备记忆机制和从用户模拟器行为中学习，显著提高了任务成功率、交互效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 随着对话智能体与用户协作经验的积累，适应用户偏好对于建立长期关系和提升协作质量至关重要。需要评估智能体如何学习用户偏好并在多轮会话中利用这些偏好来改善协作。

Method: 提出了MultiSessionCollab基准测试，并开发了配备持久记忆机制的长时期协作智能体，该记忆随着交互经验的积累而不断细化和更新用户偏好。从用户模拟器行为中提取学习信号，训练智能体生成更全面的反思并更有效地更新记忆。

Result: 实验表明，配备记忆的智能体显著提升了长期协作效果：任务成功率更高、交互效率更优、用户努力程度降低。人类用户研究进一步证实，记忆机制在实际场景中改善了用户体验。

Conclusion: 记忆机制对于对话智能体在多轮会话中学习用户偏好、提升协作质量和用户体验至关重要。MultiSessionCollab基准测试为评估和训练这类长期协作智能体提供了有效框架。

Abstract: As conversational agents accumulate experience collaborating with users, adapting to user preferences is essential for fostering long-term relationships and improving collaboration quality over time. We introduce MultiSessionCollab, a benchmark that evaluates how well agents can learn user preferences and leverage them to improve collaboration quality throughout multiple sessions. To develop agents that succeed in this setting, we present long-term collaborative agents equipped with a memory that persists and refines user preference as interaction experience accumulates. Moreover, we demonstrate that learning signals can be derived from user simulator behavior in MultiSessionCollab to train agents to generate more comprehensive reflections and update their memory more effectively. Extensive experiments show that equipping agents with memory improves long-term collaboration, yielding higher task success rates, more efficient interactions, and reduced user effort. Finally, we conduct a human user study that demonstrates that memory helps improve user experience in real-world settings.

</details>


### [93] [Time-Scaling Is What Agents Need Now](https://arxiv.org/abs/2601.02714)
*Zhi Liu,Guangzhi Wang*

Main category: cs.AI

TL;DR: 该论文提出"时间扩展"概念，强调通过系统扩展和优化智能体在时间维度上的推理能力，实现更深层次的问题空间探索和动态策略调整，而不需要按比例增加静态模型参数。


<details>
  <summary>Details</summary>
Motivation: 早期人工智能范式存在认知功能分离问题，而当前大型语言模型虽然能生成流畅文本，但缺乏稳健的语义推理能力。现有推理增强方法如思维链和思维树在搜索完整性和效率方面存在局限，需要新的方法来提升深度推理和问题解决能力。

Method: 提出"时间扩展"架构设计，利用扩展的时间路径实现：1）更深层次的问题空间探索；2）动态策略调整；3）增强的元认知控制。这种方法通过系统扩展智能体在时间维度上展开推理的能力，模拟人类在认知约束下的顺序推理过程。

Result: 时间扩展代表了增强深度推理和问题解决能力的关键前沿，能够在不按比例增加静态模型参数的情况下，实现更强大的认知能力。这种方法为构建具有闭环"感知-决策-行动"能力的认知智能体提供了理论基础。

Conclusion: 推进智能体能力需要将时间扩展原则置于前沿位置，将显式时间推理管理作为基础。这是实现人工智能范式融合和构建更强大认知系统的关键方向。

Abstract: Early artificial intelligence paradigms exhibited separated cognitive functions: Neural Networks focused on "perception-representation," Reinforcement Learning on "decision-making-behavior," and Symbolic AI on "knowledge-reasoning." With Transformer-based large models and world models, these paradigms are converging into cognitive agents with closed-loop "perception-decision-action" capabilities.
  Humans solve complex problems under limited cognitive resources through temporalized sequential reasoning. Language relies on problem space search for deep semantic reasoning. While early large language models (LLMs) could generate fluent text, they lacked robust semantic reasoning capabilities. Prompting techniques like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) extended reasoning paths by making intermediate steps explicit. Recent models like DeepSeek-R1 enhanced performance through explicit reasoning trajectories. However, these methods have limitations in search completeness and efficiency.
  This highlights the need for "Time-Scaling"--the systematic extension and optimization of an agent's ability to unfold reasoning over time. Time-Scaling refers to architectural design utilizing extended temporal pathways, enabling deeper problem space exploration, dynamic strategy adjustment, and enhanced metacognitive control, paralleling human sequential reasoning under cognitive constraints. It represents a critical frontier for enhancing deep reasoning and problem-solving without proportional increases in static model parameters. Advancing intelligent agent capabilities requires placing Time-Scaling principles at the forefront, positioning explicit temporal reasoning management as foundational.

</details>


### [94] [The Path Ahead for Agentic AI: Challenges and Opportunities](https://arxiv.org/abs/2601.02749)
*Nadia Sibai,Yara Ahmed,Serry Sibaee,Sawsan AlHalawani,Adel Ammar,Wadii Boulila*

Main category: cs.AI

TL;DR: 该章节探讨了大型语言模型从被动文本生成器向自主智能体的演进，分析了实现自主行为所需的核心组件，并指出了当前面临的技术挑战和研究重点。


<details>
  <summary>Details</summary>
Motivation: 研究LLM从被动语言模型向自主智能系统转变的动机在于探索人工智能发展的根本性转变，理解如何将语言理解能力转化为自主行动能力，并为构建安全可靠的自主AI系统提供理论框架。

Method: 通过分析LLM架构从统计模型到基于Transformer系统的演进过程，识别出实现自主行为所需的关键能力：长程推理、上下文感知和自适应决策。提出了一个集成框架，包含感知、记忆、规划和工具执行等核心组件。

Result: 提出了三个主要贡献：1) 分析了LLM能力如何通过推理-行动-反思循环向自主性扩展；2) 建立了连接LLM与自主行为的集成框架；3) 批判性评估了应用领域及在安全性、对齐性、可靠性和可持续性方面的持续挑战。

Conclusion: 从语言理解到自主行动的架构转变需要解决关键技术差距，包括可验证规划、可扩展的多智能体协调、持久记忆架构和治理框架。负责任的发展需要在技术稳健性、可解释性和伦理保障方面同时取得进展。

Abstract: The evolution of Large Language Models (LLMs) from passive text generators to autonomous, goal-driven systems represents a fundamental shift in artificial intelligence. This chapter examines the emergence of agentic AI systems that integrate planning, memory, tool use, and iterative reasoning to operate autonomously in complex environments. We trace the architectural progression from statistical models to transformer-based systems, identifying capabilities that enable agentic behavior: long-range reasoning, contextual awareness, and adaptive decision-making. The chapter provides three contributions: (1) a synthesis of how LLM capabilities extend toward agency through reasoning-action-reflection loops; (2) an integrative framework describing core components perception, memory, planning, and tool execution that bridge LLMs with autonomous behavior; (3) a critical assessment of applications and persistent challenges in safety, alignment, reliability, and sustainability. Unlike existing surveys, we focus on the architectural transition from language understanding to autonomous action, emphasizing the technical gaps that must be resolved before deployment. We identify critical research priorities, including verifiable planning, scalable multi-agent coordination, persistent memory architectures, and governance frameworks. Responsible advancement requires simultaneous progress in technical robustness, interpretability, and ethical safeguards to realize potential while mitigating risks of misalignment and unintended consequences.

</details>


### [95] [LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery](https://arxiv.org/abs/2601.02757)
*Zixuan Xiao,Jun Ma*

Main category: cs.AI

TL;DR: ChangeGPT是一个基于大语言模型和视觉基础模型的通用智能体框架，用于遥感变化检测，通过分层结构减少幻觉，在140个问题数据集上达到90.71%的匹配率，并在深圳前海湾实际案例中验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 现有变化检测方法缺乏处理多样化真实世界查询的灵活性和进行全面分析的智能性，需要更通用、智能的解决方案来支持遥感应用中的决策制定。

Method: 提出了ChangeGPT框架，将大语言模型与视觉基础模型集成，采用分层结构来缓解幻觉问题，通过智能体进行工具选择和推理，支持多步骤分析和多种问题类型。

Result: 在包含140个问题的数据集上评估，ChangeGPT（特别是使用GPT-4-turbo后端）在工具选择精度/召回率和整体查询准确率方面表现优异，达到90.71%的匹配率，特别擅长需要多步推理的变化相关查询。

Conclusion: ChangeGPT通过提供智能性、适应性和多类型变化分析能力，为遥感应用中的决策制定提供了强大的解决方案，在实际城市变化监测案例中验证了其有效性。

Abstract: Existing change detection methods often lack the versatility to handle diverse real-world queries and the intelligence for comprehensive analysis. This paper presents a general agent framework, integrating Large Language Models (LLM) with vision foundation models to form ChangeGPT. A hierarchical structure is employed to mitigate hallucination. The agent was evaluated on a curated dataset of 140 questions categorized by real-world scenarios, encompassing various question types (e.g., Size, Class, Number) and complexities. The evaluation assessed the agent's tool selection ability (Precision/Recall) and overall query accuracy (Match). ChangeGPT, especially with a GPT-4-turbo backend, demonstrated superior performance, achieving a 90.71 % Match rate. Its strength lies particularly in handling change-related queries requiring multi-step reasoning and robust tool selection. Practical effectiveness was further validated through a real-world urban change monitoring case study in Qianhai Bay, Shenzhen. By providing intelligence, adaptability, and multi-type change analysis, ChangeGPT offers a powerful solution for decision-making in remote sensing applications.

</details>


### [96] [HAL: Inducing Human-likeness in LLMs with Alignment](https://arxiv.org/abs/2601.02813)
*Masum Hasan,Junjie Zhao,Ehsan Hoque*

Main category: cs.AI

TL;DR: HAL框架通过可解释的数据驱动奖励信号，将语言模型与对话人类相似性对齐，而不影响整体性能


<details>
  <summary>Details</summary>
Motivation: 对话人类相似性在人机交互中至关重要，但难以定义、测量和优化，目前的改进主要依赖规模或广泛的监督训练，而非针对性对齐

Method: 从对比对话数据中提取显式对话特征，组合成紧凑的标量分数，作为透明奖励信号，使用标准偏好优化方法进行对齐

Result: 在大规模人类评估中，使用HAL对齐的模型在对话中更频繁地被感知为人类相似，且不影响模型整体性能

Conclusion: HAL展示了如何将语言中软性、定性的属性（先前超出对齐范围）变得可测量，并以可解释和可说明的方式进行对齐

Abstract: Conversational human-likeness plays a central role in human-AI interaction, yet it has remained difficult to define, measure, and optimize. As a result, improvements in human-like behavior are largely driven by scale or broad supervised training, rather than targeted alignment. We introduce Human Aligning LLMs (HAL), a framework for aligning language models to conversational human-likeness using an interpretable, data-driven reward. HAL derives explicit conversational traits from contrastive dialogue data, combines them into a compact scalar score, and uses this score as a transparent reward signal for alignment with standard preference optimization methods. Using this approach, we align models of varying sizes without affecting their overall performance. In large-scale human evaluations, models aligned with HAL are more frequently perceived as human-like in conversation. Because HAL operates over explicit, interpretable traits, it enables inspection of alignment behavior and diagnosis of unintended effects. More broadly, HAL demonstrates how soft, qualitative properties of language--previously outside the scope for alignment--can be made measurable and aligned in an interpretable and explainable way.

</details>


### [97] [Causal-Enhanced AI Agents for Medical Research Screening](https://arxiv.org/abs/2601.02814)
*Duc Ngo,Arya Rahgoza*

Main category: cs.AI

TL;DR: 本文提出了一种因果图增强的检索增强生成系统，通过整合显式因果推理与双层知识图谱，在系统综述任务中实现了95%的准确率和零幻觉，显著优于基线AI模型。


<details>
  <summary>Details</summary>
Motivation: 系统综述对循证医学至关重要，但每年150万+的出版物使人工审阅不可行。现有AI方法在系统综述任务中存在幻觉问题（2-15%的错误率），这在影响患者护理时是不可接受的。

Method: 提出因果图增强的检索增强生成系统，整合显式因果推理与双层知识图谱。采用证据优先协议，确保每个因果声明都能追溯到检索到的文献，并自动生成可视化干预-结果路径的有向无环图。

Result: 在234篇痴呆症运动研究摘要的评估中，CausalAgent达到95%的准确率、100%的检索成功率和零幻觉，而基线AI只有34%的准确率和10%的幻觉率。自动因果图实现了显式机制建模、可视化合成和增强的可解释性。

Conclusion: 虽然概念验证评估仅针对痴呆症运动研究的十个问题，但该架构方法展示了可信赖医疗AI的可转移原则，以及因果推理在高风险医疗保健中的潜力。

Abstract: Systematic reviews are essential for evidence-based medicine, but reviewing 1.5 million+ annual publications manually is infeasible. Current AI approaches suffer from hallucinations in systematic review tasks, with studies reporting rates ranging from 28--40% for earlier models to 2--15% for modern implementations which is unacceptable when errors impact patient care.
  We present a causal graph-enhanced retrieval-augmented generation system integrating explicit causal reasoning with dual-level knowledge graphs. Our approach enforces evidence-first protocols where every causal claim traces to retrieved literature and automatically generates directed acyclic graphs visualizing intervention-outcome pathways.
  Evaluation on 234 dementia exercise abstracts shows CausalAgent achieves 95% accuracy, 100% retrieval success, and zero hallucinations versus 34% accuracy and 10% hallucinations for baseline AI. Automatic causal graphs enable explicit mechanism modeling, visual synthesis, and enhanced interpretability. While this proof-of-concept evaluation used ten questions focused on dementia exercise research, the architectural approach demonstrates transferable principles for trustworthy medical AI and causal reasoning's potential for high-stakes healthcare.

</details>


### [98] [Sample-Efficient Neurosymbolic Deep Reinforcement Learning](https://arxiv.org/abs/2601.02850)
*Celeste Veronese,Daniele Meli,Alessandro Farinelli*

Main category: cs.AI

TL;DR: 本文提出了一种神经符号深度强化学习方法，通过整合背景符号知识来提高样本效率和泛化能力，在稀疏奖励环境和长规划任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前深度强化学习算法需要大量训练数据，且难以泛化到超出小规模训练场景的任务。为了解决这些问题，作者提出整合符号知识来改善样本效率和泛化能力。

Method: 提出神经符号深度强化学习方法：1) 将简单域实例中定义的部分策略表示为逻辑规则；2) 通过在线推理指导训练过程：在探索阶段偏置动作分布，在利用阶段重新缩放Q值；3) 将部分策略作为有用先验转移到更复杂场景。

Result: 在网格世界环境（完全可观测和部分可观测设置）的挑战性变体上进行了实证验证，相比最先进的奖励机制基线方法，本文方法表现出更好的性能。

Conclusion: 神经符号集成方法提高了可解释性和可信度，同时加速了收敛，特别是在稀疏奖励环境和长规划任务中，为深度强化学习的样本效率和泛化问题提供了有效解决方案。

Abstract: Reinforcement Learning (RL) is a well-established framework for sequential decision-making in complex environments. However, state-of-the-art Deep RL (DRL) algorithms typically require large training datasets and often struggle to generalize beyond small-scale training scenarios, even within standard benchmarks. We propose a neuro-symbolic DRL approach that integrates background symbolic knowledge to improve sample efficiency and generalization to more challenging, unseen tasks. Partial policies defined for simple domain instances, where high performance is easily attained, are transferred as useful priors to accelerate learning in more complex settings and avoid tuning DRL parameters from scratch. To do so, partial policies are represented as logical rules, and online reasoning is performed to guide the training process through two mechanisms: (i) biasing the action distribution during exploration, and (ii) rescaling Q-values during exploitation. This neuro-symbolic integration enhances interpretability and trustworthiness while accelerating convergence, particularly in sparse-reward environments and tasks with long planning horizons. We empirically validate our methodology on challenging variants of gridworld environments, both in the fully observable and partially observable setting. We show improved performance over a state-of-the-art reward machine baseline.

</details>


### [99] [M3MAD-Bench: Are Multi-Agent Debates Really Effective Across Domains and Modalities?](https://arxiv.org/abs/2601.02854)
*Ao Li,Jinghui Zhang,Luyu Li,Yuxiang Duan,Lang Gao,Mingcai Chen,Weijun Qin,Shaopeng Li,Fengxian Ji,Ning Liu,Lizhen Cui,Xiuying Chen,Yuntao Du*

Main category: cs.AI

TL;DR: M3MAD-Bench是一个统一且可扩展的多智能体辩论基准测试，解决了现有评估的碎片化问题和单模态限制，支持多领域任务、多模态输入和多维度指标的系统评估。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体辩论研究存在两个根本性局限：评估在碎片化且不一致的设置下进行，阻碍公平比较；且主要局限于依赖纯文本输入的单模态场景。需要建立一个统一的评估基准来促进标准化比较。

Method: 提出M3MAD-Bench基准，建立标准化协议覆盖五个核心任务领域（知识、数学、医学、自然科学、复杂推理），系统覆盖纯文本和视觉语言数据集，支持跨模态比较。在九个不同架构、规模和模态能力的基础模型上评估MAD方法，并纳入效率导向指标如token消耗和推理时间。

Result: 通过广泛实验，系统揭示了MAD在纯文本和多模态场景下的有效性、鲁棒性和效率。基准测试提供了性能-成本权衡的整体视图，为未来标准化MAD评估研究提供了可靠基础。

Conclusion: M3MAD-Bench为解决多智能体辩论评估的碎片化和单模态限制问题提供了统一框架，支持跨领域、跨模态的系统评估，为未来标准化MAD研究奠定了可靠基础。

Abstract: As an agent-level reasoning and coordination paradigm, Multi-Agent Debate (MAD) orchestrates multiple agents through structured debate to improve answer quality and support complex reasoning. However, existing research on MAD suffers from two fundamental limitations: evaluations are conducted under fragmented and inconsistent settings, hindering fair comparison, and are largely restricted to single-modality scenarios that rely on textual inputs only. To address these gaps, we introduce M3MAD-Bench, a unified and extensible benchmark for evaluating MAD methods across Multi-domain tasks, Multi-modal inputs, and Multi-dimensional metrics. M3MAD-Bench establishes standardized protocols over five core task domains: Knowledge, Mathematics, Medicine, Natural Sciences, and Complex Reasoning, and systematically covers both pure text and vision-language datasets, enabling controlled cross-modality comparison. We evaluate MAD methods on nine base models spanning different architectures, scales, and modality capabilities. Beyond accuracy, M3MAD-Bench incorporates efficiency-oriented metrics such as token consumption and inference time, providing a holistic view of performance--cost trade-offs. Extensive experiments yield systematic insights into the effectiveness, robustness, and efficiency of MAD across text-only and multimodal scenarios. We believe M3MAD-Bench offers a reliable foundation for future research on standardized MAD evaluation. The code is available at http://github.com/liaolea/M3MAD-Bench.

</details>


### [100] [ReTreVal: Reasoning Tree with Validation - A Hybrid Framework for Enhanced LLM Multi-Step Reasoning](https://arxiv.org/abs/2601.02880)
*Abhishek HS,Pavan C Shekar,Arpit Jain,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: ReTreVal是一个结合树状思维探索、自我精炼、LLM批判评分和反思记忆的混合框架，用于解决LLM在多步推理中的挑战，在数学和创意写作任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多步推理方面存在挑战，特别是在数学和创意写作等复杂领域。现有的方法如ReAct、Reflexion和Self-Refine虽然通过迭代精炼和反思改进了推理，但缺乏对替代解决方案路径的结构化探索和跨问题的持久学习。

Method: ReTreVal框架整合了树状思维探索、自我精炼、LLM批判评分和反思记忆。它构建基于问题复杂度的自适应深度推理树，每个节点通过LLM生成的明确反馈进行迭代自我批判和精炼。采用双重验证机制评估每个节点的推理质量、连贯性和正确性，同时在反思记忆缓冲区中持久存储成功推理路径和失败模式的见解，实现跨问题学习。基于批判的剪枝保留每层评分最高的节点，控制计算成本同时保留高质量解决方案路径。

Result: 使用Qwen 2.5 7B作为基础LLM，在500个数学问题和创意写作任务上评估ReTreVal，结果显示ReTreVal在结构化探索、批判驱动精炼和跨问题记忆的结合下，持续优于ReAct、Reflexion和Self-Refine等现有方法。

Conclusion: ReTreVal通过其结构化探索、批判驱动精炼和跨问题记忆的组合，特别适用于需要探索性推理、严格验证和知识迁移的任务，为LLM的多步推理提供了有效的解决方案。

Abstract: Multi-step reasoning remains a key challenge for Large Language Models (LLMs), particularly in complex domains such as mathematics and creative writing. While recent approaches including ReAct, Reflexion, and Self-Refine improve reasoning through iterative refinement and reflection, they often lack structured exploration of alternative solution paths and persistent learning across problems. We propose ReTreVal (Reasoning Tree with Validation), a hybrid framework that integrates Tree-of-Thoughts exploration, self-refinement, LLM-based critique scoring, and reflexion memory to enable bounded and validated multi-step reasoning. ReTreVal constructs a structured reasoning tree with adaptive depth based on problem complexity, where each node undergoes iterative self-critique and refinement guided by explicit LLM-generated feedback. A dual validation mechanism evaluates reasoning quality, coherence, and correctness at each node while persistently storing insights from successful reasoning paths and failure patterns in a reflexion memory buffer, enabling cross-problem learning. Critique-based pruning retains only the top-k highest-scoring nodes at each level, controlling computational cost while preserving high-quality solution paths. We evaluate ReTreVal against ReAct, Reflexion, and Self-Refine across 500 mathematical problems and creative writing tasks using Qwen 2.5 7B as the underlying LLM, and demonstrate that ReTreVal consistently outperforms existing methods through its combination of structured exploration, critique-driven refinement, and cross-problem memory, making it particularly effective for tasks requiring exploratory reasoning, rigorous verification, and knowledge transfer.

</details>


### [101] [Logical Phase Transitions: Understanding Collapse in LLM Logical Reasoning](https://arxiv.org/abs/2601.02902)
*Xinglang Zhang,Yunyao Zhang,ZeLiang Chen,Junqing Yu,Wei Yang,Zikai Song*

Main category: cs.AI

TL;DR: 该研究发现大语言模型在逻辑推理中存在"逻辑相变"现象：推理性能在特定逻辑深度内保持稳定，但超过临界点后会突然崩溃。作者提出了神经符号课程调优框架来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 符号逻辑推理是大语言模型的关键但未充分探索的能力，在高风险领域如数学推理和法律判断中提供可靠且可验证的决策。当前研究缺乏对逻辑复杂性增加下推理性能的系统分析。

Method: 提出了神经符号课程调优框架：1) 自适应对齐自然语言与逻辑符号以建立共享表示；2) 围绕相变边界重塑训练动态，逐步增强在增加逻辑深度下的推理能力。

Result: 在五个基准测试上的实验表明，该方法有效缓解了高复杂性下的逻辑推理崩溃，在朴素提示中平均准确率提升+1.26，在思维链中提升+3.95，同时改善了未见逻辑组合的泛化能力。

Conclusion: 发现了逻辑相变现象，并提出了神经符号课程调优框架来应对这一挑战。该方法通过渐进式训练策略显著提升了大语言模型在复杂逻辑推理任务中的性能。

Abstract: Symbolic logical reasoning is a critical yet underexplored capability of large language models (LLMs), providing reliable and verifiable decision-making in high-stakes domains such as mathematical reasoning and legal judgment. In this study, we present a systematic analysis of logical reasoning under controlled increases in logical complexity, and reveal a previously unrecognized phenomenon, which we term Logical Phase Transitions: rather than degrading smoothly, logical reasoning performance remains stable within a regime but collapses abruptly beyond a critical logical depth, mirroring physical phase transitions such as water freezing beyond a critical temperature threshold. Building on this insight, we propose Neuro-Symbolic Curriculum Tuning, a principled framework that adaptively aligns natural language with logical symbols to establish a shared representation, and reshapes training dynamics around phase-transition boundaries to progressively strengthen reasoning at increasing logical depths. Experiments on five benchmarks show that our approach effectively mitigates logical reasoning collapse at high complexity, yielding average accuracy gains of +1.26 in naive prompting and +3.95 in CoT, while improving generalization to unseen logical compositions. Code and data are available at https://github.com/AI4SS/Logical-Phase-Transitions.

</details>


### [102] [Batch-of-Thought: Cross-Instance Learning for Enhanced LLM Reasoning](https://arxiv.org/abs/2601.02950)
*Xuan Yang,Furong Jia,Roy Xie,Xiong Xi,Hengwei Bian,Jian Li,Monica Agrawal*

Main category: cs.AI

TL;DR: Batch-of-Thought (BoT) 是一种无需训练的方法，通过批量处理相关查询实现跨实例学习，利用共享推理模式和一致性约束来提高LLM推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型推理系统独立处理查询，丢弃了有价值的跨实例信号，如共享推理模式和一致性约束，这限制了推理性能的提升。

Method: 提出Batch-of-Thought (BoT)方法，通过批量处理相关查询进行跨实例学习，包括：1) 通过比较分析识别高质量推理模板；2) 通过一致性检查检测错误；3) 分摊计算成本。进一步提出BoT-R多智能体反思架构，其中反思器进行联合评估以获取孤立处理中无法获得的互信息增益。

Result: 在三个模型系列和六个基准测试上的实验表明，BoT-R持续提高准确性和置信度校准，同时将推理成本降低高达61%。理论和实验分析揭示了批量感知推理何时以及为何对LLM系统有益。

Conclusion: 批量处理相关查询能够有效利用跨实例信号，通过共享推理模式、一致性检查和计算分摊显著提升LLM推理系统的性能，同时降低计算成本。

Abstract: Current Large Language Model reasoning systems process queries independently, discarding valuable cross-instance signals such as shared reasoning patterns and consistency constraints. We introduce Batch-of-Thought (BoT), a training-free method that processes related queries jointly to enable cross-instance learning. By performing comparative analysis across batches, BoT identifies high-quality reasoning templates, detects errors through consistency checks, and amortizes computational costs. We instantiate BoT within a multi-agent reflection architecture (BoT-R), where a Reflector performs joint evaluation to unlock mutual information gain unavailable in isolated processing. Experiments across three model families and six benchmarks demonstrate that BoT-R consistently improves accuracy and confidence calibration while reducing inference costs by up to 61%. Our theoretical and experimental analysis reveals when and why batch-aware reasoning benefits LLM systems.

</details>


### [103] [Rationale-Grounded In-Context Learning for Time Series Reasoning with Multimodal Large Language Models](https://arxiv.org/abs/2601.02968)
*Qingxiang Liu,Zhiqing Cui,Xiaoliang Luo,Yuqian Wu,Zhuoyang Jiang,Huaiyu Wan,Sheng Sun,Lvchun Wang,Wei Yu,Yuxuan Liang*

Main category: cs.AI

TL;DR: RationaleTS方法通过引入基于原理的上下文学习，将时间序列推理从表面模式匹配转变为基于原则的推理，显著提升了多模态大语言模型在时间序列推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在时间序列推理中表现不佳，主要原因是缺乏将时间观测与下游结果连接起来的原理先验知识，导致模型依赖表面模式匹配而非原则性推理。

Method: 提出RationaleTS方法：1) 诱导标签条件化原理，构建从可观测证据到潜在结果的推理路径；2) 设计混合检索机制，平衡时间模式和语义上下文，为新的样本检索相关原理先验进行最终上下文推理。

Result: 在三个领域的时间序列推理任务上进行了广泛实验，证明了RationaleTS方法的有效性和效率。

Conclusion: RationaleTS通过将原理作为指导推理单元而非事后解释，显著提升了时间序列推理性能，代码将开源以供复现。

Abstract: The underperformance of existing multimodal large language models for time series reasoning lies in the absence of rationale priors that connect temporal observations to their downstream outcomes, which leads models to rely on superficial pattern matching rather than principled reasoning. We therefore propose the rationale-grounded in-context learning for time series reasoning, where rationales work as guiding reasoning units rather than post-hoc explanations, and develop the RationaleTS method. Specifically, we firstly induce label-conditioned rationales, composed of reasoning paths from observable evidence to the potential outcomes. Then, we design the hybrid retrieval by balancing temporal patterns and semantic contexts to retrieve correlated rationale priors for the final in-context inference on new samples. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed RationaleTS on three-domain time series reasoning tasks. We will release our code for reproduction.

</details>


### [104] [A framework for assuring the accuracy and fidelity of an AI-enabled Digital Twin of en route UK airspace](https://arxiv.org/abs/2601.03120)
*Adam Keane,Nick Pepper,Chris Burr,Amy Hodgkin,Dewi Gould,John Korna,Marc Thomas*

Main category: cs.AI

TL;DR: 本文提出了一个用于航空数字孪生的保证框架，结合可信和伦理保证(TEA)方法，为数字孪生系统的准确性和功能性提供结构化评估和证据要求。


<details>
  <summary>Details</summary>
Motivation: 数字孪生结合仿真、操作数据和AI，在航空业具有巨大潜力，但面临新兴的监管环境。需要建立一个框架来确保数字孪生准确代表物理对应物并在目标用例中提供足够功能，同时支持与利益相关者和监管机构的沟通。

Method: 采用可信和伦理保证(TEA)方法开发保证案例，该案例是一组嵌套的结构化论证，为顶层目标的实现提供合理证据。框架定义了可操作的目标和所需证据，评估数字孪生的准确性和功能性。

Result: 提出了一个结构化保证框架，帮助研究人员评估、理解和记录数字孪生的优势和局限性，识别需要改进的领域，并为利益相关者和监管机构的参与提供基础。

Conclusion: 该框架为数字孪生系统的保证提供了实用方法，支持未来应用的监管需求讨论，并通过具体工作示例为新兴指导做出贡献，有助于推动数字孪生在航空领域的可靠应用。

Abstract: Digital Twins combine simulation, operational data and Artificial Intelligence (AI), and have the potential to bring significant benefits across the aviation industry. Project Bluebird, an industry-academic collaboration, has developed a probabilistic Digital Twin of en route UK airspace as an environment for training and testing AI Air Traffic Control (ATC) agents. There is a developing regulatory landscape for this kind of novel technology. Regulatory requirements are expected to be application specific, and may need to be tailored to each specific use case.
  We draw on emerging guidance for both Digital Twin development and the use of Artificial Intelligence/Machine Learning (AI/ML) in Air Traffic Management (ATM) to present an assurance framework. This framework defines actionable goals and the evidence required to demonstrate that a Digital Twin accurately represents its physical counterpart and also provides sufficient functionality across target use cases. It provides a structured approach for researchers to assess, understand and document the strengths and limitations of the Digital Twin, whilst also identifying areas where fidelity could be improved. Furthermore, it serves as a foundation for engagement with stakeholders and regulators, supporting discussions around the regulatory needs for future applications, and contributing to the emerging guidance through a concrete, working example of a Digital Twin.
  The framework leverages a methodology known as Trustworthy and Ethical Assurance (TEA) to develop an assurance case. An assurance case is a nested set of structured arguments that provides justified evidence for how a top-level goal has been realised. In this paper we provide an overview of each structured argument and a number of deep dives which elaborate in more detail upon particular arguments, including the required evidence, assumptions and justifications.

</details>


### [105] [Automatic Prompt Engineering with No Task Cues and No Tuning](https://arxiv.org/abs/2601.03130)
*Faisal Chowdhury,Nandana Mihindukulasooriya,Niharika S D'Souza,Horst Samulowitz,Neeru Gupta,Tomasz Hanusiak,Michal Kapitonow*

Main category: cs.AI

TL;DR: 本文提出了一种更简单但同样有效的自动提示工程系统，无需调优和任务线索，首次应用于数据库表的加密列名扩展任务，并在英语和德语数据集上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示工程方法设计复杂且需要调优，而数据库表的加密列名扩展任务对表格数据搜索、访问和理解至关重要，但现有研究很少，且缺乏跨语言应用。

Method: 提出一种简单设计的自动提示工程系统，无需调优和任务明确线索，应用于数据库表的加密列名扩展任务，支持多语言处理。

Result: 在英语和德语数据集上评估了该方法，证明了其有效性，这是首次将自动提示工程应用于加密列名扩展任务，也是首次在英语以外的语言上应用自动提示工程。

Conclusion: 提出的自动提示工程系统设计简单、无需调优，在加密列名扩展任务上表现有效，为多语言表格数据处理提供了新方法。

Abstract: This paper presents a system for automatic prompt engineering that is much simpler in both design and application and yet as effective as the existing approaches. It requires no tuning and no explicit clues about the task. We evaluated our approach on cryptic column name expansion (CNE) in database tables, a task which is critical for tabular data search, access, and understanding and yet there has been very little existing work. We evaluated on datasets in two languages, English and German. This is the first work to report on the application of automatic prompt engineering for the CNE task. To the best of our knowledge, this is also the first work on the application of automatic prompt engineering for a language other than English.

</details>


### [106] [InfiAgent: An Infinite-Horizon Framework for General-Purpose Autonomous Agents](https://arxiv.org/abs/2601.03204)
*Chenglin Yu,Yuchen Wang,Songmiao Wang,Hongxia Yang,Ming Li*

Main category: cs.AI

TL;DR: InfiAgent框架通过将持久状态外部化到文件中心状态抽象中，保持智能体推理上下文严格有界，解决长时任务中的上下文增长和错误累积问题。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在长时任务中经常因无界上下文增长和错误累积而失效，现有解决方案如上下文压缩或检索增强提示需要在信息保真度和推理稳定性之间权衡。

Method: 提出InfiAgent框架，将持久状态外部化到文件中心状态抽象中，每个步骤从工作空间状态快照加上固定窗口的最近动作重建上下文，保持上下文严格有界。

Result: 在DeepResearch和80篇文献综述任务上的实验表明，无需任务特定微调，使用20B开源模型的InfiAgent与大型专有系统竞争，并保持比上下文中心基线更高的长时覆盖度。

Conclusion: 显式状态外部化为稳定长时智能体提供了实用基础，支持在保持上下文有界的同时处理复杂长时任务。

Abstract: LLM agents can reason and use tools, but they often break down on long-horizon tasks due to unbounded context growth and accumulated errors. Common remedies such as context compression or retrieval-augmented prompting introduce trade-offs between information fidelity and reasoning stability. We present InfiAgent, a general-purpose framework that keeps the agent's reasoning context strictly bounded regardless of task duration by externalizing persistent state into a file-centric state abstraction. At each step, the agent reconstructs context from a workspace state snapshot plus a fixed window of recent actions. Experiments on DeepResearch and an 80-paper literature review task show that, without task-specific fine-tuning, InfiAgent with a 20B open-source model is competitive with larger proprietary systems and maintains substantially higher long-horizon coverage than context-centric baselines. These results support explicit state externalization as a practical foundation for stable long-horizon agents. Github Repo:https://github.com/ChenglinPoly/infiAgent

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [107] [AMC26: VSSEA robust position control](https://arxiv.org/abs/2601.02557)
*Emre Sariyildiz*

Main category: eess.SY

TL;DR: 该论文为新型VSSEA提出了鲁棒位置控制策略，通过状态空间模型开发了两种控制方案：状态反馈控制器和滑模控制器，均集成了二阶DOb，实现了高性能运动控制。


<details>
  <summary>Details</summary>
Motivation: 开发针对新型VSSEA的鲁棒位置控制策略，以精确估计和补偿内外扰动，同时保持标称动态响应，实现高性能运动控制。

Method: 采用构建的状态空间模型，在统一框架下开发两种控制方案：1) 状态反馈控制器，2) 滑模控制器，两者均集成二阶扰动观测器(DOb)。比较了极点配置控制器和LQR控制器的性能。

Result: 仿真结果显示极点配置控制器对扰动高度敏感，而LQR控制器以较慢动态为代价提供更好的鲁棒性。集成DOb后，鲁棒性显著增强且不降低时间响应，LQR控制器可仅针对性能优化进行调参。实验验证了所提控制器在实际应用中的可行性。

Conclusion: 提出的鲁棒位置控制策略有效实现了VSSEA的高性能运动控制，为未来在不同刚度设置下的鲁棒稳定性和性能研究奠定了基础。

Abstract: This paper presents robust position control strategies for the novel VSSEA. By employing a constructed state-space model, two control schemes are developed in a unified framework: a state-feedback controller and a sliding mode controller, both integrated with a second-order DOb. The proposed framework achieves high-performance motion control by precisely estimating and compensating for internal and external disturbances, while preserving the nominal dynamic response. Simulation results demonstrate that pole-placement-based controllers are highly sensitive to disturbances, whereas LQR-based controllers offer improved robustness at the expense of slower dynamics. By incorporating DOb, robustness is significantly enhanced without degrading time response, and the LQR controller can be tuned solely for performance optimization. Experimental results confirm that the proposed robust position controllers can be implemented in real world applications. These results highlight the effectiveness of the proposed approach and lay the foundation for future investigations on robust stability and performance under different stiffness settings.

</details>


### [108] [AMC26: High-performance DOb for robust position control](https://arxiv.org/abs/2601.02560)
*Emre Sariyildiz*

Main category: eess.SY

TL;DR: 提出了一种新型HPDOb（高阶扰动观测器），相比传统DObs显著提高了运动控制系统的扰动估计精度和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 传统扰动观测器（DObs）在运动控制系统中存在精度和鲁棒性不足的问题，特别是在处理扰动估计时仅限于零阶截断误差，限制了其性能表现

Method: 在离散时间域中分析和合成HPDOb，采用新颖的合成方法将高阶截断误差动态纳入扰动估计，实现一阶截断误差而非传统的零阶截断误差

Result: HPDOb在扰动估计精度和鲁棒性方面显著优于传统DObs，仿真和实验验证了其稳定性和性能表现

Conclusion: HPDOb为运动控制系统提供了更精确、更鲁棒的扰动估计方法，能够增强实际应用中的控制器设计效果

Abstract: This paper presents a new HPDOb that significantly improves disturbance estimation accuracy and robustness in motion control systems, surpassing the capabilities of conventional DObs. The proposed observer is analysed and synthesised in the discrete-time domain, providing a realistic representation of their dynamic behaviour and enabling enhanced controller design for practical applications. The core contribution of the HPDOb is a novel synthesis method that incorporates higher-order truncation error dynamics into disturbance estimation. Unlike conventional DObs, which are limited to zero-order truncation error, the HPDOb achieves first-order truncation error, yielding markedly improved estimation accuracy and robustness against disturbances in motion control systems. Simulation and experiments verify the stability and performance of HPDOb.

</details>


### [109] [Hierarchical Preemptive Holistic Collaborative Systems for Embodied Multi-Agent Systems: Framework, Hybrid Stability, and Scalability Analysis](https://arxiv.org/abs/2601.02779)
*Ting Peng*

Main category: eess.SY

TL;DR: 本文提出了一种分层抢占式整体协作框架，通过将全局协调问题分解为拓扑连接的子空间优化，解决了多智能体系统在物理约束环境中的安全、可扩展和高效协调问题。


<details>
  <summary>Details</summary>
Motivation: 传统分散式方法（如反应式避碰）由于缺乏未来意图意识，容易陷入局部极小值或相互让步僵局；而集中式规划则面临计算复杂度高和单点故障的脆弱性。需要一种平衡安全、可扩展性和效率的解决方案。

Method: 提出了分层抢占式整体协作框架，将系统形式化为混合自动机，引入三阶段滚动时域机制（冻结执行、初步规划、主动前瞻窗口），采用显式填充防止协调传播与意图更新之间的竞争。设计了具有强制空闲缓冲区的鲁棒时序协议来消除Zeno行为，并形式化了影子智能体协议以保证跨子空间边界的轨迹一致性。

Result: 该框架通过子空间优化分解降低了计算复杂度，通过时序协议确保了计算稳定性，通过影子智能体协议解决了跨边界轨迹一致性问题，实现了安全、可扩展且高效的多智能体协调。

Conclusion: 分层抢占式整体协作框架有效解决了传统方法的局限性，在保持安全性的同时提高了系统的可扩展性和效率，为物理约束环境中的多智能体协调提供了系统化的解决方案。

Abstract: The coordination of Embodied Multi-Agent Systems in constrained physical environments requires a rigorous balance between safety, scalability, and efficiency. Traditional decentralized approaches, e.g., reactive collision avoidance, are prone to local minima or reciprocal yielding standoffs due to the lack of future intent awareness. In contrast, centralized planning suffers from intractable computational complexity and single-point-of-failure vulnerabilities. To address these limitations, we propose the Hierarchical Preemptive Holistic Collaborative (Prollect) framework, which generalizes the Preemptive Holistic Collaborative System (PHCS) by decomposing the global coordination problem into topologically connected subspace optimizations. We formalize the system as a Hybrid Automaton and introduce a three-stage receding horizon mechanism (frozen execution, preliminary planning, proactive look-ahead windows) with explicit padding to prevent races between coordination dissemination and intent updates. Notably, we design a robust timing protocol with a mandatory Idle Buffer that acts as a dwell-time constraint to eliminate Zeno behaviors and ensure computational stability under jitter. Furthermore, we formalize a Shadow Agent protocol to guarantee seamless trajectory consistency across subspace boundaries, which we treat as an Input-to-State Stability (ISS) problem.

</details>


### [110] [A Mathematical Formalization of Self-Determining Agency](https://arxiv.org/abs/2601.02885)
*Yoshiyuki Ohmura,Earnest Kota Carr,Yasuo Kuniyoshi*

Main category: eess.SY

TL;DR: 该论文提出了一种基于"随附因果"的物理模型，试图在物理决定论框架内解释智能体的自主行为，通过数学形式化消除传统物理描述与智能体行为之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 认知科学和人工智能面临的核心挑战是如何定义智能体。物理描述机械事件，但与智能体行为之间存在不可逾越的鸿沟。为了讨论智能体的道德和责任，需要建立行为模型，但物理决定论能否完全解释负责任的行为一直存在争议。

Method: 提出"随附因果"的数学形式化。定义随附因果为从随附层次到底层基础的因果效力。虽然由多个随附函数组成的代数表达式随附于基础，但决定代数表达式的索引序列并不随附于基础，因此可以拥有独立于底层基础的独特动力学规律。

Result: 建立了一个双规律系统，其中随附层次的时间上先行的变化可以引起底层基础的变化。这种独立动力学为随附层次提供了因果效力，使得物理系统能够在遵循物理定律的同时，遵循粗粒化的智能体层次决定。

Conclusion: 这种双规律系统被认为对建模人类等自我决定智能体有用，为解决物理决定论与智能体自主性之间的矛盾提供了数学框架，同时不违反物理定律。

Abstract: Defining agency is an extremely important challenge for cognitive science and artificial intelligence. Physics generally describes mechanical happenings, but there remains an unbridgeable gap between them and the acts of agents. To discuss the morality and responsibility of agents, it is necessary to model acts; whether such responsible acts can be fully explained by physical determinism has been debated. Although we have already proposed a physical "agent determinism" model that appears to go beyond mere mechanical happenings, we have not yet established a strict mathematical formalism to eliminate ambiguity. Here, we explain why a physical system can follow coarse-graining agent-level determination without violating physical laws by formulating supervenient causation. Generally, supervenience including coarse graining does not change without a change in its lower base; therefore, a single supervenience alone cannot define supervenient causation. We define supervenient causation as the causal efficacy from the supervenience level to its lower base level. Although an algebraic expression composed of the multiple supervenient functions does supervenes on the base, a sequence of indices that determines the algebraic expression does not supervene on the base. Therefore, the sequence can possess unique dynamical laws that are independent of the lower base level. This independent dynamics creates the possibility for temporally preceding changes at the supervenience level to cause changes at the lower base level. Such a dual-laws system is considered useful for modeling self-determining agents such as humans.

</details>


### [111] [Site-Specific and Frequency-Dependent Channel Characterization and MIMO Performance in FR3](https://arxiv.org/abs/2601.02903)
*Zhuangzhuang Cui,Rudranil Chattopadhyay,Emiel Vanspranghels,Sofie Pollin*

Main category: eess.SY

TL;DR: 本文研究了7-24GHz（FR3频段）的传播特性和MIMO性能，发现该频段在传播行为和频谱效率方面介于sub-6GHz和毫米波之间，且大规模天线阵列对性能提升至关重要。


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统需要通过动态频谱利用实现按需连接，因此研究FR3频段（7-24GHz）的传播特性和MIMO性能对于实现这一愿景至关重要。

Method: 使用基于Sionna框架的站点特定射线追踪（RT）模拟，在室内和室外环境中分析FR1、FR3和FR2的代表性频率（3.5、7、10、14、20、24、28GHz），包括单天线和多天线配置。

Result: FR3频段表现出介于sub-6GHz和毫米波频段之间的中间传播行为，同时保持了有效的空间复用和良好的频谱效率。大规模阵列分析表明，FR3的性能增益与天线缩放密切相关。

Conclusion: FR3频段在传播特性和MIMO性能方面具有独特优势，实际部署需要采用大规模或大孔径MIMO架构来充分发挥其性能潜力。

Abstract: Next-generation wireless systems aim to enable on-demand connectivity through dynamic spectrum utilization. Motivated by this vision, this paper investigates the propagation characteristics and MIMO performance of the upper mid-band, spanning approximately 7-24 GHz and unofficially referred to as FR3. Using site-specific ray-tracing (RT) simulations based on the Sionna framework, we analyze indoor and outdoor environments at representative frequencies across FR1, FR3, and FR2, including 3.5, 7, 10, 14, 20, 24, and 28 GHz, under both single-antenna and multi-antenna configurations. The results show that FR3 exhibits intermediate propagation behavior between sub-6 GHz and millimeter-wave bands while sustaining effective spatial multiplexing and favorable spectral efficiency. Furthermore, large-array analysis indicates that performance gains in FR3 are closely tied to antenna scaling, highlighting the importance of large-size or large-aperture MIMO architectures for practical deployments.

</details>


### [112] [Closed-Loop Transmission Power Control for Reliable and Low-Power BLE Communication in Dynamic IoT Settings](https://arxiv.org/abs/2601.03003)
*Ziyao Zhou,Hen-Wei Huang*

Main category: eess.SY

TL;DR: 本文提出了一种基于PID控制器的混合RSSI-吞吐量蓝牙低功耗传输功率控制框架，以应对动态环境中BLE通信的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 在动态物联网环境中，蓝牙低功耗通信的接收信号强度指示和数据吞吐量易受环境影响而性能下降，需要可靠的传输功率控制机制。

Method: 系统分析了RSSI、吞吐量、传输功率和外围设备功耗之间的相互关系，提出了基于PID控制器的闭环传输功率控制框架，包括RSSI控制、吞吐量控制和混合控制三种策略。

Result: 实验结果表明，混合控制策略即使在快速变化的环境条件下，也能将数据吞吐量维持在接近目标水平且方差最小，优于单一控制方法。

Conclusion: 混合RSSI-吞吐量控制策略结合了RSSI反馈的快速响应性和吞吐量测量的准确性，为动态物联网环境中的BLE通信提供了可靠的传输功率控制解决方案。

Abstract: Reliable and energy-efficient Bluetooth Low Energy (BLE) communication is crucial for Internet of Things (IoT) applications in dynamic environments. However, the Received Signal Strength Indicator (RSSI) and data throughput in BLE are highly susceptible to environmental variability, which degrades communication performance. In this work, we systematically analyze the interdependence among RSSI, throughput, transmission power (TXP), and the peripheral device system power consumption under diverse real-world conditions. We observe that adjusting the TXP effectively influences both RSSI and throughput. We propose a robust closed-loop TXP control framework based on Proportional-Integral-Derivative (PID) controllers. Two initial control strategies are investigated: an RSSI-based approach and a throughput-based approach, each exhibiting distinct advantages and limitations. The RSSI-based method provides rapid responsiveness to signal fluctuations but lacks direct correlation with data throughput, whereas the throughput-based method offers more accurate feedback on effective throughput at the cost of slower response. To address these limitations, a hybrid RSSI-throughput control strategy is developed, combining the responsiveness of RSSI feedback with the accuracy of throughput measurements. Experimental results demonstrate that the proposed hybrid approach maintains data throughput close to the target level with minimal variance, even under rapidly changing environmental conditions.

</details>


### [113] [From inconsistency to decision: explainable operation and maintenance of battery energy storage systems](https://arxiv.org/abs/2601.03007)
*Jingbo Qu,Yijie Wang,Yujie Fu,Putai Zhang,Weihan Li,Mian Li*

Main category: eess.SY

TL;DR: 本文提出了一种基于不一致性驱动的电池储能系统运维范式，通过多维不一致性评估和LLM语义推理，将监测数据转化为可解释的运维指导，显著提升运维效率。


<details>
  <summary>Details</summary>
Motivation: 电池储能系统对电网稳定性日益重要，但当前运维主要依赖反应式的专家诊断。虽然电芯级不一致性提供了早期预警信号，但缺乏可扩展且可解释的决策支持框架，无法将这些信号有效转化为运维行动。

Method: 提出不一致性驱动的运维范式，整合多维不一致性评估（电气、热、老化相关）与大语言模型语义推理，通过多智能体框架将结构化运维记录转化为可操作的维护洞察。

Result: 使用包含3,564个电芯的电池系统8个月现场数据验证，该方法能够准确、可解释地响应实际运维查询，相比传统专家驱动实践，响应时间和运维成本降低超过80%。

Conclusion: 该方法为电池储能系统的智能运维建立了可扩展路径，对可靠性、安全性以及储能系统经济高效地融入现代电力系统具有直接意义。

Abstract: Battery Energy Storage Systems (BESSs) are increasingly critical to power-system stability, yet their operation and maintenance remain dominated by reactive, expert-dependent diagnostics. While cell-level inconsistencies provide early warning signals of degradation and safety risks, the lack of scalable and interpretable decision-support frameworks prevents these signals from being effectively translated into operational actions. Here we introduce an inconsistency-driven operation and maintenance paradigm for large-scale BESSs that systematically transforms routine monitoring data into explainable, decision-oriented guidance. The proposed framework integrates multi-dimensional inconsistency evaluation with large language model-based semantic reasoning to bridge the gap between quantitative diagnostics and practical maintenance decisions. Using eight months of field data from an in-service battery system comprising 3,564 cells, we demonstrate how electrical, thermal, and aging-related inconsistencies can be distilled into structured operational records and converted into actionable maintenance insights through a multi-agent framework. The proposed approach enables accurate and explainable responses to real-world operation and maintenance queries, reducing response time and operational cost by over 80% compared with conventional expert-driven practices. These results establish a scalable pathway for intelligent operation and maintenance of battery energy storage systems, with direct implications for reliability, safety, and cost-effective integration of energy storage into modern power systems.

</details>


### [114] [Finite Memory Belief Approximation for Optimal Control in Partially Observable Markov Decision Processes](https://arxiv.org/abs/2601.03132)
*Mintae Kim*

Main category: eess.SY

TL;DR: 该论文研究部分可观测随机最优控制问题中的有限记忆信念近似，通过度量理论分析信息损失与控制性能的关系，为有限记忆信念近似提供了量化性能边界。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测马尔可夫决策过程中，信念状态虽然是充分的，但通常是无限维且不实用的。因此需要研究有限记忆信念近似方法，以在实际控制问题中实现可行的解决方案。

Method: 将截断的输入输出历史解释为诱导信念近似，基于Wasserstein度量开发度量理论，通过固定策略比较方法分析信念替换对控制性能的影响，在线性二次高斯系统中提供闭式信念失配评估。

Result: 推导出策略条件性能边界，量化有限记忆引起的价值退化；在线性二次高斯系统中，信念失配随记忆长度近似指数衰减，性能失配相应缩放；通过实证验证预测机制。

Conclusion: 研究提供了度量感知的特征描述，明确了有限记忆信念近似在部分可观测设置中能够实现和不能实现的目标，为实际应用提供了理论基础和性能保证。

Abstract: We study finite memory belief approximation for partially observable (PO) stochastic optimal control (SOC) problems. While belief states are sufficient for SOC in partially observable Markov decision processes (POMDPs), they are generally infinite-dimensional and impractical. We interpret truncated input-output (IO) histories as inducing a belief approximation and develop a metric-based theory that directly relates information loss to control performance. Using the Wasserstein metric, we derive policy-conditional performance bounds that quantify value degradation induced by finite memory along typical closed-loop trajectories. Our analysis proceeds via a fixed-policy comparison: we evaluate two cost functionals under the same closed-loop execution and isolate the effect of replacing the true belief by its finite memory approximation inside the belief-level cost. For linear quadratic Gaussian (LQG) systems, we provide closed-form belief mismatch evaluation and empirically validate the predicted mechanism, demonstrating that belief mismatch decays approximately exponentially with memory length and that the induced performance mismatch scales accordingly. Together, these results provide a metric-aware characterization of what finite memory belief approximation can and cannot achieve in PO settings.

</details>


### [115] [Time-Varying Kinematics Control for Magnetically-Actuated Satellite Swarm without Additional Actuator](https://arxiv.org/abs/2601.03143)
*Yuta Takahashi,Hiraku Sakamoto,Shin-ichiro Sakai*

Main category: eess.SY

TL;DR: 本文讨论了电磁编队飞行的可控性问题，基于系统角动量守恒的非完整约束，设计了一种无需额外姿态执行器的多卫星控制器。


<details>
  <summary>Details</summary>
Motivation: 电磁编队飞行技术使用电磁力和力矩控制多颗卫星，无需传统燃料推进。然而，系统角动量守恒构成了非完整约束，这给控制带来了挑战。本文旨在解决在无额外姿态执行器情况下的多卫星控制问题。

Method: 基于系统角动量守恒的非完整约束特性，设计了一种新的控制器。该控制器专门针对多卫星系统，不需要额外的姿态执行器，利用电磁力实现编队飞行控制。

Result: 论文讨论了电磁编队飞行系统的可控性，并成功设计出适用于多卫星系统的控制器。该控制器能够在满足角动量守恒约束的条件下实现有效控制。

Conclusion: 本文证明了在角动量守恒的非完整约束下，电磁编队飞行系统是可控的，并设计出了无需额外姿态执行器的有效控制器，为多卫星电磁编队飞行控制提供了解决方案。

Abstract: Electromagnetic Formation Flight is a technology that uses electromagnetic forces and torques to control multiple satellites without conventional fuel-based propulsion. In this paper, the controllability of the system is discussed based on the conservation of the entire system's angular momentum, which constitutes a nonholonomic constraint. This paper designs a new controller for multiple satellites without an additional attitude actuator.

</details>


### [116] [Conditioning Aircraft Trajectory Prediction on Meteorological Data with a Physics-Informed Machine Learning Approach](https://arxiv.org/abs/2601.03152)
*Amy Hodgkin,Nick Pepper,Marc Thomas*

Main category: eess.SY

TL;DR: 提出了一种物理信息化的飞机轨迹预测方法，通过从数据中学习飞机推力和空速，结合基于物理的BADA模型，提高轨迹预测的准确性和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 飞机轨迹预测面临气象条件和操作程序等认知不确定性，需要概率机器学习模型，但现有模型生成的轨迹可能缺乏物理合理性，影响可信度。

Method: 提出物理信息方法：从数据中学习飞机推力和空速，用这些参数调节现有的基于物理的BADA模型，该模型基于能量约束确保轨迹的物理合理性。识别一组信息特征来调节飞机推力和空速的概率模型。

Result: 与忽略气象条件等上下文信息的基线概率模型相比，所提方案在六项指标上表现出20%的技能提升。

Conclusion: 通过结合数据驱动的学习和物理约束，提出的物理信息方法显著提高了飞机轨迹预测的准确性和物理合理性，增强了模型的可靠性。

Abstract: Accurate aircraft trajectory prediction (TP) in air traffic management systems is confounded by a number of epistemic uncertainties, dominated by uncertain meteorological conditions and operator specific procedures. Handling this uncertainty necessitates the use of probabilistic, machine learned models for generating trajectories. However, the trustworthiness of such models is limited if generated trajectories are not physically plausible. For this reason we propose a physics-informed approach in which aircraft thrust and airspeed are learned from data and are used to condition the existing Base of Aircraft Data (BADA) model, which is physics-based and enforces energy-based constraints on generated trajectories. A set of informative features are identified and used to condition a probabilistic model of aircraft thrust and airspeed, with the proposed scheme demonstrating a 20% improvement in skilfulness across a set of six metrics, compared against a baseline probabilistic model that ignores contextual information such as meteorological conditions.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [117] [Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)](https://arxiv.org/abs/2601.02898)
*Wim Vanderbauwhede,Lauritz Thamsen,José Cano*

Main category: cs.DC

TL;DR: LOCO 2024是第一届低碳计算国际研讨会论文集


<details>
  <summary>Details</summary>
Motivation: 随着计算技术快速发展，能源消耗和碳排放问题日益突出，需要探索低碳计算解决方案

Method: 通过国际研讨会形式，汇集学术界和工业界专家，分享低碳计算领域的最新研究成果和实践经验

Result: 论文集收录了低碳计算相关的研究论文，涵盖了算法优化、硬件设计、系统架构等多个方面

Conclusion: 低碳计算是应对气候变化和可持续发展的重要方向，需要跨学科合作和技术创新

Abstract: This is the proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024).

</details>


### [118] [Software-Defined Agentic Serving](https://arxiv.org/abs/2601.03197)
*Saurabh Agarwal,Marco Laju,Jayanth Srinivasa,Myungjin Lee,Aditya Akella*

Main category: cs.DC

TL;DR: 提出了一种新的SDN启发的智能体服务框架，通过运行时状态控制通信关键属性，实现高效、响应式的智能体系统


<details>
  <summary>Details</summary>
Motivation: 随着多智能体LLM管道日益复杂，现有服务范式无法适应动态服务条件，需要可编程和系统感知的智能体服务系统

Method: 提出SDN启发的智能体服务框架，基于运行时状态控制通信关键属性，取代静态参数编码的传统服务方式

Result: 该架构能够实现服务高效、响应式的智能体系统，并为高级意图驱动的智能体服务铺平道路

Conclusion: 需要可编程和系统感知的智能体服务系统来适应动态服务条件，SDN启发的框架为此提供了有效解决方案

Abstract: As multi-agent LLM pipelines grow in complexity, existing serving paradigms fail to adapt to the dynamic serving conditions. We argue that agentic serving systems should be programmable and system-aware, unlike existing serving which statically encode the parameters. In this work, we propose a new SDN-inspired agentic serving framework that helps control the key attributes of communication based on runtime state. This architecture enables serving-efficient, responsive agent systems and paves the way for high-level intent-driven agentic serving.

</details>


<div id='nucl-ex'></div>

# nucl-ex [[Back]](#toc)

### [119] [Differential cross sections for ${{^{12}\mathrm{C}(n,α_{0})}}$, ${{^{16}\mathrm{O}(n,α_{0})}}$ and ${{^{16}\mathrm{O}(n,α_{1,2,3})}}$ between ${E_n}$ = 7.2 and 10 MeV with an active-target Time Projection Chamber](https://arxiv.org/abs/2601.02841)
*J. Bishop,C. E. Parker,R. Smith,Tz. Kokalova,G. V. Rogachev,C. Wheldon,S. Ahn,E. Koshchiy,K. Brandenburg,C. R. Brune,R. J. Charity,J. Derkin,N. Dronchi,G. Hamad,Y. Jones-Alberty,T. N. Massey,Z. Meisel,E. V. Ohstrom,S. N. Paneru,E. C. Pollacco,M. Saxena,N. Singh,L. G. Sobotka,D. Soltesz,S. K. Subedi,A. V. Voinov,J. Warren*

Main category: nucl-ex

TL;DR: 使用活性靶时间投影室首次测量中子诱导反应的微分截面，发现¹⁶O(n,α)反应截面与ENDFVIII.0评估存在偏差


<details>
  <summary>Details</summary>
Motivation: 测量¹²C(n,α₀)、¹⁶O(n,α₀)和¹⁶O(n,α₁,₂,₃)微分截面数据对于理解核反应堆中的中子嬗变等核物理应用至关重要

Method: 使用TexAT时间投影室在活性靶模式下测量微分和角度积分截面，填充CO₂气体，利用d(d,n)反应产生的准单能中子束在俄亥俄大学Edwards加速器实验室进行实验

Result: 当前结果与先前结果在重叠能量和角度上显示良好一致性，但更广角度覆盖显示¹⁶O反应积分截面与ENDFVIII.0评估存在偏差

Conclusion: 首次使用活性靶时间投影室进行中子诱导反应测量，证明该方法能够在相对低强度束流下获得高质量微分截面数据，覆盖宽角度范围并产生良好统计

Abstract: Data for the ${{^{12}\mathrm{C}(n,α_{0})}}$, ${{^{16}\mathrm{O}(n,α_{0})}}$ and ${{^{16}\mathrm{O}(n,α_{1,2,3})}}$ differential cross sections are important for several different areas of nuclear physics such as understanding neutron transmutation in nuclear reactors.
  The TexAT Time Projection Chamber was used to measure the differential and angle-integrated cross sections in active-target mode. The chamber was filled with CO$_2$ gas and used a quasi-monoenergetic neutron beam from the $d(d,n)$ reaction at Edwards Accelerator Lab at Ohio University.
  A comparison between our current and previous results at overlapping energies and angles which showed good agreement in angular dependence and absolute cross section. A broader angular coverage than previous results demonstrated that the integrated cross section for the \po16 reaction deviates from ENDFVIII.0 evaluations.
  This first instance of neutron-induced measurements with an active-target Time Projection Chamber demonstrates the use of this method for high-quality differential cross section data across a broad angular range, generating good statistics with a relatively low-intensity beam.

</details>


### [120] [Unbound states in $^{19}$O(d,p$γ$)$^{20}$O: tracing the $ν$(d$_{3/2}$) orbital](https://arxiv.org/abs/2601.03053)
*Charlie James Paxman,Irene Zanon,Emmanuel Clément,Alain Goasduff,Javier Menendez,Takayuki Miyagi,Marlene Assié,Michal Ciemala,Freddy Flavigny,Antoine Lemasson,Adrien Matta,Diego Ramos,Mauricy Rejmund*

Main category: nucl-ex

TL;DR: 利用19O(d,pγ)20O单中子转移反应研究20O核态，首次观测到7.6-9.8 MeV能量范围内的未束缚态


<details>
  <summary>Details</summary>
Motivation: 研究20O核的束缚态和未束缚态，特别是首次通过19O(d,p)通道访问7.6-9.8 MeV能量范围内的未束缚态，以更好地理解该核的结构特性

Method: 在GANIL实验室进行19O(d,pγ)20O单中子转移反应实验，使用改进的实验角分布测量技术，通过粒子-γ谱学方法分离和识别核态

Result: 观测到s波和d波转移产生的束缚态，并首次发现7.6-9.8 MeV能量范围内的多个未束缚态，通过粒子-γ谱学成功分离这些态

Conclusion: 该实验成功扩展了对20O核态的认识，特别是首次观测到中子分离能以上的未束缚态，为理解该核的结构提供了重要实验数据

Abstract: The single-neutron transfer reaction $^{19}$O(d,p$γ$)$^{20}$O has been performed at GANIL, populating states up to and above the neutron separation energy. Bound states populated by s-wave and d-wave transfer have been observed with improved experimental angular distributions. Critically, several unbound states between 7.6 MeV and 9.8 MeV have been accessed for the first time through the 19O(d,p) channel, and isolated via particle-$γ$ spectroscopy.

</details>
