<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 48]
- [nucl-ex](#nucl-ex) [Total: 1]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.AI](#cs.AI) [Total: 14]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.DC](#cs.DC) [Total: 4]
- [nucl-th](#nucl-th) [Total: 3]
- [eess.SY](#eess.SY) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld是一个实时多模态4D世界建模框架，通过生成-重建-引导范式统一视频生成、动态场景重建和长期世界记忆，实现空间、时间和物理一致性，支持实时交互和长时程生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在实时交互、长时程一致性和动态场景持久记忆方面存在局限，阻碍了它们发展为实用的世界模型。需要一种能够统一视频生成、动态场景重建和长期记忆的框架。

Method: 提出生成-重建-引导范式：生成的视频流被连续重建为动态4D时空表示，该表示反过来引导后续生成以保持一致性。采用自回归扩散视频模型，增强宏观-微观规划（MMPL）层次规划方法，减少从帧级到段级的误差累积，并使用高效的分布匹配蒸馏（DMD）实现实时合成。

Result: TeleWorld在静态和动态世界理解、长期一致性和实时生成效率方面表现优异，实现了动态对象建模和静态场景表示在统一4D框架中的无缝集成。

Conclusion: TeleWorld是迈向实用、交互式、具有记忆功能的世界模型的重要一步，为多模态生成和具身智能提供了计算可访问的系统框架。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [2] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 本文提出通过噪声优化解决文本到图像模型的模式崩溃问题，相比传统引导机制或候选池方法，该方法能提升生成多样性同时保持基础模型保真度


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型存在严重的模式崩溃问题，即给定相同文本提示时生成的多个图像缺乏多样性。现有方法主要通过引导机制或生成大量候选图像进行筛选，但本文探索不同的方向

Method: 采用简单的噪声优化目标来缓解模式崩溃，同时分析噪声的频率特性，探索具有不同频率特性的替代噪声初始化方法，以改善优化和搜索过程

Result: 实验表明噪声优化在生成质量和多样性方面都取得了优越的结果，能够有效缓解模式崩溃问题

Conclusion: 噪声优化是一种有效的解决文本到图像模型模式崩溃的方法，既能保持基础模型的保真度，又能显著提升生成图像的多样性

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [3] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: 本文介绍了Spatial4D-Bench，一个用于评估多模态大语言模型4D空间智能的大规模基准测试，包含约40,000个问题-答案对，涵盖18个任务和6个认知类别，揭示了现有模型在4D空间推理方面的显著局限性。


<details>
  <summary>Details</summary>
Motivation: 人类天生具备4D空间智能（感知物体随时间变化的能力），但多模态大语言模型在这方面的能力尚不明确。现有空间智能基准测试通常规模小或多样性有限，无法全面评估模型的4D空间推理能力。

Method: 开发了Spatial4D-Bench基准测试，包含约40,000个问题-答案对，涵盖18个明确定义的任务，这些任务被系统组织为6个认知类别：物体理解、场景理解、空间关系理解、时空关系理解、空间推理和时空推理。

Result: 对各种最先进的开源和专有多模态大语言模型进行了基准测试，发现它们在多种4D空间推理方面存在显著局限性，如路线规划、动作识别和物理合理性推理等。

Conclusion: Spatial4D-Bench为评估MLLMs的空间认知能力提供了结构化、全面的基准测试，揭示了当前模型在实现人类水平4D空间智能方面的不足，希望该基准能促进开发更强大的MLLMs。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [4] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: CMP框架通过压缩历史遍历数据学习空间先验，显著提升3D目标检测性能


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶视觉系统通常将每个位置视为首次访问，忽略了历史遍历数据中蕴含的丰富空间先验信息

Method: 提出压缩地图先验（CMP）框架，使用二值化哈希图存储历史遍历数据，存储密度仅为32KB/km²，比密集存储减少20倍

Result: CMP框架可轻松集成到主流3D感知系统中，在nuScenes数据集上显著且一致地提升了多种架构的3D目标检测性能

Conclusion: 利用压缩的历史遍历数据作为空间先验是提升自动驾驶视觉系统性能的有效方法，且计算成本极低

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [5] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0是一个金融信贷多模态基准测试，包含4,043张隐私合规图像和8,446个QA样本，用于评估视觉语言模型在金融信贷领域的感知、推理和鲁棒性能力。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI在信贷风险评估和文档审查中的广泛应用，迫切需要针对金融信贷应用特定文档和工作流程的领域基准，该基准需要包含信贷特定理解、真实世界鲁棒性，并保持隐私合规性。

Method: 通过封闭式合成-捕获管道构建样本：手动合成带有虚拟内容的文档模板，并在内部捕获场景感知图像。评估框架包括三个维度：感知（3个基础任务）、推理（4个信贷特定任务）和鲁棒性（10种真实世界采集伪影类型）。

Result: 在评估的23个最先进视觉语言模型中，Gemini 3 Pro作为商业模型获得最佳F1分数（64.61%），Qwen3-VL-235B作为开源基线获得最佳分数（57.27%），而专门针对金融信贷的Qfin-VL-Instruct模型获得最高总分（64.92%）。鲁棒性评估显示，即使表现最佳的模型在采集伪影下也会出现明显性能下降。

Conclusion: FCMBench-V1.0能够有效区分现代视觉语言模型的性能差异和鲁棒性，为金融信贷领域的多模态AI评估提供了标准化基准，同时解决了隐私合规和真实世界适用性的平衡问题。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [6] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 本文提出了FaceFocalDesc问题，即生成和识别包含面部动作单元、情绪状态和年龄估计的多属性自然语言描述，针对任意选择的面部区域。作者构建了新数据集并提出Focal-RegionFace模型，通过多阶段渐进微调实现局部面部特征的精细化分析。


<details>
  <summary>Details</summary>
Motivation: 当前面部分析研究大多关注整体面部特征，而忽略了局部区域的多属性描述问题。作者认为系统能够聚焦于个体面部区域将带来更好的理解和控制能力，因此提出了FaceFocalDesc这一未充分探索的问题。

Method: 1. 构建了针对任意选择面部区域的多属性描述数据集，包含丰富的区域级标注和自然语言描述；2. 基于Qwen2.5-VL提出Focal-RegionFace视觉语言模型，通过多个渐进微调阶段逐步细化对局部面部特征的关注；3. 实现可解释的年龄估计、面部动作单元和情绪检测。

Result: 实验结果表明，Focal-RegionFace在新基准测试中，无论是传统广泛使用的指标还是新提出的指标，都取得了最佳性能。这充分验证了其在细粒度多属性面部区域聚焦分析场景中的有效性和多功能性。

Conclusion: 本文成功解决了面部分析中未充分探索的FaceFocalDesc问题，通过构建新数据集和提出Focal-RegionFace模型，实现了对任意选择面部区域的多属性自然语言描述生成和识别，为细粒度面部分析提供了新方法。

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [7] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D是一个无需训练的3D变形框架，利用结构化潜在表示(SLAT)生成高质量、语义一致且时间平滑的跨类别3D变形序列。


<details>
  <summary>Details</summary>
Motivation: 3D变形面临生成语义一致和时间平滑变形的挑战，特别是在跨类别情况下。现有方法难以处理这些复杂变形需求。

Method: 提出Morphing Cross-Attention(MCA)融合源和目标SLAT特征以保持结构一致性，Temporal-Fused Self-Attention(TFSA)增强时间一致性，以及方向校正策略缓解姿态模糊性。

Result: 实验表明该方法能生成最先进的变形序列，即使是具有挑战性的跨类别情况。支持解耦变形和3D风格迁移等高级应用，并可推广到其他基于SLAT的生成模型。

Conclusion: MorphAny3D通过智能融合SLAT特征在3D生成器的注意力机制中，实现了高质量、无需训练的3D变形，为跨类别3D变形提供了有效解决方案。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [8] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 该论文提出了一种基于3D实例分割的作物计数框架，通过多视角2D图像和神经辐射场技术实现精确的作物枚举，解决了户外环境中作物遮挡和聚类难以区分的问题。


<details>
  <summary>Details</summary>
Motivation: 在户外农田环境中，作物部分遮挡以及从单一视角难以区分聚类作物的问题，给基于图像的分割方法带来了巨大挑战，需要更精确的作物计数方法以支持有效的农业管理和干预策略。

Method: 提出了一种新颖的作物计数框架，利用多视角拍摄的2D图像，结合神经辐射场（NeRF）进行视图合成，引入作物可见性和掩码一致性评分，结合NeRF模型的3D信息，实现3D作物实例分割。

Result: 在棉花铃、苹果和梨三个农业数据集上验证了该框架，尽管作物颜色、形状和尺寸存在显著差异，但仍能保持一致的计数性能。与现有技术相比，在作物计数任务上表现出优越性能。

Conclusion: 该方法通过3D实例分割实现了高度精确的作物计数，消除了对作物特定参数调整的依赖，并贡献了棉花植物数据集以推动该领域的进一步研究。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [9] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: IntraStyler提出了一种基于示例的风格合成方法，用于无监督域适应中的域内风格多样化，无需先验知识即可捕获多样的域内风格。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应方法主要关注源域和目标域之间的域偏移，而域内变异性研究不足。传统方法需要预先指定域内变化进行风格合成，这在实际应用中可能不切实际。

Method: 提出IntraStyler方法，使用示例图像引导风格合成，使输出风格匹配示例风格。引入基于对比学习的风格编码器来提取纯风格特征，实现无需先验知识的多样风格合成。

Result: 在CrossMoDA 2023数据集上的实验表明，该方法在可控风格合成方面有效，且多样化的合成数据对下游分割任务有益。

Conclusion: IntraStyler能够无需先验知识捕获多样的域内风格，为无监督域适应中的域内变异性问题提供了有效解决方案。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [10] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 该论文提出使用强化学习来提升多模态大语言模型的视觉推理能力，通过设计针对图像理解、思维步骤和答案准确性的奖励函数，采用GRPO优化策略，在Qwen-2.5-VL-7B模型上实现了5.56%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在生成推理链时缺乏视觉信息的整合，限制了其在需要精确视觉感知的任务（如视觉谜题）上的表现。研究表明视觉感知是这类任务的关键瓶颈，将图像转换为文本描述能显著提升性能。

Method: 采用奖励驱动的强化学习机制，设计了六个针对不同推理方面的奖励函数（包括图像理解、思维步骤和答案准确性），使用组相对策略优化（GRPO）来激励更长的结构化推理，并防止视觉信息的绕过。

Result: 在Qwen-2.5-VL-7B模型上实现了5.56%的性能提升，在领域内和领域外设置中都表现出一致的增益。实验还显示，将图像转换为文本描述能使Claude 3.5提升26.7%，Claude 3.7提升23.6%。

Conclusion: 强化学习是解锁开源多模态大语言模型长视觉推理能力的有效机制，无需昂贵的监督数据。通过精心设计的奖励函数和GRPO优化，能够显著提升模型在需要视觉感知任务上的表现。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [11] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC是一种新的向量量化方法，使用低维码本进行组合向量量化，通过重构码向量与特征向量的关系、引入参数自由的外推-插值机制，在显著减小码本大小的同时实现更好的性能。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度的增加，需要更高容量但更紧凑的向量量化方法。现有方法在码本容量和紧凑性之间存在冲突，需要解决这一矛盾。

Method: 1. 重构码向量与特征向量的关系，将码向量视为特征向量中的低维组合单元进行组合，显著扩展解空间；2. 引入参数自由的外推-插值机制，在VQ过程中增强和平滑特征；3. 设计确保码本完全使用，避免崩溃问题；4. 可作为即插即用模块用于现有VQ方法。

Result: 在不同任务、数据集和架构上的广泛评估表明，LooC在显著减小码本大小的同时，优于现有VQ方法，实现了最先进的性能。

Conclusion: LooC成功解决了向量量化中码本容量与紧凑性之间的冲突，通过低维组合码本和参数自由的特征增强机制，实现了更紧凑码本下的更好性能，可作为通用模块应用于各种下游任务。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [12] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 该论文提出SynDR-IQA框架，通过重塑合成数据分布来解决盲图像质量评估中合成数据训练模型泛化能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 盲图像质量评估面临标注数据稀缺的挑战，合成数据是潜在解决方案，但现有合成数据集训练的模型泛化能力有限。研究发现合成数据学习到的表示呈现离散聚类模式，阻碍回归性能。

Method: 提出SynDR-IQA框架，基于样本多样性和冗余对泛化误差影响的理论推导，采用两种策略：1）分布感知的多样化内容上采样，增强视觉多样性同时保持内容分布；2）密度感知的冗余聚类下采样，通过减少密集聚类区域的密度来平衡样本。

Result: 在三种跨数据集设置（合成到真实、合成到算法、合成到合成）上进行广泛实验，证明了该方法的有效性。

Conclusion: SynDR-IQA通过重塑合成数据分布有效提升了盲图像质量评估模型的泛化能力，为解决合成数据训练中的泛化问题提供了新思路。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [13] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 提出跨模态数据增强框架，结合CycleGAN和YOLOv8解决PCB红外缺陷检测数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 红外(IR)数据稀缺是PCB缺陷检测的关键瓶颈，传统方法依赖配对监督，难以获得足够训练数据

Method: 使用CycleGAN进行非配对图像翻译，将丰富的可见光PCB图像映射到红外域，生成高质量伪红外样本；构建异构训练策略，融合伪红外数据和有限真实红外样本训练轻量级YOLOv8检测器

Result: 该方法在低数据条件下有效增强特征学习，增强后的检测器显著优于仅使用有限真实数据训练的模型，性能接近完全监督训练的基准

Conclusion: 伪红外合成作为工业检测的鲁棒增强策略具有显著效果，为解决红外数据稀缺问题提供了有效解决方案

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [14] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: TotalFM是一个放射学基础模型，通过器官分离概念高效学习3D-CT图像与语言表达对应关系，在零样本器官病变分类任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 放射学基础模型在处理3D-CT体积数据时面临计算成本约束的挑战，需要平衡计算效率与表示能力。

Method: 基于器官分离概念，利用14万系列大规模数据集，通过分割技术和LLM处理放射报告自动创建器官体积-发现句子对，结合VideoMAE自监督预训练和体积-文本对比学习。

Result: 在零样本器官病变分类中，83%器官的F1分数优于CT-CLIP，64%优于Merlin；在零样本发现病变分类中，83%类别的AUROC优于Merlin；在放射报告生成任务中性能与现有VLM相当。

Conclusion: 器官分离学习框架可作为3D-CT基础模型实际实施的现实有效设计指南，具有高泛化性能。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [15] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign是一个大规模多学科多模态数据集，包含1550万高质量图像-文本对，通过AI增强管道改善科学图像与文本的对齐，为科学AI提供基础资源。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在通用领域已取得革命性进展，但在科学发现中的应用受到复杂科学图像与稀疏文本描述之间深刻语义鸿沟的阻碍。

Method: 从250万篇开放获取科学论文中提取1550万图像-文本对，涵盖物理、生物、工程等多学科；引入AI就绪的语义增强管道，利用Qwen-VL多模态大模型系列，通过合成论文摘要和引用上下文来重新描述图像。

Result: 技术验证显示增强显著提高了数据质量：基于SciBERT的伪困惑度指标显示语义模糊性降低，CLIP分数表明图像-文本对齐提高了18.21%。

Conclusion: S1-MMAlign为推进科学推理和跨模态理解提供了基础资源，支持AI for Science时代的发展。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [16] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 提出ActErase方法，一种无需训练的扩散模型概念擦除技术，通过激活差异分析和动态替换实现高效概念移除


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型存在安全、版权和伦理风险，当前概念擦除方法依赖数据密集且计算昂贵的微调，需要更高效的解决方案

Method: 基于激活差异分析，通过提示对分析识别激活差异区域，提取目标激活并在前向传播过程中动态替换输入激活，实现无需训练的概念擦除

Result: 在三个关键擦除任务（裸露、艺术风格、对象移除）上达到最先进的擦除性能，有效保持模型生成能力，且对对抗攻击具有强鲁棒性

Conclusion: ActErase建立了扩散模型中轻量级但有效的概念操作新范式，为安全、版权和伦理问题提供了实用的即插即用解决方案

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [17] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS是一个在稀疏观测下重建动态目标的框架，通过骨架驱动的变形场和运动估计，在稀疏视角和时间采样下实现高质量动态重建。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的动态目标重建面临挑战，因为观测通常在时间和视角上都很稀疏（如监控摄像头），而传统方法需要密集的多视角视频，这在真实场景中难以实现。

Method: SV-GS框架利用粗略骨架图和初始静态重建作为输入，优化骨架驱动的变形场，包括粗粒度骨架关节姿态估计器和细粒度变形模块。通过使关节姿态估计器具有时间依赖性，实现平滑运动插值并保留几何细节。

Result: 在合成数据集上，该方法在稀疏观测下比现有方法PSNR提升高达34%；在真实数据集上，使用显著更少的帧数就能达到与密集单目视频方法相当的性能。还可以用扩散生成先验替代初始静态重建。

Conclusion: SV-GS能够在稀疏观测下有效重建动态目标，通过骨架驱动的变形场实现高质量运动估计，为真实场景中的动态重建提供了实用解决方案。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [18] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 开发基于深度学习的皮肤疾病分类诊断模型，使用Swin Transformer在ISIC2019数据集上达到87.71%的准确率


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病日益普遍但皮肤科医生资源有限，需要智能工具支持患者和临床医生进行及时准确的皮肤疾病诊断

Method: 利用公开皮肤疾病图像数据集进行预训练，提取视觉特征；优化模型架构、数据预处理流程，应用针对性数据增强技术；基于Swin Transformer构建最终模型

Result: 在ISIC2019数据集的8个皮肤病变类别上达到87.71%的预测准确率

Conclusion: 该模型展示了作为临床医生诊断支持工具和患者自我评估辅助工具的潜力

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [19] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor是一个基于草图的视频着色模型，支持使用异构、可变数量的参考图像，通过显式的每参考区域分配和时空对应掩码注意力来提升着色质量。


<details>
  <summary>Details</summary>
Motivation: 现有着色模型通常只使用单个参考（通常是场景的第一帧），忽略了其他条件数据源，如角色设定图、背景图像或任意着色帧。这限制了着色的一致性和质量。

Method: TimeColor将参考图像编码为额外的潜在帧，在时间维度上拼接，使它们能在每个扩散步骤中并行处理。使用显式的每参考区域分配、时空对应掩码注意力以及模态分离的RoPE索引，防止捷径学习和跨身份调色板泄漏。

Result: 在SAKUGA-42M数据集上的实验表明，TimeColor在单参考和多参考协议下，相比现有基线在颜色保真度、身份一致性和时间稳定性方面都有显著提升。

Conclusion: TimeColor通过支持异构、可变数量的参考图像，并采用有效的区域绑定机制，显著提升了视频着色的质量和一致性，为视频着色任务提供了更灵活的解决方案。

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [20] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet是一个计算高效的人员重识别模型，通过多尺度特征融合、语义聚类和动态权重平均等技术，在保持高精度的同时大幅降低计算成本，适合实时监控和移动应用部署。


<details>
  <summary>Details</summary>
Motivation: 人员重识别在监控和移动应用中极为重要，需要高精度但计算成本低。现有方法虽然精度高但计算预算大，因此需要开发适合实际场景的高效模型。

Method: VisNet采用多尺度特征融合（融合ResNet50的1-4阶段）、语义聚类（基于解剖学身体分区的规则伪标注）、动态权重平均技术平衡分类语义正则化，以及FIDI损失函数改进度量学习。

Result: 在Market-1501数据集上达到87.05% Rank-1准确率和77.65% mAP，仅有32.41M参数和4.601 GFLOPs计算量，计算效率显著提升。

Conclusion: VisNet提供了一个实用的实时部署方案，特别适合计算资源有限的监控和移动应用场景，实现了精度与效率的良好平衡。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [21] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本文提出了OmniVaT框架，首次成功解决了单域泛化多模态视觉触觉学习（SDG-VTL）任务，通过多模态分数傅里叶适配器和离散树生成模块，有效缓解模态差异并增强对未见域的适应性。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉学习（VTL）面临视觉和触觉图像之间的模态差异问题，以及由非标准化触觉传感器和不一致数据收集程序引起的域差距。这些挑战被形式化为新的单域泛化多模态VTL（SDG-VTL）任务。

Method: 提出了OmniVaT框架，包含两个核心模块：1）多模态分数傅里叶适配器（MFFA），将视觉和触觉嵌入映射到统一的嵌入-频率空间，无需多域训练数据或复杂的跨模态融合策略；2）离散树生成（DTG）模块，通过分层树结构获得多样且可靠的多模态分数表示，增强对未见域中波动域偏移的适应性。

Result: 大量实验表明，OmniVaT在SDG-VTL任务上表现出优异的跨域泛化性能。

Conclusion: OmniVaT框架首次成功解决了SDG-VTL任务，通过创新的MFFA和DTG模块有效缓解了视觉-触觉模态差异问题，并增强了对未见域的适应性，为多模态感知系统提供了新的解决方案。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [22] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: DVEFormer是一种基于RGB-D Transformer的高效方法，通过知识蒸馏预测密集文本对齐视觉嵌入，替代传统语义分割，支持自然语言查询和3D地图构建。


<details>
  <summary>Details</summary>
Motivation: 在家庭环境中，机器人需要全面理解周围环境才能与未经训练的人类有效直观地互动。传统语义分割方法使用固定预定义类别，限制了灵活性和应用范围。

Method: 提出DVEFormer方法，使用Alpha-CLIP的教师嵌入通过知识蒸馏指导高效的Transformer学生模型学习细粒度像素级嵌入，支持文本查询和3D地图应用。

Result: 在室内数据集评估中达到竞争性性能，满足实时要求：完整模型26.3 FPS，小型变体77.0 FPS（NVIDIA Jetson AGX Orin）。定性结果展示了实际应用效果。

Conclusion: DVEFormer可作为传统分割方法的直接替代，同时支持灵活的自然语言查询和无缝集成到移动机器人3D建图流程中。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [23] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics是一个端到端可微分框架，通过自然语言提示为3D场景推断合理的物理参数，无需真实轨迹或标注视频指导，利用多模态大语言模型估计材料参数，并通过可学习的运动蒸馏损失从预训练视频扩散模型中提取运动先验。


<details>
  <summary>Details</summary>
Motivation: 传统3D物体和材料模拟需要专家知识和耗时的物理参数调整，才能获得期望的动态行为。现有方法通常需要真实轨迹或标注视频作为指导，限制了应用的便捷性。

Method: 1. 使用多模态大语言模型估计材料参数值，并约束在合理范围内；2. 提出可学习的运动蒸馏损失，从预训练视频扩散模型中提取鲁棒的运动先验，同时最小化外观和几何归纳偏差来指导模拟。

Result: 在30多个场景中评估，包括真实世界、人工设计和AI生成的3D物体，涵盖弹性固体、金属、泡沫、沙子、牛顿和非牛顿流体等多种材料。MotionPhysics能生成由自然语言引导的视觉真实动态模拟，超越现有技术水平，同时自动确定物理上合理的参数。

Conclusion: MotionPhysics框架通过自然语言提示成功推断物理参数，实现了无需真实轨迹指导的逼真动态模拟，为3D物理模拟提供了更便捷有效的方法。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [24] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 本文提出了一种概率双流框架，用于骨架动作识别，通过统一可靠性建模和多模态集成，在不确定条件下实现专家化学习，特别关注手部细微动作的识别。


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作识别方法主要关注身体大尺度运动，忽视了手部细微动作对于细粒度识别的重要性。同时，现有方法在可靠性建模和多模态集成方面存在不足，需要一种能够处理不确定性和噪声的统一框架。

Method: 1. 无校准预处理管道：移除规范空间变换，直接从原生坐标学习
2. 概率Noisy-OR融合：无需显式置信度监督，稳定可靠性感知的双流学习
3. 内部到跨模态集成：将四种骨架模态（关节、骨骼、关节运动、骨骼运动）与RGB表示耦合，在统一跨模态公式中桥接结构和视觉运动线索

Result: 在多个基准测试（NTU RGB+D 60/120、PKU-MMD、N-UCLA）和新定义的手部中心基准上进行了全面评估，在噪声和异构条件下表现出一致的改进和鲁棒性。

Conclusion: 提出的概率双流框架通过统一可靠性建模和多模态集成，在骨架动作识别中实现了更好的性能，特别是在处理手部细微动作和不确定条件方面表现出优势。

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [25] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse是一个多功能4D世界模型，能够进行4D重建、新轨迹视频生成和丰富的下游应用，解决了现有4D建模方法可扩展性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有4D世界建模方法存在可扩展性限制，主要源于昂贵的多视角4D数据或繁琐的训练预处理，作者希望开发一个能够处理多样化单目视频的通用4D模型。

Method: NeoVerse采用无姿态前馈4D重建、在线单目退化模式模拟等技术，使整个流程能够扩展到多样化的野外单目视频，具有良好对齐的设计。

Result: NeoVerse在标准重建和生成基准测试中达到了最先进的性能，展现出对各个领域的良好泛化能力。

Conclusion: NeoVerse通过创新的设计实现了对多样化单目视频的可扩展4D建模，为4D重建和生成任务提供了强大的多功能解决方案。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [26] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: 该论文发布了MS COCOAI数据集，包含96000个真实和合成图像数据点，用于AI生成图像检测，支持两种任务：真实/生成分类和生成模型识别。


<details>
  <summary>Details</summary>
Motivation: 随着多模态生成AI系统（如Stable Diffusion、DALL-E、MidJourney）的快速发展，合成图像越来越难以与真实照片区分，这导致了误导性内容、虚假信息和操纵媒体的传播，因此检测生成图像变得至关重要。

Method: 基于MS COCO数据集构建了包含96000个数据点的MS COCOAI数据集，使用五种生成器（Stable Diffusion 3、Stable Diffusion 2.1、SDXL、DALL-E 3、MidJourney v6）生成合成图像，并提出了两种检测任务。

Result: 创建了一个公开可用的数据集，支持AI生成图像检测研究，数据集已在Hugging Face平台发布。

Conclusion: MS COCOAI数据集为对抗AI生成图像的滥用提供了重要资源，有助于开发更有效的检测方法，应对合成媒体带来的挑战。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [27] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: RoLID-11K是首个用于车载摄像头路边垃圾检测的大规模数据集，包含超过11,000张标注图像，涵盖英国多样化驾驶条件，具有长尾分布和小目标检测挑战。


<details>
  <summary>Details</summary>
Motivation: 当前路边垃圾监测依赖人工调查和公众报告，空间覆盖有限。现有视觉数据集主要针对街景、航拍或水生环境，无法反映车载摄像头中垃圾目标极小、稀疏且背景杂乱的独特特性。

Method: 构建了RoLID-11K数据集，包含超过11,000张标注图像，涵盖英国多样化驾驶条件。对多种现代检测器进行基准测试，包括基于transformer的精度导向架构和实时YOLO模型。

Result: CO-DETR及相关transformer架构在定位精度上表现最佳，但实时模型受限于粗糙的特征层次结构。该数据集为动态驾驶场景中的极端小目标检测建立了具有挑战性的基准。

Conclusion: RoLID-11K为路边垃圾检测提供了首个大规模车载摄像头数据集，支持开发可扩展、低成本的监测系统。数据集已公开可用，旨在推动该领域的研究发展。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [28] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF提出了一种针对微小目标检测的噪声鲁棒定位框架，通过归一化流进行灵活误差建模和不确定性引导优化，解决了微小目标对标注噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管通用目标检测取得了显著进展，但微小目标与正常尺度目标之间仍存在性能差距。研究发现微小目标对标注噪声高度敏感，优化严格定位目标容易导致噪声过拟合。

Method: 提出TOLF框架：1）使用归一化流进行复杂、非高斯预测分布的误差建模；2）采用不确定性感知梯度调制机制，抑制从高不确定性、易受噪声影响的样本中学习，减轻过拟合并稳定训练。

Result: 在三个数据集上的广泛实验验证了方法的有效性。特别是在AI-TOD数据集上，TOLF将DINO基线提升了1.2% AP。

Conclusion: TOLF通过流基误差建模和不确定性引导优化，有效解决了微小目标检测中的噪声敏感问题，显著提升了微小目标定位性能。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [29] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 该研究针对医学视觉语言模型在部署后可能因数据分布变化导致性能下降的问题，提出结合输入数据偏移检测和输出置信度指标的综合监控框架，以更可靠地检测模型性能退化。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在医学图像分析中表现出色，但部署后当输入数据分布发生变化时，模型性能可能下降。检测这种性能退化对临床可靠性至关重要，但对于无需标注数据的大型预训练VLM来说仍然具有挑战性。

Method: 研究开发了DomainSAT轻量级工具箱，集成代表性偏移检测算法，用于系统分析输入数据偏移。同时研究输出级预测行为，引入基于置信度的无标签退化指标。最后将输入数据偏移检测与输出置信度指标相结合。

Result: 分析表明，输入数据偏移检测能有效识别分布变化并提供早期诊断信号，但并不总是对应实际性能退化。基于置信度的退化指标与性能退化密切相关，可作为输入偏移检测的有效补充。在大规模病理数据集上的实验显示，结合两种方法能更可靠地检测数据偏移下的VLM性能退化。

Conclusion: 结合输入数据偏移检测和输出置信度指标为数字病理学中基础模型的可靠性监控提供了实用且互补的框架，有助于更准确地检测和解释数据偏移下的模型性能退化。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [30] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种用于微调视觉语言模型的对比感知策略优化方法，通过检测输入图像扰动下模型输出的熵变化来识别感知标记，并引入对比感知损失来增强感知一致性，无需额外模型或数据。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在语言模型推理方面取得了进展，但将其扩展到多模态推理需要同时改进感知和推理能力。先前工作主要使用显式感知奖励，但难以将感知标记与推理标记分离，需要额外LLM、真实数据、强制分离感知与推理，或对所有输出标记不加区分地应用奖励。

Method: CPPO通过检测输入图像扰动下模型输出的熵变化来识别感知标记，然后在RL目标函数中扩展对比感知损失(CPL)，该损失在信息保留扰动下强制一致性，在信息移除扰动下强制敏感性。

Result: 实验表明，CPPO超越了先前的感知奖励方法，同时避免了额外模型，使训练更加高效和可扩展。

Conclusion: CPPO通过创新的对比感知损失和基于熵的感知标记检测，有效解决了多模态强化学习中感知与推理分离的挑战，提供了一种更高效、可扩展的视觉语言模型微调方法。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [31] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText是一个无需训练、即插即用的框架，通过利用扩散Transformer模型的内在机制来改进文本渲染，解决了多行布局、密集排版和中文等长尾脚本的渲染问题。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型在开放域合成方面表现出色，但在精确文本渲染方面仍有困难，特别是对于多行布局、密集排版和中文等长尾脚本。现有解决方案通常需要昂贵的重新训练或严格的外部布局约束，这会降低美学质量并限制灵活性。

Method: FreeText将问题分解为"在哪里写"和"写什么"两个部分。对于"在哪里写"，通过读取图像到文本注意力中的token-wise空间归因来定位书写区域，使用sink-like tokens作为稳定的空间锚点，并通过拓扑感知细化生成高置信度掩码。对于"写什么"，引入频谱调制字形注入(SGMI)，通过频域带通调制注入噪声对齐的字形先验，以增强字形结构并抑制语义泄漏。

Result: 在Qwen-Image、FLUX.1-dev和SD3变体上的广泛实验表明，在长文本基准测试、CVTG和作者提出的CLT-Bench上，文本可读性持续提升，同时很大程度上保持了语义对齐和美学质量，推理开销适中。

Conclusion: FreeText是一个有效的训练免费框架，通过利用扩散Transformer模型的内在机制，显著改进了文本渲染质量，特别是在处理复杂布局和长尾脚本方面，同时保持了模型的灵活性和美学质量。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [32] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM：针对视觉非显著场景改进SAM模型，通过Mask-Edge Token交互解码器和非显著特征挖掘模块，在保持零样本泛化能力的同时提升对低对比度场景的分割性能


<details>
  <summary>Details</summary>
Motivation: SAM在视觉非显著场景（前景与背景对比度低）中表现不佳，现有方法难以捕捉准确轮廓。需要提升SAM在这类场景下的感知能力，同时保持其原有的零样本泛化能力

Method: 提出VNS-SAM，包含两个核心设计：1) Mask-Edge Token交互解码器，有效利用SAM的低层特征；2) 非显著特征挖掘模块，帮助解码器深入理解非显著特征。模型仅需少量参数增加和计算需求，可在4小时内完成优化

Result: 构建了VNS-SEG数据集（超过35K图像），涵盖多种VNS场景。在各种VNS分割任务上的大量实验表明，VNS-SAM在零样本设置下表现优异，特别是在视觉非显著场景中

Conclusion: VNS-SAM成功提升了SAM在视觉非显著场景下的分割性能，同时保持了零样本泛化能力，具有广泛的现实应用潜力。代码和数据集已公开

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [33] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: DynaDrag是一种基于预测-移动框架的拖拽式图像编辑方法，通过迭代执行运动预测和运动监督来避免传统方法的跟踪问题和编辑性问题


<details>
  <summary>Details</summary>
Motivation: 传统的拖拽式图像编辑方法存在跟踪丢失、模糊跟踪、源图像与目标图像差距过大、中间点不合理导致编辑性低等问题，需要一种更有效的框架来解决这些挑战

Method: 提出DynaDrag方法，采用预测-移动框架，迭代执行运动预测和运动监督，并动态调整有效控制点以提高性能

Result: 在面部和人体数据集上的实验表明，该方法在拖拽式图像编辑方面优于先前的工作

Conclusion: DynaDrag通过创新的预测-移动框架有效解决了传统拖拽式图像编辑方法的局限性，实现了更好的像素级图像操控

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [34] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro是一种基于点云迭代概念的新型三维光声成像重建算法，专门针对不规则几何换能器阵列设计，相比传统方法显著提升了重建速度和质量。


<details>
  <summary>Details</summary>
Motivation: 临床应用中需要高质量的三维光声成像，但传统方法面临空间限制和高成本问题。不规则几何换能器阵列可以减少换能器数量，但传统迭代重建算法在处理不规则阵列时存在计算复杂度高、内存需求大、重建时间长等挑战。

Method: 基于Sliding ball adaptive growth (SlingBAG)方法的点云迭代概念，扩展其兼容性以支持任意阵列几何形状。采用分层优化策略，结合零梯度滤波和迭代过程中逐步增加的时间采样率，快速去除冗余空间点云，加速收敛。

Result: 相比原始SlingBAG算法，SlingBAG Pro在不规则阵列几何下实现了高达2.2倍的点云三维光声重建速度提升。通过仿真和活体小鼠实验验证了方法的有效性。

Conclusion: SlingBAG Pro算法能够在不规则阵列几何下保持高质量重建，减少所需换能器数量，并显著缩短整体重建时间，为临床三维光声成像应用提供了有效的解决方案。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [35] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: AEGIS是一个评估统一多模态模型世界知识应用能力的多任务基准，包含1050个手动标注的问题，涵盖21个主题和6种推理类型，采用确定性检查表评估方法提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在局限性，只能进行孤立的单任务评估，缺乏诊断能力，无法全面评估统一多模态模型在不同任务中应用世界知识的能力。

Method: 提出AEGIS基准，包含视觉理解、生成、编辑和交错生成等多任务；采用确定性检查表评估方法，用原子化的"是/否"判断替代模糊的提示评分，提高评估可靠性。

Result: 实验显示大多数统一多模态模型存在严重的世界知识缺陷，随着推理复杂度增加性能显著下降；简单的插件推理模块可以部分缓解这些弱点。

Conclusion: 世界知识推理是统一多模态模型发展的关键前沿领域，需要进一步研究来提升模型在这方面的能力。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [36] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 本文提出GranAlign框架，通过粒度感知对齐解决零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 零样本视频时刻检索面临的主要挑战是文本查询和视频内容之间的语义粒度不匹配。现有方法虽然利用预训练知识实现联合表示，但未能平衡不同模态的语义粒度，导致检索不准确。

Method: 提出GranAlign训练免费框架，包含两种互补技术：1) 基于粒度的查询重写，生成不同语义粒度的查询；2) 查询感知的标题生成，将查询意图嵌入视频内容。通过将多级查询与查询无关和查询感知的标题配对，有效解决语义不匹配问题。

Result: 该方法在三个主要基准测试（QVHighlights、Charades-STA、ActivityNet-Captions）上均达到新的最先进水平，在具有挑战性的QVHighlights数据集上实现了3.23% mAP@avg的显著提升。

Conclusion: GranAlign框架通过粒度感知对齐有效解决了零样本视频时刻检索中的语义粒度不匹配问题，无需额外训练即可显著提升检索性能，为跨模态对齐提供了新思路。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [37] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: SafeMo是一个可信赖的运动生成框架，通过最小化运动遗忘技术实现安全的人类运动生成，避免了传统离散代码本替换方法的缺陷，并在安全性和实用性之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本到运动生成的方法存在安全隐患，传统离散代码本替换方法有两个关键缺陷：1) 替换被良性提示重复使用的代码本条目会导致日常任务性能下降；2) 离散标记方法引入量化和平滑度损失，导致伪影和不平稳过渡。此外，现有文本到运动数据集包含不安全意图和对应运动，不适合安全驱动的机器学习。

Method: 提出SafeMo框架，集成最小化运动遗忘技术，这是一种两阶段机器学习遗忘策略，能够在连续空间中实现安全的人类运动生成，保留连续运动学特性而不引入代码本损失。同时创建首个安全文本到运动数据集SafeMoVAE-29K，包含重写的安全文本提示和连续精炼运动。

Result: 实验显示SafeMo在遗忘不安全提示方面表现有效，在HumanML3D和Motion-X数据集上分别达到2.5倍和14.4倍更高的遗忘集FID，相比之前的最先进人类运动遗忘方法LCR。在安全提示上的良性性能相当或更好。

Conclusion: SafeMo通过连续空间中的最小化运动遗忘技术，成功解决了文本到运动生成中的安全问题，在保持运动自然过渡的同时实现了有效的安全控制，为可信赖的人类运动生成提供了新框架。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [38] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种模态主导感知指数（MDI）来量化RGB-IR多模态检测中的优化偏差，并开发了模态主导感知跨模态学习框架（MDACL），通过分层跨模态引导和对抗均衡正则化来平衡模态融合，在三个基准测试中实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: RGB-红外多模态感知对于复杂物理环境中的嵌入式多媒体系统至关重要。现有跨模态融合方法虽然有所进展，但由于模态特征不对称（信息密度和特征质量差异）导致的优化偏差问题尚未得到充分研究，这种偏差会导致训练过度强调主导模态，阻碍有效融合。

Method: 1. 提出模态主导指数（MDI），通过联合建模特征熵和梯度贡献来量化模态主导程度；2. 开发模态主导感知跨模态学习框架（MDACL），包含分层跨模态引导（HCG）增强特征对齐，以及对抗均衡正则化（AER）平衡融合过程中的优化动态。

Result: 在三个RGB-IR基准测试上进行了广泛实验，结果表明MDACL能有效缓解优化偏差，并实现了最先进的性能。

Conclusion: 通过量化模态主导现象并设计相应的平衡机制，MDACL框架成功解决了RGB-IR多模态检测中的优化偏差问题，为跨模态融合提供了新的理论和方法基础。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [39] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose：一种用于康复训练的实时3D人体姿态估计与运动分析方法，通过多摄像头RGB视频输入实现端到端的实时监测与评估，提供即时反馈指导患者正确执行康复训练。


<details>
  <summary>Details</summary>
Motivation: 康复训练中需要实时监测和评估患者的运动状态，提供即时反馈和指导，帮助患者正确执行康复动作，恢复肌肉力量和运动功能。传统方法难以实现实时、准确的监测与评估。

Method: 1. 提出统一的端到端实时人体姿态估计与运动分析流水线；2. 针对多人干扰的医疗康复场景提出快速跟踪方法（单帧跟踪时间<1ms）；3. 改进SmoothNet用于实时姿态估计，减少估计误差并恢复真实运动状态；4. 使用Unity平台进行实时监测、评估和肌肉应力可视化。

Result: 该方法能够实时监测和评估康复训练中的患者运动，提供即时反馈和指导，快速跟踪方法在多人干扰场景下表现优异，改进的姿态估计方法使运动状态更平滑准确。

Conclusion: RePose方法为康复训练提供了一种有效的实时3D人体姿态估计与运动分析解决方案，能够帮助患者正确执行康复动作，加速康复进程，具有实际应用价值。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [40] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: HyperPriv-EPN：一种基于超图的特权信息学习框架，用于术前室管膜瘤预后预测，通过双流蒸馏使学生图从视觉特征中"幻觉"出语义社区结构，无需推理时的文本数据。


<details>
  <summary>Details</summary>
Motivation: 室管膜瘤的术前预后对治疗规划至关重要，但由于MRI缺乏术后手术报告中的语义洞察而具有挑战性。现有的多模态方法在推理时无法利用这些特权文本数据。

Method: 提出HyperPriv-EPN框架，采用Severed Graph策略，使用共享编码器处理教师图（包含术后特权信息）和学生图（仅限术前数据）。通过双流蒸馏，学生图学习仅从视觉特征中"幻觉"出语义社区结构。

Result: 在311名患者的多中心队列中验证，HyperPriv-EPN实现了最先进的诊断准确性和生存分层，有效将专家知识转移到术前设置。

Conclusion: 该框架解锁了历史术后数据的价值，指导新患者的诊断，无需在推理时使用文本数据，成功将特权信息学习应用于术前室管膜瘤预后预测。

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [41] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 基于图像深度学习的马铃薯储存质量监测系统，使用预训练模型实现发芽检测、重量损失估计和保质期预测，DenseNet在发芽检测上达到98.03%准确率。


<details>
  <summary>Details</summary>
Motivation: 马铃薯储存过程中需要非侵入式、可扩展的质量监测方案，以解决发芽检测、重量损失估计和保质期预测等关键挑战，改善库存管理并减少食物浪费。

Method: 在200天控制温湿度条件下收集图像和重量数据，利用ResNet、VGG、DenseNet和Vision Transformer等预训练架构，设计两个专门模型：高精度二分类发芽检测器和先进多分类预测器（用于重量损失和保质期预测）。

Result: DenseNet在发芽检测上达到98.03%准确率；保质期预测在粗分类（2-5类）时准确率超过89.83%，细分类（6-8类）时准确率下降；证明了图像模型集成到自动化分拣系统的可行性。

Conclusion: 该方法提供了一种经济高效、非破坏性的质量评估方法，支持马铃薯储存和分销的效率和可持续性。未来研究应开发针对不同品种和储存条件的通用模型，以增强适应性和可扩展性。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [42] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: CRoPS是一种无需训练的幻觉缓解框架，通过选择性移除关键文本标记构建幻觉模型，并结合广义对比解码来改善大型视觉语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在生成幻觉内容的倾向，这影响了其在现实世界应用中的可靠性。现有无需训练的方法存在两个主要局限：一是对幻觉来源的假设过于狭窄，二是在生成后期效果下降，而幻觉最可能在此阶段发生。

Method: 提出CRoPS框架：1）构建新型幻觉模型，通过选择性移除关键文本标记来捕捉幻觉效应；2）引入广义对比解码，整合多个幻觉模型以表示多样化的幻觉来源。

Result: CRoPS在CHAIR分数上提升了20%，在六个基准测试和三个大型视觉语言模型家族中均取得一致增益，优于现有的无需训练方法。

Conclusion: CRoPS框架通过创新的幻觉模型构建和广义对比解码，有效缓解了大型视觉语言模型的幻觉问题，提高了模型的可靠性，且无需额外训练。

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [43] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的单图像到视频生成框架，通过构建3D高斯场景表示并在单次前向传递中采样合理的物体运动，实现快速、相机引导的视频生成，无需迭代去噪过程。


<details>
  <summary>Details</summary>
Motivation: 现有单图像条件视频生成方法虽然改进了时间连贯性和3D一致性，但缺乏鲁棒的用户可控性（如修改相机路径），限制了实际应用。大多数相机控制的图像到视频模型在准确建模相机运动、保持时间一致性和维护几何完整性方面存在困难。

Method: 提出一个新颖框架，从单张图像构建3D高斯场景表示，并在单次前向传递中采样合理的物体运动。该方法避免了传统方法中需要迭代去噪来将物体运动注入渲染帧的过程，实现了快速、相机引导的视频生成。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上的大量实验表明，该方法在视频质量和推理效率方面达到了最先进的水平。

Conclusion: 该方法通过构建3D高斯场景表示并在单次前向传递中采样物体运动，实现了高效、可控的单图像到视频生成，解决了现有方法在时间一致性和几何完整性方面的不足。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [44] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM提出了一种基于高斯分布的SLAM框架，用训练免费的多视角对应关系三角化初始化替代了传统的残差驱动密度化阶段，提高了稳定性和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM使用残差驱动密度化方法，通过逐步添加高斯分布来填补缺失几何结构，这种方法可能导致早期映射不稳定、收敛速度慢，特别是在纹理丰富和杂乱场景中表现不佳。

Method: RGS-SLAM采用一次性三角化方法：1) 使用DINOv3描述符提取密集多视角对应关系；2) 通过置信度感知的内点分类器进行精炼；3) 生成结构感知的高斯种子分布作为优化前的先验；4) 保持与现有GS-SLAM管道的完全兼容性。

Result: 在TUM RGB-D和Replica数据集上的评估显示：1) 收敛速度提升约20%；2) 在纹理丰富和杂乱场景中获得更高的渲染保真度；3) 定位和重建精度达到或超过最先进的高斯和基于点的SLAM系统；4) 维持实时映射性能，最高可达925 FPS。

Conclusion: RGS-SLAM通过训练免费的对应关系三角化初始化方法，显著改善了高斯分布SLAM的稳定性和效率，为实时高保真三维重建提供了有效的解决方案。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [45] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 使用多模态大语言模型自动评分手写STEM考试的工作流程，通过参考解决方案和分级规则实现可靠评分，在真实课程测试中达到与讲师评分约8分的平均绝对差异。


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能捕捉开放式推理和图表，但人工评分速度慢且难以扩展，需要自动化解决方案来保持标准考试流程。

Method: 端到端工作流程：讲师提供手写参考解决方案和评分规则；参考方案转换为文本摘要用于条件评分；采用多阶段设计，包括格式/存在性检查、独立评分器集成、监督器聚合和确定性验证模板。

Result: 使用GPT-5.2和Gemini-3 Pro后端，完整流程与讲师评分的平均绝对差异约为8分，偏差低，手动审查触发率约17%（D_max=40）。消融实验显示简单提示和移除参考方案会显著降低准确性并引入系统性过高评分。

Conclusion: 结构化提示和参考基础对于手写STEM考试自动评分至关重要，提出的多阶段工作流程在保持标准考试流程的同时实现了可靠的自动化评分。

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [46] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 该研究探索了将自监督学习作为辅助任务来优化深度伪造检测主任务，通过融合自监督任务的特征表示，在跨数据集评估中实现了更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 探索自监督学习作为辅助任务的潜力，以优化广义深度伪造检测这一主要任务，解决现有检测器在跨数据集泛化方面的局限性。

Method: 研究了自监督学习任务与深度伪造检测主任务的不同训练方案组合，通过融合自监督辅助任务的特征表示来增强主任务的表示能力。

Result: 在DF40、FaceForensics++、Celeb-DF、DFD、FaceShifter、UADFV等多个数据集上的实验表明，该方法在跨数据集评估中相比当前最先进的检测器具有更好的泛化性能。

Conclusion: 融合自监督辅助任务的特征表示能够充分利用自监督和主任务的独特表示潜力，显著提升深度伪造检测任务的性能，特别是在跨数据集泛化方面表现优异。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [47] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 本文提出了LNU-Net和IBU-Net两种深度学习架构用于左心室MRI图像分割，通过不同的归一化策略改进U-Net，在805张MRI图像上取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对心脏图像的临床量化和诊断至关重要，需要开发更精确的分割方法来提高诊断准确性。

Method: 提出LNU-Net（基于层归一化的U-Net）和IBU-Net（基于实例-批量归一化的U-Net）两种架构，采用下采样路径进行特征提取和上采样路径进行精确定位，结合仿射变换和弹性变形进行数据增强。

Result: 在包含45名患者805张左心室MRI图像的数据集上评估，提出的方法在Dice系数和平均垂直距离指标上优于其他最先进方法。

Conclusion: LNU-Net和IBU-Net是有效的左心室分割方法，通过不同的归一化策略改进了U-Net架构，在心脏MRI图像分割任务中表现出优越性能。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [48] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR提出了一种用于单目视频动态3D场景重建的统一框架，通过自适应Gabor表示和时序连续性约束，解决了现有方法在细节捕捉和运动平滑性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于单高斯基元的方法受限于低通滤波特性，而标准Gabor函数存在能量不稳定问题。同时，缺乏时序连续性约束导致插值时出现运动伪影。需要同时解决频率适应性和时序连续性这两个关键挑战。

Method: 1) 自适应Gabor表示：通过可学习频率权重和自适应能量补偿扩展高斯函数，平衡细节捕捉和稳定性；2) 时序连续性：采用三次Hermite样条和时序曲率正则化确保平滑运动演化；3) 自适应初始化：结合深度估计、点跟踪和前景掩码建立早期训练的稳定点云分布。

Result: 在Tap-Vid DAVIS数据集上达到SOTA性能（PSNR 35.49，SSIM 0.9433，LPIPS 0.0723），在帧插值、深度一致性、视频编辑和立体视图合成等任务上表现出强大的泛化能力。

Conclusion: AdaGaR通过统一的框架同时解决了动态场景建模中的频率适应性和时序连续性挑战，在保持高频细节的同时实现了平滑的运动演化，为单目视频动态3D重建提供了有效的解决方案。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='nucl-ex'></div>

# nucl-ex [[Back]](#toc)

### [49] [KATRIN experiment](https://arxiv.org/abs/2601.00248)
*Guido Drexlin,Christian Weinheimer*

Main category: nucl-ex

TL;DR: KATRIN实验通过测量氚β衰变谱的端点区域来直接测量中微子质量，目标灵敏度低于300 meV，并计划扩展到搜索惰性keV中微子和应用量子读出技术提高灵敏度。


<details>
  <summary>Details</summary>
Motivation: 中微子振荡表明中微子具有微小但非零的质量，中微子质量标度对宇宙学、天体物理学和粒子物理学具有根本重要性，可以通过弱衰变的运动学直接测量。

Method: 使用无窗口气态分子氚源和巨型MAC-E过滤器型谱仪，以前所未有的统计量和精度测量氚β衰变谱的端点区域。

Result: KATRIN实验即将达到中微子质量低于300 meV的目标灵敏度，成为世界领先的直接中微子质量搜索实验。

Conclusion: 实验将转向搜索惰性keV中微子，然后通过应用量子读出技术结合原子氚源（KATRIN++）显著提高中微子质量灵敏度。

Abstract: Since the discovery of neutrino oscillations, it is known that neutrinos have small but non-zero masses. The neutrino mass scale, which is of fundamental importance for cosmology, astrophysics and particle physics, can be measured directly from the kinematics of weak decays. The Karlsruhe tritium neutrino experiment KATRIN measures the end point region of the tritium \b{eta}-spectrum with unrivalled t statistics and an unprecedented precision. This world-leading direct neutrino mass search experiment is characterised by a windowless, gaseous molecular tritium source and a giant MAC- E filter-type spectrometer. The precision measurement of the tritium \b{eta}-spectrum also allows the search for many other phenomena beyond the Standard Model of particle physics. The KATRIN experiment is about to reach its target sensitivity of the neutrino mass of less than 300 meV and will then turn its attention to the search for sterile keV neutrinos before the neutrino mass sensitivity is to be significantly increased once again by applying quantum read-out technology combined with an atomic tritium source with KATRIN++.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [50] [Advanced Vulnerability Scanning for Open Source Software: Detection and Mitigation of Log4j Vulnerabilities](https://arxiv.org/abs/2601.00235)
*Victor Wen,Zedong Peng*

Main category: cs.SE

TL;DR: 开发了一个先进的Log4j扫描工具，通过评估软件的实际可利用性来减少误报，集成到GitHub Actions中实现自动化持续扫描，在28个开源项目中达到91.4%的准确率。


<details>
  <summary>Details</summary>
Motivation: Log4j漏洞检测工具主要关注识别安装版本，导致大量误报，因为它们不检查软件是否真的可被恶意利用。需要开发能评估实际可利用性的工具来减少误报。

Method: 首先识别漏洞，然后提供针对性的缓解建议和即时反馈。通过GitHub Actions集成，提供自动化持续扫描能力，确保代码变更时及时识别漏洞。

Result: 在28个开源软件项目的不同版本中评估了140次扫描，达到91.4%的准确率。GitHub Action实现已在GitHub市场提供。

Conclusion: 该工具为检测和缓解开源项目中的漏洞提供了可靠方法，通过集成到现有开发工作流程中实现实时监控和快速响应潜在威胁。

Abstract: Automated detection of software vulnerabilities remains a critical challenge in software security. Log4j is an industrial-grade Java logging framework listed as one of the top 100 critical open source projects. On Dec. 10, 2021 a severe vulnerability Log4Shell was disclosed before being fully patched with Log4j2 version 2.17.0 on Dec. 18, 2021. However, to this day about 4.1 million, or 33 percent of all Log4j downloads in the last 7 days contain vulnerable packages. Many Log4Shell scanners have since been created to detect if a user's installed Log4j version is vulnerable. Current detection tools primarily focus on identifying the version of Log4j installed, leading to numerous false positives, as they do not check if the software scanned is really vulnerable to malicious actors. This research aims to develop an advanced Log4j scanning tool that can evaluate the real-world exploitability of the software, thereby reducing false positives. Our approach first identifies vulnerabilities and then provides targeted recommendations for mitigating these detected vulnerabilities, along with instant feedback to users. By leveraging GitHub Actions, our tool offers automated and continuous scanning capabilities, ensuring timely identification of vulnerabilities as code changes occur. This integration into existing development workflows enables real-time monitoring and quicker responses to potential threats. We demonstrate the effectiveness of our approach by evaluating 28 open-source software projects across different releases, achieving an accuracy rate of 91.4% from a sample of 140 scans. Our GitHub action implementation is available at the GitHub marketplace and can be accessed by anyone interested in improving their software security and for future studies. This tool provides a dependable way to detect and mitigate vulnerabilities in open-source projects.

</details>


### [51] [An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems](https://arxiv.org/abs/2601.00254)
*Md Hasan Saju,Maher Muhtadi,Akramul Azim*

Main category: cs.SE

TL;DR: 本文比较了三种基于大语言模型的软件漏洞检测方法：检索增强生成、监督微调和双智能体框架，发现检索增强生成方法在准确率和F1分数上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，为自动化软件漏洞检测提供了新的机会，这对于保护现代代码库安全至关重要。本研究旨在比较不同LLM技术在软件漏洞检测中的有效性。

Method: 研究评估了三种方法：1）检索增强生成，整合互联网和MITRE CWE数据库的外部领域知识；2）监督微调，使用参数高效的QLoRA适配器实现；3）双智能体LLM框架，其中第二个智能体审计和优化第一个智能体的输出。使用从Big-Vul和GitHub真实代码库中整理的包含五个关键CWE类别的数据集进行评估。

Result: 检索增强生成方法取得了最高的整体准确率（0.86）和F1分数（0.85）。监督微调方法也表现出色。双智能体系统在提高推理透明度和错误缓解方面显示出潜力，同时减少了资源开销。

Conclusion: 研究结果表明，整合领域专业知识机制能显著增强大语言模型在实际漏洞检测任务中的适用性，检索增强生成方法在性能上表现最优。

Abstract: The rapid advancement of Large Language Models (LLMs) presents new opportunities for automated software vulnerability detection, a crucial task in securing modern codebases. This paper presents a comparative study on the effectiveness of LLM-based techniques for detecting software vulnerabilities. The study evaluates three approaches, Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), and a Dual-Agent LLM framework, against a baseline LLM model. A curated dataset was compiled from Big-Vul and real-world code repositories from GitHub, focusing on five critical Common Weakness Enumeration (CWE) categories: CWE-119, CWE-399, CWE-264, CWE-20, and CWE-200. Our RAG approach, which integrated external domain knowledge from the internet and the MITRE CWE database, achieved the highest overall accuracy (0.86) and F1 score (0.85), highlighting the value of contextual augmentation. Our SFT approach, implemented using parameter-efficient QLoRA adapters, also demonstrated strong performance. Our Dual-Agent system, an architecture in which a secondary agent audits and refines the output of the first, showed promise in improving reasoning transparency and error mitigation, with reduced resource overhead. These results emphasize that incorporating a domain expertise mechanism significantly strengthens the practical applicability of LLMs in real-world vulnerability detection tasks.

</details>


### [52] [In Line with Context: Repository-Level Code Generation via Context Inlining](https://arxiv.org/abs/2601.00376)
*Chao Hu,Wenhao Zeng,Yuling Shi,Beijun Shen,Xiaodong Gu*

Main category: cs.SE

TL;DR: InlineCoder是一个用于仓库级代码生成的新框架，通过将未完成函数内联到其调用图中，将复杂的仓库理解任务转化为更简单的函数级编码任务。


<details>
  <summary>Details</summary>
Motivation: 现有的仓库级代码生成方法（如RAG或基于上下文的函数选择）主要依赖表面相似性，难以捕捉控制仓库级语义的丰富依赖关系，导致在理解整个仓库和跨函数、类、模块的复杂依赖推理方面存在不足。

Method: InlineCoder框架：1）给定函数签名，首先生成草稿完成（称为锚点），近似下游依赖并启用基于困惑度的置信度估计；2）双向内联过程：上游内联将锚点嵌入其调用者以捕捉多样化使用场景；下游检索将锚点的被调用者集成到提示中以提供精确的依赖上下文；3）结合草稿完成、上游和下游视角的丰富上下文为LLM提供全面的仓库视图。

Result: 论文摘要中未提供具体的实验结果数据，但描述了方法的核心创新：通过内联未完成函数到调用图中，将仓库级代码生成重新构建为更易处理的函数级任务。

Conclusion: InlineCoder通过创新的双向内联方法，将复杂的仓库理解任务转化为函数级编码问题，为仓库级代码生成提供了更有效的解决方案，克服了现有方法在捕捉深层依赖关系方面的局限性。

Abstract: Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.

</details>


### [53] [On Plagiarism and Software Plagiarism](https://arxiv.org/abs/2601.00429)
*Rares Folea,Emil Slusanschi*

Main category: cs.SE

TL;DR: 本文探讨软件相似性自动检测的复杂性，介绍开源软件解决方案Project Martial，并综述学术界和法律领域对抗软件抄袭的现有方法。


<details>
  <summary>Details</summary>
Motivation: 软件相似性检测面临数字工件的独特挑战，需要解决软件抄袭问题。现有方法分散在学术界和法律实践中，缺乏系统整合，且商业应用中的软件版权侵权案例需要深入分析。

Method: 1. 分析现有对抗软件抄袭的方法，包括学术界研究和法律案例；2. 基于可用工件对检测挑战进行分类；3. 综述文献中的技术，包括指纹识别、软件出生标记、代码嵌入等方法；4. 在Project Martial开源项目中应用这些技术。

Result: 1. 系统梳理了软件相似性检测的挑战分类；2. 综述了现有检测技术；3. 开发了开源软件Project Martial，展示了如何应用这些检测技术；4. 通过法律案例分析，提供了商业应用中软件版权侵权的实际理解。

Conclusion: 软件相似性检测是一个复杂的多学科问题，需要结合技术方法和法律理解。Project Martial作为一个开源解决方案，为检测代码相似性提供了实用工具，同时通过整合学术研究和法律实践，为对抗软件抄袭提供了更全面的框架。

Abstract: This paper explores the complexities of automatic detection of software similarities, in relation to the unique challenges of digital artifacts, and introduces Project Martial, an open-source software solution for detecting code similarity. This research enumerates some of the existing approaches to counter software plagiarism by examining both the academia and legal landscape, including notable lawsuits and court rulings that have shaped the understanding of software copyright infringements in commercial applications. Furthermore, we categorize the classes of detection challenges based on the available artifacts, and we provide a survey of the previously studied techniques in the literature, including solutions based on fingerprinting, software birthmarks, or code embeddings, and exemplify how a subset of them can be applied in the context of Project Martial.

</details>


### [54] [DSL or Code? Evaluating the Quality of LLM-Generated Algebraic Specifications: A Case Study in Optimization at Kinaxis](https://arxiv.org/abs/2601.00469)
*Negin Ayoughi,David Dewar,Shiva Nejati,Mehrdad Sabetzadeh*

Main category: cs.SE

TL;DR: EXEOS是一种基于大语言模型的方法，能够从自然语言描述生成AMPL模型和Python代码，并通过求解器反馈进行迭代优化。研究表明，在数学优化领域，AMPL这种领域特定语言在LLM生成方面与Python具有竞争力，有时甚至更优。


<details>
  <summary>Details</summary>
Motivation: 模型驱动工程（MDE）虽然提供抽象和分析严谨性，但在许多领域的工业采用受到模型开发和维护成本的限制。大语言模型（LLMs）可以通过支持从自然语言描述直接生成模型来改变这种成本平衡。然而，对于领域特定语言（DSLs），LLM生成的模型可能不如主流语言（如Python）的代码准确，因为后者在LLM训练语料中占主导地位。

Method: 作者提出了EXEOS方法，这是一种基于LLM的方法，能够从自然语言问题描述中推导出AMPL模型和Python代码，并通过求解器反馈进行迭代优化。研究使用公共优化数据集和工业合作伙伴Kinaxis的真实供应链案例进行评估，比较生成的AMPL模型与Python代码在可执行性和正确性方面的表现。

Result: 通过使用两个LLM家族的消融研究表明，AMPL在LLM生成方面与Python具有竞争力，有时甚至更好。EXEOS中的设计选择提高了生成规范的质量。

Conclusion: 研究表明，即使在LLM训练语料中代表性不足的领域特定语言（如AMPL），通过适当的方法设计（如EXEOS），LLM也能生成高质量的模型规范，这对于推动模型驱动工程在工业领域的采用具有重要意义。

Abstract: Model-driven engineering (MDE) provides abstraction and analytical rigour, but industrial adoption in many domains has been limited by the cost of developing and maintaining models. Large language models (LLMs) can help shift this cost balance by supporting direct generation of models from natural-language (NL) descriptions. For domain-specific languages (DSLs), however, LLM-generated models may be less accurate than LLM-generated code in mainstream languages such as Python, due to the latter's dominance in LLM training corpora. We investigate this issue in mathematical optimization, with AMPL, a DSL with established industrial use. We introduce EXEOS, an LLM-based approach that derives AMPL models and Python code from NL problem descriptions and iteratively refines them with solver feedback. Using a public optimization dataset and real-world supply-chain cases from our industrial partner Kinaxis, we evaluate generated AMPL models against Python code in terms of executability and correctness. An ablation study with two LLM families shows that AMPL is competitive with, and sometimes better than, Python, and that our design choices in EXEOS improve the quality of generated specifications.

</details>


### [55] [Multi-Agent Coordinated Rename Refactoring](https://arxiv.org/abs/2601.00482)
*Abhiram Bellur,Mohammed Raihan Ullah,Fraol Batole,Mohit Kansara,Masaharu Morimoto,Kai Ishikawa,Haifeng Chen,Yaroslav Zharov,Timofey Bryksin,Tien N. Nguyen,Hridesh Rajan,Danny Dig*

Main category: cs.SE

TL;DR: 本文提出首个多智能体框架来自动化协调重命名，通过范围推断、计划执行和复制三个智能体协作，显著减少开发者在跨文件重命名重构中的负担。


<details>
  <summary>Details</summary>
Motivation: 协调重命名是软件开发中频繁但具有挑战性的任务，开发者需要手动在多个相关标识符间传播重命名重构，过程繁琐且容易出错。现有启发式方法产生过多误报，而普通大语言模型因上下文限制和无法与重构工具交互提供不完整建议。

Method: 设计并实现首个多智能体框架：范围推断智能体将开发者初始重构线索转化为自然语言声明的范围；计划执行智能体使用该范围作为严格计划识别需要重构的程序元素，并通过IDE可信重构API安全执行更改；复制智能体指导项目范围的搜索。

Result: 通过对100个开源项目中609K次提交的协调重命名实践进行形成性研究，并调查了205名开发者，验证了该框架的有效性。

Conclusion: AI智能体在软件开发中的主要价值在于扩展开发者的推理和行动能力，而非取代人类参与。协调重命名正是智能体能够显著减轻开发者负担同时保持其主导地位的重复性任务类型。

Abstract: The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.
  We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...

</details>


### [56] [STELLAR: A Search-Based Testing Framework for Large Language Model Applications](https://arxiv.org/abs/2601.00497)
*Lev Sorokin,Ivan Vasilev,Ken E. Friedl,Andrea Stocco*

Main category: cs.SE

TL;DR: STELLAR是一个基于进化优化的自动化测试框架，用于发现LLM应用中导致不当响应的文本输入，相比现有方法能暴露更多故障


<details>
  <summary>Details</summary>
Motivation: LLM应用部署广泛但易产生不准确、虚构或有害的响应，其高维输入空间使得系统测试具有挑战性，需要更有效的测试方法

Method: 将测试生成建模为优化问题，将输入空间离散化为风格、内容和扰动特征，采用进化优化动态探索更可能暴露故障的特征组合

Result: 在三个LLM对话问答系统上评估，STELLAR比现有基线方法暴露最多4.3倍（平均2.5倍）的故障

Conclusion: STELLAR框架能有效发现LLM应用中的不当响应，为LLM系统测试提供了自动化解决方案

Abstract: Large Language Model (LLM)-based applications are increasingly deployed across various domains, including customer service, education, and mobility. However, these systems are prone to inaccurate, fictitious, or harmful responses, and their vast, high-dimensional input space makes systematic testing particularly challenging. To address this, we present STELLAR, an automated search-based testing framework for LLM-based applications that systematically uncovers text inputs leading to inappropriate system responses. Our framework models test generation as an optimization problem and discretizes the input space into stylistic, content-related, and perturbation features. Unlike prior work that focuses on prompt optimization or coverage heuristics, our work employs evolutionary optimization to dynamically explore feature combinations that are more likely to expose failures. We evaluate STELLAR on three LLM-based conversational question-answering systems. The first focuses on safety, benchmarking both public and proprietary LLMs against malicious or unsafe prompts. The second and third target navigation, using an open-source and an industrial retrieval-augmented system for in-vehicle venue recommendations. Overall, STELLAR exposes up to 4.3 times (average 2.5 times) more failures than the existing baseline approaches.

</details>


### [57] [SEMODS: A Validated Dataset of Open-Source Software Engineering Models](https://arxiv.org/abs/2601.00635)
*Alexandra González,Xavier Franch,Silverio Martínez-Fernández*

Main category: cs.SE

TL;DR: SEMODS是一个包含3,427个Hugging Face模型的软件工程专用数据集，通过自动化收集和人工标注结合LLM辅助验证构建，将模型与软件开发生命周期任务关联，支持数据分析、模型发现、基准测试等应用。


<details>
  <summary>Details</summary>
Motivation: 随着Hugging Face上数百万模型的增长，缺乏专门针对软件工程任务的模型目录，使得识别适合SE任务的模型变得困难且低效。

Method: 从Hugging Face提取3,427个模型，采用自动化收集与严格验证相结合的方法，包括人工标注和大型语言模型辅助验证，将模型与软件开发生命周期任务和活动关联。

Result: 构建了SEMODS数据集，包含3,427个SE相关模型，提供标准化的评估结果表示，支持数据分析和模型发现等多种应用。

Conclusion: SEMODS填补了软件工程领域专用模型目录的空白，为AI在SE中的集成提供了重要资源，支持模型发现、基准测试和适应等应用。

Abstract: Integrating Artificial Intelligence into Software Engineering (SE) requires having a curated collection of models suited to SE tasks. With millions of models hosted on Hugging Face (HF) and new ones continuously being created, it is infeasible to identify SE models without a dedicated catalogue. To address this gap, we present SEMODS: an SE-focused dataset of 3,427 models extracted from HF, combining automated collection with rigorous validation through manual annotation and large language model assistance. Our dataset links models to SE tasks and activities from the software development lifecycle, offering a standardized representation of their evaluation results, and supporting multiple applications such as data analysis, model discovery, benchmarking, and model adaptation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [58] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 本文提出了一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，超越表面语义相似性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略以优化LLM性能仍是一个重要挑战。现有方法往往只关注表面语义相似性，而忽略了与对话逻辑结构对齐的知识检索。

Method: 提出推理感知的知识检索方法，采用粗到细的两阶段检索策略：1）首先识别知识库中与上下文相关的子区域，确保所有句子都与主题相关；2）在该子区域内细化搜索，提取与推理过程特别相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过共同关键词在知识句子中有效导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更紧密地与人际对话中的底层推理对齐，还显著提高了检索知识的多样性，从而产生更具信息性和创造性的响应。

Conclusion: 提出的推理感知知识检索方法通过整合检索和推理策略，超越了传统的表面语义相似性检索，能够为LLMs提供与对话逻辑结构更一致的知识，从而提升模型在对话任务中的表现。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [59] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 该论文设计了一个基于大语言模型（LLM）的智能体，能够从原始文本中提取因果反馈模糊认知图（FCMs），并通过双向交互过程使FCM动态系统获得一定程度的自主性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个能够从文本中自动提取因果关系的智能系统，通过LLM智能体与FCM动态系统的双向交互，使系统能够在保持"智能体牵引"的同时获得一定自主性，从而更好地理解和建模复杂因果系统。

Method: 方法包括：1）设计一个LLM智能体，通过三个精细调整的系统指令逐步提取文本中的关键名词和名词短语；2）从这些名词中提取FCM概念节点；3）推断节点之间的部分或模糊因果边。最后混合不同LLM智能体生成的FCMs。

Result: 测试结果显示：1）三步骤过程生成的FCM动态系统与人工生成的FCMs收敛到相同的平衡极限环，尽管节点和边数量不同；2）混合不同LLM智能体生成的FCMs能够吸收主要混合组分的平衡点，同时创建新的平衡点，更好地近似底层因果动态系统。

Conclusion: 该研究成功开发了一个能够从文本中提取因果关系的LLM智能体系统，通过双向交互赋予FCM动态系统一定自主性。混合不同LLM生成的FCMs能够产生更丰富的平衡状态，更好地建模复杂因果系统，展示了LLM在因果推理和动态系统建模方面的潜力。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [60] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了一种基于大语言模型的尼日利亚皮钦语抑郁症自动筛查工具，通过微调LLMs适应尼日利亚本土语言，解决了传统PHQ-9问卷在低收入国家的语言文化障碍问题。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，主要障碍包括临床医生资源不足、社会污名化和语言文化障碍。传统PHQ-9问卷在高收入国家验证，但在尼日利亚这样的多语言环境中存在语言和文化不适应性，特别是当地居民使用尼日利亚皮钦语和520多种地方语言。

Method: 研究收集了432名18-40岁尼日利亚年轻人的皮钦语音频回答，内容基于PHQ-9项目的心理体验评估。进行了转录、严格预处理和标注，包括语义标注、俚语和习语解释、PHQ-9严重程度评分。对三种LLMs（Phi-3-mini-4k-instruct、Gemma-3-4B-it和GPT-4.1）在该标注数据集上进行微调，并从定量（准确性、精确度和语义对齐）和定性（清晰度、相关性和文化适宜性）两方面评估性能。

Result: GPT-4.1在定量评估中表现最佳，PHQ-9严重程度评分预测准确率达到94.5%，优于Gemma-3-4B-it和Phi-3-mini-4k-instruct。在定性评估中，GPT-4.1也产生了最具文化适宜性、清晰度和上下文相关性的回答。

Conclusion: 该研究为在语言多样、资源有限的环境中部署对话式心理健康工具奠定了基础，展示了AI介导的抑郁症筛查在服务不足的尼日利亚社区中的潜力。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [61] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文提出了一种多算法方法来解决最后一公里包裹配送系统中的人力资源工作量平衡问题，通过结合距离和工作量考虑来优化包裹分配，确保每位配送员完成相似的工作量。


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法效率低下，导致配送员之间工作量分配不均衡。需要优化配送系统，通过工作量平衡来改善配送时间，纠正特定区域内配送员之间的显著工作量不平衡问题。

Method: 提出多算法方法，包括不同版本的k-means算法、进化方法、基于k-means初始化的递归分配（采用不同问题编码）以及混合进化集成算法。这些算法结合距离和工作量考虑来优化包裹分配。

Result: 在西班牙Azuqueca de Henares城市最后一公里包裹配送系统的实际案例中验证了所提方法的性能。

Conclusion: 通过多算法方法可以有效解决最后一公里包裹配送系统的人力资源工作量平衡问题，确保配送员之间工作量均衡分配，提高系统效率。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [62] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 本文提出了一种基于规则的战略框架，使用新的MinDist手牌评估指标来改进13张牌印度拉米游戏的算法策略


<details>
  <summary>Details</summary>
Motivation: 13张牌印度拉米是一种不完全信息的序列游戏，需要概率推理和组合决策。传统启发式方法存在局限性，需要更形式化和可解释的策略设计方法。

Method: 提出基于规则的策略框架，引入MinDist手牌评估指标（修改MinScore指标，量化手牌与最近有效配置的编辑距离）。设计计算高效的算法，利用动态剪枝和模式缓存精确计算该指标。在双人零和模拟框架中融入对手手牌建模，并使用统计假设检验评估策略。

Result: 实证结果显示，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，为算法拉米策略设计提供了形式化和可解释的步骤。

Conclusion: MinDist指标能够有效捕捉手牌完成的结构接近度，基于此的算法策略在13张牌印度拉米游戏中表现出优越性能，为不完全信息游戏中的组合决策提供了新的方法框架。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [63] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究探索生成式AI如何理解乡土建筑中的建筑智慧，以伊朗鸽塔为例，测试三种扩散模型在不同提示阶段的表现，评估AI对建筑类型、材料、环境等要素的重构能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索生成式AI系统如何解释乡土建筑形式中蕴含的建筑智慧，理解AI在感知、扭曲和重新想象传统设计智能方面的能力边界。

Method: 使用伊朗鸽塔作为案例研究，测试Midjourney v6、DALL-E 3和基于Stable Diffusion XL的DreamStudio三种扩散模型，通过参考性、适应性和推测性三个提示阶段，采用五标准评估框架（类型学、材料性、环境、真实性和文化特异性）进行分析。

Result: AI能可靠地再现几何图案，但误解材料和气候推理；参考图像能提高真实性但限制创造力，而脱离参考则能产生创新但文化模糊的结果；研究定义了视觉相似性与建筑推理之间的边界。

Conclusion: 研究提出了计算乡土推理框架，用于分析AI如何感知、扭曲和重新想象传统设计智能，揭示了AI在建筑理解方面的能力与局限。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [64] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法和大型语言模型，自动演化游戏机制，通过合成完整游戏并评估技能排序能力来优化机制设计。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计通常需要大量时间和专家参与，是一个耗时且专业驱动的过程。手动设计游戏机制限制了游戏设计的创新性和多样性。

Method: Mortar系统结合质量多样性算法和大型语言模型，探索多样化的游戏机制。通过树搜索程序合成完整游戏，评估机制对技能排序的贡献度，即强玩家是否始终优于弱玩家。

Result: Mortar能够生成多样且可玩的游戏，产生的游戏机制对技能排序得分有更大贡献。消融研究和用户研究验证了系统组件的有效性。

Conclusion: Mortar系统成功实现了游戏机制的自主演化，通过结合质量多样性算法和语言模型，能够生成多样、可玩且具有良好技能排序特性的游戏机制。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [65] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 该研究探讨了在视频问答任务中，基于置信度的选择性预测能否可靠控制错误率，以及这种控制在分布偏移下是否稳健。研究发现，置信度阈值在分布内能提供机制性控制，但在分布偏移下可靠性下降。


<details>
  <summary>Details</summary>
Motivation: 在视觉语言模型的高风险部署中，需要选择性预测机制，让系统在不确定时选择弃权而非冒险犯错。研究旨在验证置信度弃权能否在视频问答中提供可靠的错误率控制，以及这种控制在分布偏移下是否稳健。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型进行研究。通过扫描置信度阈值epsilon来产生风险-覆盖权衡曲线，评估置信度阈值在分布内和分布偏移下的表现。

Result: 研究发现：1) 置信度阈值在分布内能提供机制性控制，通过调整阈值可以平滑地降低错误率；2) 但在分布偏移下，这种控制的可靠性显著下降。

Conclusion: 虽然置信度阈值在分布内能有效控制错误率，但在面对分布偏移时其可靠性不足，这表明需要开发更稳健的选择性预测方法来应对现实世界中的分布变化。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [66] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM驱动的智能体不仅存在人口统计偏见，还会在最小"我们vs他们"线索下表现出群体间偏见。当这种群体边界与智能体-人类划分重合时，风险从人类群体间差异转向更根本的群体不对称性——人类整体可能被智能体视为外群体。研究还提出了信念投毒攻击(BPA)来抑制人类规范脚本并重新激活对人类的偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究LLM驱动的智能体是否会在最小群体线索下表现出群体间偏见，特别是当这种群体边界与智能体-人类划分重合时，人类整体是否会被智能体视为外群体。这涉及到从人口统计偏见向更根本的群体不对称性风险的转变。

Method: 研究方法包括：1)构建基于分配决策的受控多智能体社会模拟，在明确收益权衡下测试群体间偏见；2)提出信念投毒攻击(BPA)，包括初始化时的配置文件投毒(BPA-PP)和通过优化信念精炼后缀注入存储反思的内存投毒(BPA-MP)；3)通过大量实验验证智能体群体间偏见的存在和BPA的严重性。

Result: 实验结果显示：1)智能体在最小群体线索下表现出一致的群体间偏见；2)当部分对应方被框架为人类时，这种偏见会减弱，但这种减弱归因于只有在智能体相信真实人类存在时才会激活的隐含人类规范脚本；3)BPA攻击能够有效抑制人类规范脚本并重新激活对人类的偏见，证明了当前智能体框架的脆弱性。

Conclusion: 研究结论是智能体确实存在群体间偏见，且当群体边界与智能体-人类划分重合时，人类可能被整体视为外群体。信念依赖创造了新的攻击面，BPA攻击能够利用这一漏洞。研究提出了在配置文件和内存边界进行干预的实用缓解策略，目标是促进更安全的智能体设计而非实际利用这些漏洞。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [67] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: ACCD框架通过三阶段渐进式架构，采用记忆引导自适应机制动态学习最优检测配置，显著提升社交平台协同不实行为检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有社交平台协同不实行为检测方法存在依赖表面相关性分析、使用静态参数设置、需要大量人工标注等问题，需要更系统化的解决方案。

Method: 提出自适应因果协调检测（ACCD）框架，包含三阶段：1）自适应收敛交叉映射技术识别账户间真实因果关系；2）半监督分类中集成主动学习和不确定性采样减少人工标注；3）基于历史检测经验的自动化验证模块实现自我验证和优化。

Result: 在真实数据集（Twitter IRA、Reddit协调痕迹等）上评估，ACCD在协同攻击检测中达到87.3%的F1分数，比现有最强基线提升15.2%，减少68%人工标注需求，通过层次聚类优化实现2.8倍处理加速。

Conclusion: ACCD为社交平台协同行为识别提供了更准确、高效、高度自动化的端到端解决方案，具有重要的实际应用价值和广阔的应用前景。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [68] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 该论文将语义空间推理从计算语言学扩展到团队运动的战术决策，将球员视为"词语"，团队配置视为"语义结构"，通过向量空间建模战术匹配度并生成适应性策略建议。


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学的语义空间推理方法可以类比应用于团队运动的战术决策，将球员视为词语、团队配置视为语义结构，为战术分析和优化提供新的理论框架。

Method: 将球员表示为整合技术、身体和心理属性的多维向量，通过上下文加权聚合成团队语义表示；在共享向量空间中编码战术模板（如高位压迫、反击），使用向量距离度量评估战术"匹配度"和对手利用潜力。

Result: 开发了Python原型系统，能够生成可解释的动态适应性策略建议，并提供属性层面的细粒度诊断洞察；该方法可推广到篮球、曲棍球、协作机器人、人机协调系统等团队领域。

Conclusion: 该研究为集体决策和团队表现优化提供了通用框架，未来方向包括真实数据集成、预测模拟以及混合人机战术智能系统的开发。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [69] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟时刻"很少见，不会随训练变得更频繁，也很少提高准确性，表明它们不是真正的自我修正机制，而是推理不稳定的表现。


<details>
  <summary>Details</summary>
Motivation: 先前研究认为像DeepSeek-R1-Zero这样的模型会在推理过程中经历突然的"顿悟时刻"，从而实现准确输出，暗示其具有内在的自我修正能力。但尚不清楚这种推理策略的内在转变是否真正提升了性能。

Method: 研究分析了超过100万条推理轨迹、数百个训练检查点、三个推理领域、多种解码温度和模型架构。通过检测训练运行中的推理转变，并基于模型不确定性研究其影响。

Result: 研究发现：1) 推理转变很罕见；2) 不会随训练变得更频繁；3) 很少提高准确性；4) 其效果随模型不确定性而变化。在高熵条件下人为触发外在转变可以可靠地提高准确性。

Conclusion: 推理过程中的转变是不稳定推理行为的表现，而非内在的自我修正机制。它们反映了模型在不确定性下的推理不稳定性，而非真正的"顿悟"。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [70] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出了一种难度感知的直接偏好优化框架，通过估计偏好数据的难度并重新加权训练样本，解决多模态大语言模型中偏好优化过拟合问题，提高幻觉抑制效果。


<details>
  <summary>Details</summary>
Motivation: 现有多模态DPO方法由于偏好数据难度不平衡容易过拟合，模型倾向于过度关注容易区分的偏好对，这阻碍了细粒度幻觉抑制并降低整体性能。

Method: DA-DPO包含两个主要组件：1) 难度估计：利用预训练的视觉-语言模型，结合生成式和对比式目标，通过分布感知投票策略产生鲁棒的难度分数；2) 难度感知训练：基于估计难度重新加权偏好对，降低简单样本权重，强调困难样本以缓解过拟合。

Result: 大量实验表明，DA-DPO持续改进多模态偏好优化，在标准基准测试中表现出更强的幻觉鲁棒性和更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO通过难度感知的偏好优化框架，有效解决了多模态大语言模型中偏好优化过拟合问题，提高了幻觉抑制效果和模型性能，且无需额外数据或微调阶段。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [71] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM是一个结合视觉特征、文本数据和交通领域知识的行人过街行为推理框架，通过增强LLaMA-2-7B模型实现从站点特定模式识别到可泛化行为推理的转变，在未见场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推理方法（从统计模型到监督学习方法）泛化能力有限，在新场景中表现不佳。虽然大语言模型提供了从数值模式拟合到语义、上下文感知行为推理的转变，但现有LLM应用缺乏领域特定适应和视觉上下文。

Method: 提出PedX-LLM框架，集成LLaVA提取的视觉特征与文本数据及交通领域知识，通过低秩适应（LoRA）微调LLaMA-2-7B基础模型来推理行人过街决策。

Result: PedX-LLM达到82.0%的平衡准确率，优于最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识集成带来额外4.1%改进。在五个未见测试站点上，零样本配置达到66.9%平衡准确率，比基线数据驱动方法至少高18个百分点。通过少样本学习（仅5个验证示例）进一步提升到72.2%。

Conclusion: PedX-LLM在未见场景中表现出强大的泛化能力，证实视觉和知识增强的推理使模型能够模仿人类决策逻辑，克服纯数据驱动方法的局限性。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [72] [A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies](https://arxiv.org/abs/2601.00510)
*Jetlir Duraj,Ishita Khan,Kilian Merkelbach,Mehran Elyasi*

Main category: cs.IR

TL;DR: 本文提出了一种结合树搜索与LLM语义评分的链式思维方法，用于电商搜索查询分类，相比基于嵌入的方法表现更优，并能检测分层分类法中的问题。


<details>
  <summary>Details</summary>
Motivation: 电商搜索依赖于结构化的库存分类体系，准确地将用户查询分类到正确的叶子类别至关重要，这不仅能精确定位库存空间，还能开启对查询的多重意图理解能力。然而，在实际电商分类法中实现准确查询分类是一个基础且具有挑战性的问题。

Method: 探索了一种新颖的链式思维范式，将简单的树搜索与大型语言模型的语义评分相结合。该方法通过LLM评估查询与类别之间的语义相关性，同时利用树结构进行高效搜索。此外，还提出了具有相同思路但能扩展到百万级查询规模的LLM方法。

Result: 在人工评判的查询-类别对、相关性测试以及与基于LLM的参考方法比较中，链式思维方法的分类性能优于基于嵌入的查询类别预测基准。该方法还能有效检测分层分类法中的问题。

Conclusion: 链式思维方法为电商查询分类提供了一种实用且准确的解决方案，优于传统的嵌入方法，并能识别分类体系中的结构问题。同时提出的可扩展方法为大规模应用提供了可能。

Abstract: Search in e-Commerce is powered at the core by a structured representation of the inventory, often formulated as a category taxonomy. An important capability in e-Commerce with hierarchical taxonomies is to select a set of relevant leaf categories that are semantically aligned with a given user query. In this scope, we address a fundamental problem of search query categorization in real-world e-Commerce taxonomies. A correct categorization of a query not only provides a way to zoom into the correct inventory space, but opens the door to multiple intent understanding capabilities for a query. A practical and accurate solution to this problem has many applications in e-commerce, including constraining retrieved items and improving the relevance of the search results. For this task, we explore a novel Chain-of-Thought (CoT) paradigm that combines simple tree-search with LLM semantic scoring. Assessing its classification performance on human-judged query-category pairs, relevance tests, and LLM-based reference methods, we find that the CoT approach performs better than a benchmark that uses embedding-based query category predictions. We show how the CoT approach can detect problems within a hierarchical taxonomy. Finally, we also propose LLM-based approaches for query-categorization of the same spirit, but which scale better at the range of millions of queries.

</details>


### [73] [Improving Scientific Document Retrieval with Academic Concept Index](https://arxiv.org/abs/2601.00567)
*Jeyun Lee,Junhyoung Lee,Wonbin Kweon,Bowen Jin,Yu Zhang,Susik Yoon,Dongha Lee,Hwanjo Yu,Jiawei Han,Seongku Kang*

Main category: cs.IR

TL;DR: 本文提出了一种学术概念索引方法，通过提取论文中的关键概念并按学术分类法组织，用于改进科学领域检索器的两个方向：基于概念覆盖的查询生成和概念聚焦的上下文增强。


<details>
  <summary>Details</summary>
Motivation: 将通用领域检索器适配到科学领域面临两大挑战：缺乏大规模领域相关性标注数据，以及词汇和信息需求存在显著不匹配。现有基于大语言模型的方法（生成合成查询和辅助上下文）往往忽略了科学文档中嵌入的多样化学术概念，导致生成冗余或概念狭窄的查询和上下文。

Method: 1. 构建学术概念索引：从论文中提取关键概念，按学术分类法组织
2. CCQGen（概念覆盖查询生成）：基于未覆盖概念自适应地引导LLM生成补充查询，实现更广泛的概念覆盖
3. CCExpand（概念聚焦上下文增强）：利用文档片段作为概念感知查询的简洁响应，生成辅助上下文

Result: 实验表明，将学术概念索引整合到查询生成和上下文增强中，能够产生更高质量的查询、更好的概念对齐，并显著提升检索性能。

Conclusion: 通过构建学术概念索引并应用于查询生成和上下文增强两个方向，能够有效解决科学领域检索中的概念覆盖不足问题，提高检索器的适应性和性能。

Abstract: Adapting general-domain retrievers to scientific domains is challenging due to the scarcity of large-scale domain-specific relevance annotations and the substantial mismatch in vocabulary and information needs. Recent approaches address these issues through two independent directions that leverage large language models (LLMs): (1) generating synthetic queries for fine-tuning, and (2) generating auxiliary contexts to support relevance matching. However, both directions overlook the diverse academic concepts embedded within scientific documents, often producing redundant or conceptually narrow queries and contexts. To address this limitation, we introduce an academic concept index, which extracts key concepts from papers and organizes them guided by an academic taxonomy. This structured index serves as a foundation for improving both directions. First, we enhance the synthetic query generation with concept coverage-based generation (CCQGen), which adaptively conditions LLMs on uncovered concepts to generate complementary queries with broader concept coverage. Second, we strengthen the context augmentation with concept-focused auxiliary contexts (CCExpand), which leverages a set of document snippets that serve as concise responses to the concept-aware CCQGen queries. Extensive experiments show that incorporating the academic concept index into both query generation and context augmentation leads to higher-quality queries, better conceptual alignment, and improved retrieval performance.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [74] [Word Frequency Counting Based on Serverless MapReduce](https://arxiv.org/abs/2601.00380)
*Hanzhe Li,Bingchen Lin,Mengyuan Xu*

Main category: cs.DC

TL;DR: 本文提出了一种基于无服务器计算平台的MapReduce编程模型，通过优化Map和Reduce函数的数量来提升词频统计任务的执行效率和减少时间跨度。


<details>
  <summary>Details</summary>
Motivation: 随着对高性能和高效率计算需求的增长，无服务器计算（特别是函数即服务）和MapReduce大数据处理模型成为研究热点。本文旨在结合两者的优势，利用无服务器框架的高并发性和MapReduce模型的鲁棒性，提升词频统计任务的执行效率。

Method: 采用基于无服务器计算平台的MapReduce编程模型，通过实验探索特定任务中最优的Map函数和Reduce函数数量配置。

Result: 大量实验表明，随着Map函数和Reduce函数数量的增加，相同工作负载下的执行时间减少，程序整体效率以不同速率提升。

Conclusion: 发现最优的Map和Reduce函数数量配置可以帮助企业和程序员找到最优化解决方案，提升大数据处理任务的效率。

Abstract: With the increasing demand for high-performance and high-efficiency computing, cloud computing, especially serverless computing, has gradually become a research hotspot in recent years, attracting numerous research attention. Meanwhile, MapReduce, which is a popular big data processing model in the industry, has been widely applied in various fields. Inspired by the serverless framework of Function as a Service and the high concurrency and robustness of MapReduce programming model, this paper focus on combining them to reduce the time span and increase the efficiency when executing the word frequency counting task. In this case, the paper use a MapReduce programming model based on a serverless computing platform to figure out the most optimized number of Map functions and Reduce functions for a particular task. For the same amount of workload, extensive experiments show both execution time reduces and the overall efficiency of the program improves at different rates as the number of map functions and reduce functions increases. This paper suppose the discovery of the most optimized number of map and reduce functions can help cooperations and programmers figure out the most optimized solutions.

</details>


### [75] [Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving](https://arxiv.org/abs/2601.00397)
*Amey Agrawal,Mayank Yadav,Sukrit Kumar,Anirudha Agrawal,Garv Ghai,Souradeep Bera,Elton Pinto,Sirish Gambhira,Mohammad Adain,Kasra Sohrab,Chus Antonanzas,Alexey Tumanov*

Main category: cs.DC

TL;DR: Revati是一个时间扭曲仿真器，通过直接执行真实服务系统代码实现性能建模，无需物理GPU，比真实GPU执行快5-17倍，预测误差小于5%


<details>
  <summary>Details</summary>
Motivation: 部署LLM需要测试数百种服务配置，但在GPU集群上评估每个配置需要数小时和数千美元成本。离散事件仿真器虽然更快更便宜，但需要重新实现服务系统的控制逻辑，随着框架演进负担加重。

Method: Revati是一个时间扭曲仿真器，通过拦截CUDA API调用来虚拟化设备管理，允许服务框架在没有物理GPU的情况下运行。系统不执行GPU内核，而是执行时间跳跃——通过预测的内核持续时间快速推进虚拟时间。提出了协调协议来同步分布式进程中的这些跳跃，同时保持因果关系。

Result: 在vLLM和SGLang上，Revati在多个模型和并行配置中实现了小于5%的预测误差，同时运行速度比真实GPU执行快5-17倍。

Conclusion: Revati通过直接执行真实服务系统代码实现快速准确的性能建模，解决了传统仿真器需要重新实现控制逻辑的问题，为LLM服务配置优化提供了高效工具。

Abstract: Deploying LLMs efficiently requires testing hundreds of serving configurations, but evaluating each one on a GPU cluster takes hours and costs thousands of dollars. Discrete-event simulators are faster and cheaper, but they require re-implementing the serving system's control logic -- a burden that compounds as frameworks evolve.
  We present Revati, a time-warp emulator that enables performance modeling by directly executing real serving system code at simulation-like speed. The system intercepts CUDA API calls to virtualize device management, allowing serving frameworks to run without physical GPUs. Instead of executing GPU kernels, it performs time jumps -- fast-forwarding virtual time by predicted kernel durations. We propose a coordination protocol that synchronizes these jumps across distributed processes while preserving causality. On vLLM and SGLang, Revati achieves less than 5% prediction error across multiple models and parallelism configurations, while running 5-17x faster than real GPU execution.

</details>


### [76] [Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure](https://arxiv.org/abs/2601.00530)
*Ravi Teja Pagidoju*

Main category: cs.DC

TL;DR: 本文对谷歌云平台(GCP)和微软Azure上的零售POS系统部署进行了系统性对比，使用免费层资源和开源基准测试代码，发现GCP响应时间快23.0%，Azure成本效率高71.9%。


<details>
  <summary>Details</summary>
Motivation: 零售业数字化转型加速了基于云的POS系统采用，但缺乏针对零售工作负载的平台特定性能实证研究，特别是小型零售商和研究人员可用的透明评估方法。

Method: 使用免费层云资源和开源基准测试代码，通过实时API端点对GCP和Azure进行系统性、可重复的POS工作负载部署比较，测量响应延迟、吞吐量、可扩展性等关键性能指标，并基于实际资源使用和当前公有云定价估算运营成本。

Result: GCP在基准负载下实现23.0%更快的响应时间，而Azure在稳态操作中显示71.9%更高的成本效率。所有表格和图表直接从代码输出生成，确保实验数据与报告结果一致。

Conclusion: 本研究建立了强大的零售云应用开放基准测试方法，首次提供了跨领先云平台的POS系统特有工作负载的全面代码驱动比较，为考虑云POS实施的商家提供了有用框架。

Abstract: Althoughthereislittleempiricalresearchonplatform-specific performance for retail workloads, the digital transformation of the retail industry has accelerated the adoption of cloud-based Point-of-Sale (POS) systems. This paper presents a systematic, repeatable comparison of POS workload deployments on Google Cloud Platform (GCP) and Microsoft Azure using real-time API endpoints and open-source benchmarking code. Using free-tier cloud resources, we offer a transparent methodology for POS workload evaluation that small retailers and researchers can use. Our approach measures important performance metrics like response latency, throughput, and scalability while estimating operational costs based on actual resource usage and current public cloud pricing because there is no direct billing under free-tier usage. All the tables and figures in this study are generated directly from code outputs, ensuring that the experimental data and the reported results are consistent. Our analysis shows that GCP achieves 23.0% faster response times at baseline load, while Azure shows 71.9% higher cost efficiency for steady-state operations. We look at the architectural components that lead to these differences and provide a helpful framework for merchants considering cloud point-of-sale implementation. This study establishes a strong, open benchmarking methodology for retail cloud applications and offers the first comprehensive, code-driven comparison of workloads unique to point-of-sale systems across leading cloud platforms.

</details>


### [77] [FlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding](https://arxiv.org/abs/2601.00644)
*Yuchen Li,Rui Kong,Zhonghao Lyu,Qiyang Li,Xinran Chen,Hengyi Cai,Lingyong Yan,Shuaiqiang Wang,Jiashu Zhao,Guangxu Zhu,Linghe Kong,Guihai Chen,Haoyi Xiong,Dawei Yin*

Main category: cs.DC

TL;DR: FlexSpec是一个针对边缘-云协作推理的通信高效框架，通过共享骨干架构和自适应推测机制解决传统推测解码中的模型同步开销问题。


<details>
  <summary>Details</summary>
Motivation: 在移动和边缘计算环境中部署大语言模型面临资源限制、无线带宽稀缺和模型频繁更新的挑战。现有的边缘-云协作推理框架依赖于边缘草稿模型和云端目标模型的紧密耦合，导致重复的模型同步带来过大的通信开销，增加了端到端延迟，限制了推测解码在边缘环境中的可扩展性。

Method: FlexSpec采用共享骨干架构，使单个静态的边缘侧草稿模型能够与一系列演进的云端目标模型保持兼容，从而解耦边缘部署与云端模型更新。此外，开发了信道感知自适应推测机制，根据实时信道状态信息和设备能量预算动态调整推测草稿长度。

Result: 大量实验表明，FlexSpec在推理效率方面相比传统推测解码方法取得了优越的性能表现。

Conclusion: FlexSpec通过解耦边缘与云端模型更新，显著减少了通信和维护成本，同时通过自适应推测机制适应了时变的无线条件和异构设备约束，为边缘-云协作推理提供了高效可扩展的解决方案。

Abstract: Deploying large language models (LLMs) in mobile and edge computing environments is constrained by limited on-device resources, scarce wireless bandwidth, and frequent model evolution. Although edge-cloud collaborative inference with speculative decoding (SD) can reduce end-to-end latency by executing a lightweight draft model at the edge and verifying it with a cloud-side target model, existing frameworks fundamentally rely on tight coupling between the two models. Consequently, repeated model synchronization introduces excessive communication overhead, increasing end-to-end latency, and ultimately limiting the scalability of SD in edge environments. To address these limitations, we propose FlexSpec, a communication-efficient collaborative inference framework tailored for evolving edge-cloud systems. The core design of FlexSpec is a shared-backbone architecture that allows a single and static edge-side draft model to remain compatible with a large family of evolving cloud-side target models. By decoupling edge deployment from cloud-side model updates, FlexSpec eliminates the need for edge-side retraining or repeated model downloads, substantially reducing communication and maintenance costs. Furthermore, to accommodate time-varying wireless conditions and heterogeneous device constraints, we develop a channel-aware adaptive speculation mechanism that dynamically adjusts the speculative draft length based on real-time channel state information and device energy budgets. Extensive experiments demonstrate that FlexSpec achieves superior performance compared to conventional SD approaches in terms of inference efficiency.

</details>


<div id='nucl-th'></div>

# nucl-th [[Back]](#toc)

### [78] [Revisiting p-$^{11}$B Fusion: Updated Cross-sections, Reactivity, and Energy Balance](https://arxiv.org/abs/2601.00241)
*Hong-Yi Wang,Yu-Qi Li,Qian Wu,Zhu-Fang Cui*

Main category: nucl-th

TL;DR: 本文开发了p-11B聚变反应截面的高精度参数化模型，评估了热核反应性，并分析了能量平衡，发现使用现代截面数据和自洽热模型时，p-11B聚变不受轫致辐射限制。


<details>
  <summary>Details</summary>
Motivation: 近期实验进展显著改善了p-11B聚变反应的截面数据，特别是在先前缺乏直接测量的能量区域。需要将这些新数据整合到连续且数值高效的表示中，以准确评估该反应的可行性。

Method: 开发了p-11B反应在0-10 MeV能量范围内的高精度分析参数化模型，将新实验数据纳入连续表示。使用该参数化评估热核反应性，分析0.6 MeV处的主共振和新观测到的4.7 MeV共振的影响，并通过分析聚变功率密度和电子轫致辐射功率密度来评估能量平衡。

Result: 结果表明，当使用当代截面数据和自洽热模型时，p-11B聚变不受轫致辐射约束的限制。新参数化提供了连续且数值高效的截面表示，能够准确评估反应性。

Conclusion: p-11B聚变反应在能量平衡方面是可行的，不受轫致辐射功率的限制，这为基于该反应的聚变能开发提供了积极的前景。

Abstract: Recent experimental progress has substantially improved the available cross-section data for the p-$^{11}$B fusion reaction, particularly in energy regions that previously lacked direct measurements. In this study, we develop a high-precision analytical parameterization of the p-$^{11}$B reaction cross-section over the 0--10 MeV energy range, incorporating the new experimental data into a continuous and numerically efficient representation. Using this parameterization, we evaluate the thermonuclear reactivity of the p-$^{11}$B reaction and examine the effects of the dominant resonance at 0.6 MeV and a newly observed resonance around 4.7 MeV. Furthermore, we assess the energy balance by analyzing the fusion power density and the electron bremsstrahlung power density. Our results indicate that p-$^{11}$B fusion is not precluded by bremsstrahlung constraints when contemporary cross-section data and self-consistent thermal modeling are employed.

</details>


### [79] [Toward $\textit{Ab Initio}$ Quantum Simulations of Atomic Nuclei Using Noisy Qubits](https://arxiv.org/abs/2601.00315)
*Chongji Jiang,Junchen Pei,Rongzhe Hu,Shaoliang Jin,Haoyu Shang,Siqin Fan,Furong Xu*

Main category: nucl-th

TL;DR: 该论文展示了在噪声量子设备上实现氚核从头算量子模拟，通过测量优化和粒子数投影技术显著提高了效率和精度。


<details>
  <summary>Details</summary>
Motivation: 量子计算机有望成为量子多体系统的终极求解器，但在当前噪声量子设备上实现这一目标面临巨大挑战。本文旨在解决从头算核物理量子模拟中的效率和噪声问题。

Method: 采用量子模拟方法进行氚核的无核壳模型从头算计算，结合手征二核子和三核子力。使用通用对易性测量和渐近优化显著降低测量成本，并应用粒子数投影测量来减少噪声引起的粒子数污染。

Result: 测量成本显著降低，噪声引起的粒子数污染问题得到有效改善，计算精度大幅提升。成功展示了在噪声量子设备上进行原子核从头算量子计算的重要进展。

Conclusion: 通过解决效率和噪声问题，这项工作在实现原子核从头算量子计算方面迈出了实质性的一步，为在噪声量子设备上进行量子多体系统模拟提供了有效方法。

Abstract: Quantum computers are expected to provide a ultimate solver for quantum many-body systems, although it is a tremendous challenge to achieve that goal on current noisy quantum devices. This work illustrated quantum simulations of ab initio no-core shell model calculations of $^3$H with chiral two-nucleon and three-nucleon forces. The measurement costs are remarkably reduced by using the general commutativity measurement together with the asymptotic optimization. In addition, the noise causes serious contaminations of configurations with undesired particle numbers, and the accuracies are much improved by applying the particle number projected measurement. By tackling the efficiency and noise issues, this work demonstrated a substantial step toward ab initio quantum computing of atomic nuclei.

</details>


### [80] [Comparison of Relativistic and Non-relativistic Faddeev calculations for Proton-Deuteron Elastic Scattering](https://arxiv.org/abs/2601.00534)
*H. Kamada,A. Arslanaliev,Y. Kostylenko,A. V. Shebeko,J. Golak,R. Skibiński,K. Topolnicki,V. Chahar,D. F. Ramírez Jiménez,H. Witała,W. N. Polyzou*

Main category: nucl-th

TL;DR: 该研究比较了非相对论和相对论核子-核子势在pd散射中的应用，发现相对论效应在135MeV时后向角差异显著，极化观测量在300MeV以下非相对论计算仍可靠


<details>
  <summary>Details</summary>
Motivation: 研究动机是比较传统非相对论核子-核子势（如CDBonn、AV18）与内在相对论的Kharkiv势在pd散射中的表现差异，特别关注相对论效应的影响

Method: 采用Coester-Pieper-Serduke（CPS）和Kamada-Glöckle（KG）转换方法从现实NN势构建伪相对论势（PRP），保持氘核结合能和相移不变；使用相对论Faddeev方程计算微分截面；将Kharkiv势反向转换为伪非相对论势（PNRP）进行分析

Result: 相对论效应在135MeV时后向角差异显著；前向角差异主要源于Kharkiv势本身特性；后向角相对论效应在100-400MeV范围内随能量增加而增强；极化观测量在300MeV以上时相对论效应及CPS与KG转换差异变得显著；300MeV以下非相对论计算使用PRP仍可靠

Conclusion: 相对论效应在pd散射中后向角表现显著，特别是高能区；虽然存在相对论效应，但300MeV以下非相对论计算使用伪相对论势仍能提供可靠的极化观测量预测

Abstract: This investigation compares non-relativistic and relativistic nucleon-nucleon (NN) potentials in the context of pd scattering. Conventional NN potentials (e.g., CDBonn, AV18) rely on the non-relativistic Schrödinger equation, whereas the Kharkiv potential is intrinsically relativistic. We employ the Coester-Pieper-Serduke (CPS) and Kamada-Glöckle (KG) conversion methods to construct a Pseudo-Relativistic Potential (PRP) from a realistic NN potential, preserving the deuteron binding energy and phase shifts. Calculations of the differential cross section using the relativistic Faddeev equation show that relativistic effects particularly the deviation at the backward angle become pronounced at 135 MeV. The differences in the forward angle were attributed to the characteristics of the Kharkiv potential itself. The reverse transformation of the Kharkiv potential into a Pseudo-Non-Relativistic Potential (PNRP) confirms that the backward-angle relativistic effect increases with energy in the range from 100 MeV to 400 MeV. Comparisons of the polarization observables indicate that relativistic effects, as well as the discrepancy between the CPS and KG transformations, become significant above 300 MeV. Nevertheless, non-relativistic calculations using the PRP remain generally reliable for polarization observables below 300 MeV.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [81] [Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective](https://arxiv.org/abs/2601.00257)
*Aly Sabri Abdalla,Vuk Marojevic*

Main category: eess.SY

TL;DR: 本文提出了一种基于O-RAN的低空经济框架，通过语义感知rApp和强化学习xApp实现无人机群在复杂环境中的实时轨迹规划，并探讨了相关研究挑战和标准化需求。


<details>
  <summary>Details</summary>
Motivation: 低空经济应用（如无人机物流和应急响应）在复杂信号受限环境中面临实时、弹性和上下文感知协调的挑战，缺乏专门为LAE任务设计的AI集成。

Method: 提出O-RAN启用的LAE框架，利用解耦的RAN架构、开放接口和RAN智能控制器实现闭环AI优化。通过语义感知rApp作为地形解释器，为强化学习xApp提供语义指导，实现LAE群节点的实时轨迹规划。

Result: 评估了所提架构的可行性和性能，调查了可用于LAE研究的无人机测试平台能力，并提出了关键研究挑战和标准化需求。

Conclusion: O-RAN框架为低空经济任务提供了AI优化、任务关键型操作的支持，需要进一步研究解决相关挑战并推动标准化。

Abstract: Despite the growing interest in low-altitude economy (LAE) applications, including UAV-based logistics and emergency response, fundamental challenges remain in orchestrating such missions over complex, signal-constrained environments. These include the absence of real-time, resilient, and context-aware orchestration of aerial nodes with limited integration of artificial intelligence (AI) specialized for LAE missions. This paper introduces an open radio access network (O-RAN)-enabled LAE framework that leverages seamless coordination between the disaggregated RAN architecture, open interfaces, and RAN intelligent controllers (RICs) to facilitate closed-loop, AI-optimized, and mission-critical LAE operations. We evaluate the feasibility and performance of the proposed architecture via a semantic-aware rApp that acts as a terrain interpreter, offering semantic guidance to a reinforcement learning-enabled xApp, which performs real-time trajectory planning for LAE swarm nodes. We survey the capabilities of UAV testbeds that can be leveraged for LAE research, and present critical research challenges and standardization needs.

</details>


### [82] [Probability-Aware Parking Selection](https://arxiv.org/abs/2601.00521)
*Cameron Hickert,Sirui Li,Zhengbing He,Cathy Wu*

Main category: eess.SY

TL;DR: 该论文提出概率感知停车选择问题，通过动态规划框架帮助司机选择最佳停车位置而非直接前往目的地，考虑停车场可用性的概率信息，显著减少停车搜索时间。


<details>
  <summary>Details</summary>
Motivation: 当前停车导航系统低估总旅行时间，未考虑寻找停车位的时间，这影响了用户体验、交通模式选择、拥堵和排放。需要解决停车搜索时间的问题。

Method: 提出概率感知停车选择问题，采用可适应的动态规划框架进行决策，基于停车场层面的概率可用性信息。通过闭式分析确定何时针对特定停车场或探索替代方案，以及预期时间成本。

Result: 使用美国西雅图真实数据实验显示，随着观测频率增加，平均绝对误差从7%降至2%以下。数据模拟中，概率感知策略相比概率无感知基线节省高达66%的时间，但仍比直接到目的地估计多花123%的时间。

Conclusion: 该方法能有效考虑停车可用性的动态特性，在减少停车搜索时间方面具有可行性，但需要平衡感知基础设施成本与停车时间节省之间的权衡。

Abstract: Current parking navigation systems often underestimate total travel time by failing to account for the time spent searching for a parking space, which significantly affects user experience, mode choice, congestion, and emissions. To address this issue, this paper introduces the probability-aware parking selection problem, which aims to direct drivers to the best parking location rather than straight to their destination. An adaptable dynamic programming framework is proposed for decision-making based on probabilistic information about parking availability at the parking lot level. Closed-form analysis determines when it is optimal to target a specific parking lot or explore alternatives, as well as the expected time cost. Sensitivity analysis and three illustrative cases are examined, demonstrating the model's ability to account for the dynamic nature of parking availability. Acknowledging the financial costs of permanent sensing infrastructure, the paper provides analytical and empirical assessments of errors incurred when leveraging stochastic observations to estimate parking availability. Experiments with real-world data from the US city of Seattle indicate this approach's viability, with mean absolute error decreasing from 7% to below 2% as observation frequency grows. In data-based simulations, probability-aware strategies demonstrate time savings up to 66% relative to probability-unaware baselines, yet still take up to 123% longer than direct-to-destination estimates.

</details>


### [83] [Optimal Transport-Based Decentralized Multi-Agent Distribution Matching](https://arxiv.org/abs/2601.00548)
*Kooktae Lee*

Main category: eess.SY

TL;DR: 本文提出了一种用于多智能体系统分布匹配的分散控制框架，通过最优传输理论实现规定的终端空间分布，采用局部信息处理和记忆校正机制保证可靠运行。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中实现规定的终端空间分布是一个重要问题，传统方法需要全局信息或集中式控制，难以在通信受限的实际场景中应用。本文旨在开发一种完全分散的控制框架，使智能体仅使用局部信息就能实现有效的分布匹配。

Method: 1. 使用最优传输理论（Wasserstein距离）作为分布差异的度量基础；2. 将全局分布匹配目标重构为可处理的每个智能体决策过程；3. 引入顺序权重更新规则构建可行的局部传输计划；4. 加入基于记忆的校正机制以应对间歇性和范围受限的通信；5. 支持线性和非线性智能体动力学。

Result: 建立了收敛性保证，证明了在循环迭代中替代传输成本的改进。仿真结果表明，所提出的框架能够实现有效且可扩展的分布匹配，同时完全以分散方式运行。

Conclusion: 本文成功开发了一种完全分散的多智能体分布匹配控制框架，通过局部信息处理和记忆校正机制，在通信受限条件下实现了有效的分布匹配，为实际多智能体系统应用提供了可行的解决方案。

Abstract: This paper presents a decentralized control framework for distribution matching in multi-agent systems (MAS), where agents collectively achieve a prescribed terminal spatial distribution. The problem is formulated using optimal transport (Wasserstein distance), which provides a principled measure of distributional discrepancy and serves as the basis for the control design. To avoid solving the global optimal transport problem directly, the distribution-matching objective is reformulated into a tractable per-agent decision process, enabling each agent to identify its desired terminal locations using only locally available information. A sequential weight-update rule is introduced to construct feasible local transport plans, and a memory-based correction mechanism is incorporated to maintain reliable operation under intermittent and range-limited communication. Convergence guarantees are established, showing cycle-wise improvement of a surrogate transport cost under both linear and nonlinear agent dynamics. Simulation results demonstrate that the proposed framework achieves effective and scalable distribution matching while operating fully in a decentralized manner.

</details>


### [84] [A formal theory on problem space as a semantic world model in systems engineering](https://arxiv.org/abs/2601.00755)
*Mayuranath SureshKumar,Hanumanthrao Kannan*

Main category: eess.SY

TL;DR: 该论文提出了一种形式化问题空间的理论框架，将问题空间定义为包含理论构造的显式语义世界模型，为系统工程提供了严谨的问题空间表示方法。


<details>
  <summary>Details</summary>
Motivation: 当前系统工程实践中，推理往往直接从利益相关者目标转向规范性工件，使得关于操作环境、可接受交互和上下文条件的基本假设变得隐含或过早嵌入架构或需求中。缺乏对问题空间本身的严谨系统理论表示。

Method: 通过形式化问题空间作为显式语义世界模型，包含在需求和解决方案承诺之前定义的理论构造。开发了公理、定理和推论，建立了明确的边界语义、上下文相关交互可追溯性和问题空间规范充分性的严谨标准。

Result: 建立了一个严谨的理论框架，能够明确区分问题域的真实情况和选择的解决方案。提供了无歧义的边界语义、上下文相关交互到成功利益相关者目标满足的可追溯性，以及问题空间规范的充分性标准。

Conclusion: 该理论为实践者提供了重要指导，通过利益相关者与工程师之间的对话式假设案例研究，展示了如何在设计任何规范性工件之前指导问题框架构建，明确区分问题域和解决方案。

Abstract: Classic problem-space theory models problem solving as a navigation through a structured space of states, operators, goals, and constraints. Systems Engineering (SE) employs analogous constructs (functional analysis, operational analysis, scenarios, trade studies), yet still lacks a rigorous systems-theoretic representation of the problem space itself. In current practice, reasoning often proceeds directly from stakeholder goals to prescriptive artifacts. This makes foundational assumptions about the operational environment, admissible interactions, and contextual conditions implicit or prematurely embedded in architectures or requirements. This paper addresses that gap by formalizing the problem space as an explicit semantic world model containing theoretical constructs that are defined prior to requirements and solution commitments. These constructs along with the developed axioms, theorems and corollary establish a rigorous criterion for unambiguous boundary semantics, context-dependent interaction traceability to successful stakeholder goal satisfaction, and sufficiency of problem-space specification over which disciplined reasoning can occur independent of solution design. It offers a clear distinction between what is true of the problem domain and what is chosen as a solution. The paper concludes by discussing the significance of the theory on practitioners and provides a dialogue-based hypothetical case study between a stakeholder and an engineer, demonstrating how the theory guides problem framing before designing any prescriptive artifacts.

</details>
