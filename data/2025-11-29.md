<div id=toc></div>

# Table of Contents

- [cs.DL](#cs.DL) [Total: 3]
- [nucl-ex](#nucl-ex) [Total: 1]
- [eess.SY](#eess.SY) [Total: 18]
- [cs.SE](#cs.SE) [Total: 7]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.IR](#cs.IR) [Total: 4]
- [nucl-th](#nucl-th) [Total: 3]


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [1] [Access models, authorship patterns, and citation impact in Ukrainian scholarly publishing (2020-2023)](https://arxiv.org/abs/2511.20862)
*Myroslava Hladchenko*

Main category: cs.DL

TL;DR: 本研究分析了2020-2023年乌克兰研究成果的获取模式、作者模式和引用影响之间的关系，重点关注国家科学院和大学学者。研究发现开放获取文章占主导地位，俄罗斯全面入侵对发表模式产生影响，混合金OA、青铜OA和绿色OA文章引用影响最高。


<details>
  <summary>Details</summary>
Motivation: 探索乌克兰研究成果的开放获取模式与引用影响之间的关系，了解俄罗斯入侵对学术出版的影响，为可持续开放获取模式提供参考。

Method: 分析2020-2023年乌克兰国家科学院和大学学者的发表数据，比较不同开放获取模式（金OA、钻石OA、混合金OA、青铜OA、绿色OA）的分布和引用影响。

Result: 开放获取文章占主导（NASU 75.4%，大学85.8%），金OA和混合金OA增长显著。俄罗斯入侵导致外国期刊文章比例下降，国际合著金OA文章增加。混合金OA、青铜OA和绿色OA引用影响最高。

Conclusion: 金OA日益占据主导地位，需要建立既确保公平又促进广泛传播的可持续开放获取模式。

Abstract: This study aimed to explore the relationship between access models, authorship patterns, and citation impact in Ukrainian research output from 2020 to 2023. The focus was on scholars affiliated with the National Academy of Sciences of Ukraine (NASU) and universities. Findings highlight that open access (OA) articles constituted the majority of publications by Ukrainian scholars during this period. This percentage reached 75.4% for NASU and 85.8% for universities. In both cases, the increase was driven by Gold OA and Hybrid Gold OA, the latter benefiting in part from Elsevier's waivers. Diamond OA prevailed for NASU, while Gold OA was dominant for universities. The effects of Russia's full-scale invasion of Ukraine included (1) a decline in the share of articles in foreign journals for both NASU and universities, (2) a decrease in Gold OA in foreign journals and an increase in Gold OA in Ukrainian journals for universities, and (3) a rise in internationally co-authored Gold OA articles in foreign journals for both entities. Despite waivers for Gold OA provided by major publishers and an increase in Gold OA articles in Elsevier and Springer journals, MDPI and Aluna Publishing House remained the dominant publishers of Gold OA in foreign journals. Hybrid Gold OA, Bronze OA, and Green OA articles in foreign journals had the highest citation impact. The citation impact of Gold OA outperformed Diamond OA. The study confirms the growing dominance of Gold OA, suggesting the need for sustainable OA models that ensure both equity and broad dissemination of research.

</details>


### [2] [Prevalence and Trends in Global Retractions Explored Through a Topic Lens](https://arxiv.org/abs/2511.21176)
*Zhengyi Zhou,Ying Lou,Zhesi Shen,Menghui Li*

Main category: cs.DL

TL;DR: 该研究通过主题视角分析全球论文撤稿趋势，发现撤稿数量持续高位增长且增速远超论文发表增速，不同学科领域撤稿分布不均，某些特定主题同时出现发表量激增和异常高撤稿率的现象。


<details>
  <summary>Details</summary>
Motivation: 近年来科学论文撤稿数量显著增加，主要由于低质量和欺诈性论文泛滥，需要从主题角度系统分析撤稿趋势及其演变规律。

Method: 分析全球撤稿数据，通过主题视角考察不同学科领域的撤稿分布特征和异常模式。

Result: 撤稿数量持续高位增长，增速超过全球论文发表增速；撤稿分布不均，高撤稿率学科中某些主题问题轻微，低撤稿率学科中某些主题问题严重；特定主题同时出现发表激增和异常高撤稿率。

Conclusion: 研究识别出多个指标可帮助科学界识别需要严格审查的关键领域，为不同主题制定针对性治理政策以提升研究诚信提供重要参考。

Abstract: Scientific publications form the cornerstone of innovation and have maintained a stable growth trend over the years. However, in recent years, there has been a significant surge in retractions, driven largely by the proliferation of low-quality and fraudulent papers. This study aims to examine retractions and their evolving trends through a topic lens. Our analysis of global retraction data reveals that the numbers of retraction have remained alarmingly high in recent years, with the growth rate of retracted papers significantly outpacing that of overall global publications. While retractions are observed across various fields, their distribution is not uniform. In disciplines characterized by high retraction rates, certain topics may only encounter minor issues, whereas in fields with lower retraction rates, some topics can experience substantial challenges. Moreover, an unexpected surge in publications has been observed in specific topics that also display abnormally high retraction rates. This study underscores several indicators that can assist the scientific community in pinpointing key fields that require rigorous scrutiny for potential low-quality and fraudulent research. Ultimately, our findings could serve as a benchmark for examining scientific integrity across diverse topics and offer crucial insights for developing tailored governance policies to enhance research integrity in each field.

</details>


### [3] [The Intertwined Rise of Collaboration Scale, Reference Diversity, and Breakthrough Potential in Modern Science: A 40-Year Cross-Disciplinary Study](https://arxiv.org/abs/2511.21505)
*Sarah J. James,Marcus A. Rodriguez,David P. Miller*

Main category: cs.DL

TL;DR: 本研究分析了1970-2010年间1500万篇论文，发现学术知识生产方式发生重大转变：研究团队规模扩大，引文来源更广泛多样，高影响力发现更多来自复杂合作。不同学科存在显著差异，基于更广泛知识基础的论文获得更多引用，大型团队平均影响力更大但存在规模收益递减。


<details>
  <summary>Details</summary>
Motivation: 跟踪过去40年学术知识生产方式的转变，研究团队规模、引文广度和引用影响力这三个核心特征的共同演化，揭示不同学科间的差异模式。

Method: 使用覆盖1970-2010年的1500万篇出版物数据集，涵盖六大领域（人文、社会科学、农业科学、医学与健康科学、工程与技术、自然科学），分析团队规模、引文多样性和引用影响力的时间演化关系。

Result: 所有领域中，基于更广泛和多样化知识基础的论文获得更多引用；大型团队平均产生更大影响力工作，但收益随规模增加而递减；人文社科保持小团队传统，自然科学、医学和工程已转向大团队合作模式。

Conclusion: 这些模式揭示了科学发现的生产技术，显示了学科特定的合作和思想整合障碍，为研究资助机构、大学和政策制定者提供了基于证据的指导，以最大化突破潜力组织科研工作。

Abstract: Over the last four decades, the way knowledge is created in academia has transformed dramatically: research teams have grown larger, scholars draw from ever-wider pools of prior work, and the most influential discoveries increasingly emerge from complex collaborative efforts. Using a massive dataset of over 15 million publications spanning 1970-2010 and covering six major domains (Humanities, Social Sciences, Agricultural Sciences, Medical and Health Sciences, Engineering and Technology, and Natural Sciences), this study tracks how three core features of scientific papers - authorship team size, the breadth and variety of cited sources, and eventual citation impact - have co-evolved over time. We uncover striking differences across disciplines. In every field, papers that build on a broader and more diverse knowledge base consistently attract more citations later on, lending large-scale empirical support to theories that view scientific breakthroughs as outcomes of novel recombination across distant ideas. Bigger teams, on average, generate work with greater ultimate influence, but the gains taper off after a certain scale; very large consortia seldom produce the absolute highest-impact papers. While the Humanities and Social Sciences remain anchored in solo or small-group authorship traditions, the Natural Sciences, Medicine, and Engineering have moved decisively toward big-team mega-science. These patterns illuminate the underlying production technology of discovery, reveal discipline-specific barriers to collaboration and idea integration, and offer evidence-based guidance for research funding agencies, universities, and policymakers seeking to organize scientific work for maximum breakthrough potential.

</details>


<div id='nucl-ex'></div>

# nucl-ex [[Back]](#toc)

### [4] [First measurement of the energy and Mandelstam-$t$ dependence of both coherent and incoherent $J/ψ$ photonuclear production](https://arxiv.org/abs/2511.21239)
*Vendulka Humlova*

Main category: nucl-ex

TL;DR: ALICE实验通过测量铅-铅碰撞中J/ψ介子的衍射光产生，研究量子色动力学中的胶子饱和现象，提供了对核胶子结构的突破性约束。


<details>
  <summary>Details</summary>
Motivation: 研究量子色动力学在高能极限下的胶子饱和现象，铅核碰撞为探测饱和起始提供了理想环境。

Method: 利用ALICE探测器测量铅-铅碰撞中相干和非相干J/ψ光产生，覆盖20-800 GeV的光子-核子质心能量范围，对应Bjorken-x从10^{-2}到10^{-5}。

Result: 获得了相干J/ψ产生能量依赖性的最新结果（对平均胶子密度敏感），以及非相干产生能量和Mandelstam-t依赖性（探测不同空间尺度的胶子场涨落）。

Conclusion: 这些测量为高能极限下的QCD模型提供了前所未有的约束，标志着核胶子结构研究的里程碑。

Abstract: A new phenomenon, gluon saturation, is expected to emerge in quantum chromodynamics (QCD) at high energies, when gluon splitting and recombination processes reach a dynamic equilibrium. In heavy nuclei, this balance is expected to be achieved at lower energies than in protons, making lead-lead collisions at the LHC an ideal environment to probe the onset of saturation. The diffractive photoproduction of the $J/ψ$ vector meson provides an excellent tool to study this regime since it directly probes the gluon distribution in the target. ALICE offers unique kinematic coverage of the photon-nucleon centre-of-mass energy, spanning from 20 to 800 GeV, corresponding to three orders of magnitude in Bjorken-$x$ from about $10^{-2}$ down to $10^{-5}$. This contribution presents the latest ALICE results on the energy dependence of coherent $J/ψ$ production, which is sensitive to the average gluon density, and on the energy and Mandelstam-$t$ dependence of incoherent production, which probes fluctuations of the gluon field at different spatial scales. These measurements provide unprecedented constraints on models of QCD in the high-energy limit and mark a milestone in studying the gluonic structure of nuclei.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [5] [Local Dissipativity Analysis of Nonlinear Systems](https://arxiv.org/abs/2511.20838)
*Amy K. Strong,Leila Bridgeman*

Main category: eess.SY

TL;DR: 本文提出了一种确定非线性控制系统局部耗散性的通用方法，通过凸优化同时寻找系统的最优输入输出特性并合成连续分段仿射存储函数。


<details>
  <summary>Details</summary>
Motivation: 耗散性是非线性系统的重要输入输出特性，可用于组合鲁棒控制，但确定系统的耗散性通常是一个复杂且模型特定的过程。

Method: 将Hamilton-Jacobi不等式与耗散不等式的关系重新表述为线性矩阵不等式，开发了三角剖分的新LMI边界，并提出了合成组合二次和CPA存储函数的方法。

Result: 该方法能够始终找到可行的输入输出特性以及CPA或二次存储函数，前提是系统是严格局部耗散的。

Conclusion: 所提出的方法为非线性系统的局部耗散性分析提供了一种通用且可靠的解决方案。

Abstract: Dissipativity is an input-output (IO) characterization of nonlinear systems that enables compositional robust control through Vidyasagar's Network Dissipativity Theorem. However, determining the dissipativity of a system is an involved and, often, model-specific process. We present a general method to determine the local dissipativity properties of nonlinear, control affine systems. We simultaneously search for the optimal IO characterization of a system and synthesize a continuous piecewise affine (CPA) storage function via a convex optimization problem. To do so, we reformulate the relationship between the Hamilton-Jacobi inequality and the dissipation inequality as an linear matrix inequality (LMI) and develop novel LMI bounds for a triangulation. Further, we develop a method to synthesize a combined quadratic and CPA storage function to expand the systems the optimization problem is applicable to. Finally, we demonstrate that our method will always find a feasible IO characterization and a CPA or quadratic storage function given that the system is strictly locally dissipative.

</details>


### [6] [Dynamic Modeling of Load Demand in Electrified Highways Based on the EV Composition](https://arxiv.org/abs/2511.20874)
*Ashutossh Gupta,Vassilis Kekatos,Dionysios Aliprantis,Steve Pekarek*

Main category: eess.SY

TL;DR: 本文研究了电动道路（ER）上动态无线电力传输（DWPT）系统的负载特性，分析了单个电动汽车负载的时域和频域模型，以及多个电动汽车组成的总体负载的随机模型，重点关注谐波特性及其对电网的影响。


<details>
  <summary>Details</summary>
Motivation: 由于电动道路中发射线圈的空间布置，电动汽车接收线圈获取的功率具有振荡特性，理解DWPT负载的动态行为对于电力系统动态研究非常重要。

Method: 建立了恒定速度下单个电动汽车负载的时域和频域模型，比较了非线性控制方案与线性方案的谐波特性，提出了ER路段总DWPT负载的随机模型。

Result: 发现现有DWPT电动汽车中实施的非线性控制方案比线性方案产生更温和的频率谐波；电动汽车负载的谐波幅度随接收线圈长度减小；但服务更多配备较长接收线圈的电动汽车（如卡车）并不一定意味着更温和的谐波。

Conclusion: 研究结果为电网运营商和电动道路设计者提供了有价值的见解，有助于理解电动汽车组成对电动道路频率谱的影响。

Abstract: Electrified roadways (ERs) equipped with the dynamic wireless power transfer (DWPT) technology can achieve longer driving range and reduce on-board battery requirements for electric vehicles (EVs). Due to the spatial arrangement of transmitter (Tx) coils embedded into the ER pavement, the power drawn by the EV's receiver (Rx) coil is oscillatory in nature. Therefore, understanding the dynamic behavior of the total DWPT load is important for power system dynamic studies. To this end, we model the load of individual EVs in the time and frequency domains for constant EV speed. We establish that a nonlinear control scheme implemented in existing DWPT-enabled EVs exhibits milder frequency harmonics compared to its linear alternative. According to this model, the harmonics of an EV load decrease in amplitude with the Rx coil length. We further propose and analyze stochastic models for the total DWPT load served by an ER segment. Our models explain how the EV composition on the ER affects its frequency spectrum. Interestingly, we show that serving more EVs with longer Rx coils (trucks) does not necessarily entail milder harmonics. Our analytical findings are corroborated using realistic flows from a traffic simulator and offer valuable insights to grid operators and ER designers.

</details>


### [7] [Adaptive Gradient Descent MPPT Algorithm With Complexity-Aware Benchmarking for Low-Power PV Systems](https://arxiv.org/abs/2511.20895)
*Kimia Ahmadi,Wouter A. Serdijn*

Main category: eess.SY

TL;DR: 提出一种计算高效、实时的最大功率点跟踪算法，适用于快速变化辐照度和部分遮挡条件下的低功率光伏系统。该算法通过自适应梯度下降机制增强经典P&O算法，动态调整扰动步长，最小化跟踪时间和稳态振荡。


<details>
  <summary>Details</summary>
Motivation: 针对低功率光伏系统在快速变化辐照度和部分遮挡条件下的MPPT需求，传统P&O算法存在跟踪速度慢和稳态振荡问题，需要更高效、适应性强的解决方案。

Method: 在经典P&O算法基础上引入自适应梯度下降机制，根据瞬时功率-电压斜率动态缩放扰动步长；可选初始化程序增强部分遮挡条件下的全局MPP跟踪能力。

Result: 在标准测试条件下达到99.94%的MPPT效率，实验数据应用达到99.21%，温度测试超过99.6%；部分遮挡条件下初始化程序将跟踪效率提升高达7.8%；在效率、跟踪时间和计算成本综合评估中优于35种先进P&O基MPPT算法。

Conclusion: 该算法在动态和资源受限条件下表现出色，适合集成到低功率电源管理集成电路中，具有拓扑无关的鲁棒性能。

Abstract: This paper proposes a computationally efficient, real-time maximum power point tracking (MPPT) algorithm tailored for low-power photovoltaic (PV) systems operating under fast-changing irradiance and partial shading conditions (PSC). The proposed method augments the classical perturb and observe (P&O) algorithm with an adaptive gradient descent mechanism that dynamically scales the perturbation step size based on the instantaneous power-voltage slope, thereby minimizing tracking time and steady-state oscillations. An optional initialization routine enhances global MPP (GMPP) tracking under PSC. Extensive simulations, including irradiance recordings from freely moving rodent subjects relevant to the targeted application, and tests across varying converter topologies and temperatures, demonstrate its robust, topology-independent performance. The proposed algorithm achieves 99.94 percent MPPT efficiency under standard test conditions (STC), 99.21 percent when applied to experimental data, and more than 99.6 percent for the tested temperature profiles. Under PSC, the initialization routine improves tracking efficiency by up to 7.8 percent. A normalized gate-level complexity analysis and a unified figure-of-merit (FoM) incorporating efficiency, tracking time, and computational cost demonstrate that the proposed algorithm outperforms 35 state-of-the-art P&O-based MPPT algorithms. These results underscore its suitability for integration in low-power power management integrated circuits (PMICs) operating under dynamic and resource-constrained conditions.

</details>


### [8] [Data-Driven Post-Event Analysis with Real-World Oscillation Data from Denmark](https://arxiv.org/abs/2511.20939)
*Youhong Chen,Debraj Bhattacharjee,Balarko Chaudhuri,Mark O Malley,Nan Qin,Adrian Pilkaer Expethit*

Main category: eess.SY

TL;DR: 本文展示了基于Koopman算子理论的扩展动态模态分解(EDMD)方法如何有效识别电力系统中振荡的主要贡献者。使用丹麦实际0.15Hz振荡事件的PMU数据进行后事件分析，仅处理19个PMU的电压和电流相量数据，在无额外系统信息的盲测条件下，EDMD准确识别了0.2Hz振荡的主要贡献源位置。


<details>
  <summary>Details</summary>
Motivation: 传统方法如ISO-NE OSL工具中使用的耗散能流(DEF)方法未能清晰识别问题电厂，需要开发更有效的振荡源定位技术。

Method: 采用扩展动态模态分解(EDMD)算法，仅基于PMU记录的电压和电流相量数据，在无辅助系统信息的盲测条件下进行后事件分析。

Result: EDMD准确识别了0.2Hz振荡的主要贡献源位置，与Energinet后来确认的问题IBR电厂位置一致，该问题的根本原因是控制系统问题。

Conclusion: 与Energinet的联合验证强化了EDMD在识别主要振荡贡献者和实现针对性次同步振荡缓解方面的潜力。

Abstract: This paper demonstrates how Extended Dynamic Mode Decomposition (EDMD), grounded in Koopman operator theory, can effectively identify the main contributor(s) to oscillations in power grids. We use PMU data recorded from a real 0.15 Hz oscillation event in Denmark for post-event analysis. To this end, the EDMD algorithm processed only voltage and current phasors from nineteen PMUs at different voltage levels across the Danish grid. In such a blind-test setting with no supplementary system information, EDMD accurately pinpointed the location of the main contributor to the 0.2 Hz oscillation, consistent with the location of the problematic IBR plant later confirmed by Energinet, where the underlying cause was a control system issue. Conventional approaches, such as the dissipating energy flow (DEF) method used in the ISO-NE OSL tool did not clearly identify this plant. This joint validation with Energinet, reinforcing earlier studies using simulated IBR-dominated systems and real PMU data from ISO-NE, highlights the potential of EDMD-based post-event analysis for identifying major oscillation contributors and enabling targeted SSO mitigation.

</details>


### [9] [Independent policy gradient-based reinforcement learning for economic and reliable energy management of multi-microgrid systems](https://arxiv.org/abs/2511.20977)
*Junkai Hu,Li Xia*

Main category: eess.SY

TL;DR: 本文研究了多微电网系统中的经济可靠能源管理问题，提出了一种基于均值-方差团队随机博弈的分布式方法，包括参数已知时的分布式独立策略梯度算法和参数未知时的深度强化学习算法。


<details>
  <summary>Details</summary>
Motivation: 多微电网系统中效率和可靠性对能源管理至关重要，特别是在集成间歇性分布式可再生能源的情况下。需要解决传统基于期望累积奖励最大化方法不适用于方差指标的问题。

Method: 将能源管理问题建模为均值-方差团队随机博弈，提出两种算法：参数已知时的分布式独立策略梯度算法，以及大规模未知参数场景下的基于独立策略梯度的深度强化学习算法。

Result: 在两种场景下的数值实验验证了所提方法的有效性，能够充分利用多微电网的分布式计算能力。

Conclusion: 所提出的方法实现了经济性能和运行可靠性之间的良好平衡权衡。

Abstract: Efficiency and reliability are both crucial for energy management, especially in multi-microgrid systems (MMSs) integrating intermittent and distributed renewable energy sources. This study investigates an economic and reliable energy management problem in MMSs under a distributed scheme, where each microgrid independently updates its energy management policy in a decentralized manner to optimize the long-term system performance collaboratively. We introduce the mean and variance of the exchange power between the MMS and the main grid as indicators for the economic performance and reliability of the system. Accordingly, we formulate the energy management problem as a mean-variance team stochastic game (MV-TSG), where conventional methods based on the maximization of expected cumulative rewards are unsuitable for variance metrics. To solve MV-TSGs, we propose a fully distributed independent policy gradient algorithm, with rigorous convergence analysis, for scenarios with known model parameters. For large-scale scenarios with unknown model parameters, we further develop a deep reinforcement learning algorithm based on independent policy gradients, enabling data-driven policy optimization. Numerical experiments in two scenarios validate the effectiveness of the proposed methods. Our approaches fully leverage the distributed computational capabilities of MMSs and achieve a well-balanced trade-off between economic performance and operational reliability.

</details>


### [10] [An Exact, Finite Dimensional Representation for Full-Block, Circle Criterion Multipliers](https://arxiv.org/abs/2511.20995)
*Felix Biertümpfel,Bin Hu,Geir Dullerud,Peter Seiler*

Main category: eess.SY

TL;DR: 本文首次提供了完整块圆判据乘子的有限维特征化，针对离散时间线性时不变系统与扇区有界非线性反馈互联的情况，提出了计算可行的有限约束描述方法。


<details>
  <summary>Details</summary>
Motivation: 完整块圆判据乘子定义了非重复扇区有界非线性的所有可能二次约束，能提供最不保守的稳定性条件，但原始形式包含不可数无限约束，计算不可行。

Method: 关键理论洞察：非重复扇区有界非线性的所有输入输出对集合等于适当构造的分段线性函数的增量对集合，新描述仅需有限个矩阵共正性约束。

Result: 新特征化方法在非线性输入输出维度较小（≤4）时具有精确且计算可行的实现，通过简单示例验证了有效性。

Conclusion: 本文提出的有限维特征化方法解决了完整块圆判据乘子的计算可行性问题，为非线性系统分析提供了更实用的工具。

Abstract: This paper provides the first finite-dimensional characterization for the complete set of full-block, circle criterion multipliers. We consider the interconnection of a discrete-time, linear time-invariant system in feedback with a non-repeated, sector-bounded nonlinearity. Sufficient conditions for stability and performance can be derived using: (i) dissipation inequalities, and (ii) Quadratic Constraints (QCs) that bound the input/output pairs of the nonlinearity. Larger classes of QCs (or multipliers) reduce the conservatism of the conditions. Full-block, circle criterion multipliers define the complete set of all possible QCs for non-repeated, sector-bounded nonlinearities. These provide the least conservative conditions. However, full-block multipliers are defined by an uncountably infinite number of constraints and hence do not lead to computationally tractable solutions if left in this raw form. This paper provides a new finite-dimensional characterization for the set of full-block, circle criterion multipliers. The key theoretical insight is: the set of all input/output pairs of non-repeated sector-bounded nonlinearities is equal to the set of all incremental pairs for an appropriately constructed piecewise linear function. Our new description for the complete set of multipliers only requires a finite number of matrix copositivity constraints. These conditions have an exact, computationally tractable implementation for problems where the nonlinearity has small input/output dimensions $(\le 4)$. We illustrate the use of our new characterization via a simple example.

</details>


### [11] [Design and Measurements of mmWave FMCW Radar Based Non-Contact Multi-Patient Heart Rate and Breath Rate Monitoring System](https://arxiv.org/abs/2511.21255)
*Jewel Benny,Pranjal Mahajan,Srayan Sankar Chatterjee,Mohd Wajid,Abhishek Srivastava*

Main category: eess.SY

TL;DR: 本文提出了一种基于FMCW毫米波雷达的非接触式多患者心率和呼吸率监测系统，通过结合多种处理方法和最小二乘解来提高测量精度和泛化能力，实验结果显示呼吸率和心率测量准确率分别超过97%和93%。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达技术的发展使得真正非接触式心率和呼吸率测量成为可能，为患者监测提供了极大便利。同时，这些技术也为同时监测多名患者的心率和呼吸率提供了机会，这在高效群体监测场景中变得越来越重要。

Method: 使用频率调制连续波毫米波雷达开发非接触式多患者心率和呼吸率监测系统，提出了一种结合多种处理方法并使用最小二乘解的新方法，以提高测量精度、泛化能力并处理测量误差。

Result: 使用德州仪器的FMCW雷达开发了该系统，多受试者实验结果显示，测量的呼吸率和心率准确率分别超过97%和93%。

Conclusion: 提出的系统能够有效实现非接触式多患者心率和呼吸率监测，具有高准确率和良好的实用性。

Abstract: Recent developments in mmWave radar technologies have enabled the truly non-contact heart-rate (HR) and breath-rate (BR) measurement approaches, which provides a great ease in patient monitoring. Additionally, these technologies also provide opportunities to simultaneously detect HR and BR of multiple patients, which has become increasingly important for efficient mass monitoring scenarios. In this work, a frequency modulated continuous wave (FMCW) mmWave radar based truly non-contact multiple patient HR and BR monitoring system has been presented. Furthermore, a novel approach is also proposed, which combines multiple processing methods using a least squares solution to improve measurement accuracy, generalization, and handle measurement error. The proposed system has been developed using Texas Instruments' FMCW radar and experimental results with multiple subjects are also presented, which show >97% and >93% accuracy in the measured BR and HR values, respectively.

</details>


### [12] [Response-Based Frequency Stability Assessment under Multi-Scale Disturbances in High-Renewable Power Systems](https://arxiv.org/abs/2511.21269)
*Jinhui Chen,Huadong Sun,Ping Wu,Baocai Wang,Bing Zhao*

Main category: eess.SY

TL;DR: 提出了一种基于响应的频率稳定性评估方法，通过发电机电气响应推断扰动功率，统一处理多时间尺度扰动，并在高可再生能源电力系统中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 高可再生能源电力系统中，有功功率扰动变得更大且时间尺度更加多样化，这使未预期事件下的频率稳定性评估变得复杂。

Method: 基于发电机组的实测功率响应构建统一扰动功率模型，在线识别扰动类型并量化扰动强度；为每类扰动推导解析频率响应模型，对阶跃扰动获得最大可容忍扰动功率，对斜坡型扰动使用改进系统频率响应模型计算频率偏差超限时间。

Result: 在CSEE-FS频率稳定性基准系统上验证了所提方法的有效性和准确性，能够对高可再生能源电力系统进行定量频率稳定性评估。

Conclusion: 所提出的基于响应的评估方法能够有效处理多尺度扰动，为高可再生能源电力系统提供准确的频率稳定性定量评估。

Abstract: In high-renewable power systems, active-power disturbances are becoming larger and exhibit increasingly diverse time scales, which complicates frequency stability assessment under unanticipated events. This paper presents a response-based frequency stability assessment method that uses disturbance power, inferred from generator electrical responses, to provide a unified treatment of multi-scale disturbances. Unanticipated disturbances are first classified into short-term and permanent events; permanent disturbances are further divided into step, second-level slope and minute-level slope disturbances. Based on the measured power responses of generator groups, a unified disturbance-power model is constructed to identify the disturbance type online and to quantify disturbance intensity through the disturbance power and its rate of change. Analytical frequency-response models are then derived for each disturbance class. For step disturbances, the maximum tolerable disturbance power is obtained under steady-state and transient frequency deviation constraints, and a safety-margin index is defined. For slope-type disturbances, an improved system frequency response (SFR) model and the rotor motion equation after exhaustion of primary frequency regulation are used to compute the over-limit time of frequency deviation. The proposed response-based assessment method is validated on the CSEE-FS frequency-stability benchmark system, demonstrating its effectiveness and accuracy for quantitative frequency stability assessment in high-renewable power systems.

</details>


### [13] [Adaptive Lighting Control in Visible Light Systems: An Integrated Sensing, Communication, and Illumination Framework](https://arxiv.org/abs/2511.21271)
*Xinyan Xie,Xuesong Wang,Xin Lai,Yongheng Wen,Fengrui Yang,Haoyang He,Lai Zhang,Dong Zhao*

Main category: eess.SY

TL;DR: 提出自适应集成感知、通信和照明框架，通过几何分区和NLOS定位实现能耗优化，相比非自适应系统节能53.59%，SNR均匀性提升57.79%。


<details>
  <summary>Details</summary>
Motivation: 解决室内可见光通信中高数据率、高感知精度与高能耗、用户视觉舒适度之间的冲突，将节能作为主要目标。

Method: 使用几何方法划分接收平面为活动区和非活动区，基于NLOS定位动态切换优化目标：活动区最小化总发射功率，非活动区最大化SNR均匀性。

Result: 实现53.59%的节能效果，SNR均匀性提升57.79%，满足所有照明约束，平均定位误差为0.071米。

Conclusion: 自适应ISCI框架成功平衡了性能、能耗和用户舒适度，为6G可见光通信提供了有效解决方案。

Abstract: Indoor visible light communication (VLC) is a promising sixth-generation (6G) technology, as its directional and sensitive optical signals are naturally suited for integrated sensing and communication (ISAC). However, current research mainly focuses on maximizing data rates and sensing accuracy, creating a conflict between high performance, high energy consumption, and user visual comfort. This paper proposes an adaptive integrated sensing, communication, and illumination (ISCI) framework that resolves this conflict by treating energy savings as a primary objective. The framework's mechanism first partitions the receiving plane using a geometric methodology, defining an activity area and a surrounding non-activity area to match distinct user requirements. User location, determined using non-line-of-sight (NLOS) sensing, then acts as a dynamic switch for the system's optimization objective. The system adaptively shifts between minimizing total transmit power while guaranteeing communication and illumination performance in the activity area and maximizing signal-to-noise ratio (SNR) uniformity in the non-activity area. Numerical results confirm that this adaptive ISCI approach achieves 53.59% energy savings over a non-adaptive system and improves SNR uniformity by 57.79%, while satisfying all illumination constraints and maintaining a mean localization error of 0.071 m.

</details>


### [14] [Respiratory Motion Compensation and Haptic Feedback for X-ray-Guided Teleoperated Robotic Needle Insertion](https://arxiv.org/abs/2511.21273)
*Ana Cordon-Avila,Mostafa Selim,Momen Abayazid*

Main category: eess.SY

TL;DR: 该论文提出了一种机器人补偿呼吸运动的方法，通过运动估计模型和基于接近度的触觉反馈进行远程操作，在肝脏模型上验证了3mm以下的运动估计误差和2.60-7.75mm的插入误差。


<details>
  <summary>Details</summary>
Motivation: 呼吸运动限制了腹部经皮手术的准确性和精度，需要开发方法来补偿这种运动并减少辐射暴露。

Method: 使用机器人运动估计模型补偿呼吸运动，并采用基于接近度的触觉反馈进行远程操作插入。

Result: 在机器人肝脏模型上进行了5次插入测试，运动估计误差在所有运动方向均低于3mm，3D插入误差分别为：上下方向2.60mm、横向7.75mm、前后方向2.86mm。

Conclusion: 该方法有望最大限度地减少因呼吸运动导致的治疗或诊断不准确，并减少辐射暴露。

Abstract: Respiratory motion limits the accuracy and precision of abdominal percutaneous procedures. In this paper, respiratory motion is compensated robotically using motion estimation models. Additionally, a teleoperated insertion is performed using proximity-based haptic feedback to guide physicians during insertion, enabling a radiation-free remote insertion for the end-user. The study has been validated using a robotic liver phantom, and five insertions were performed. The resulting motion estimation errors were below 3 mm for all directions of motion, and the overall resulting 3D insertion errors were 2.60, 7.75, and 2.86 mm for the superior-inferior, lateral, and anterior-posterior directions of motion, respectively. The proposed approach is expected to minimize the chances of inaccurate treatment or diagnosis due to respiratory-induced motion and reduce radiation exposure.

</details>


### [15] [Sparse shepherding control of large-scale multi-agent systems via Reinforcement Learning](https://arxiv.org/abs/2511.21304)
*Luigi Catello,Italo Napolitano,Davide Salzano,Mario di Bernardo*

Main category: eess.SY

TL;DR: 提出一个强化学习框架，用于大规模多智能体系统的稀疏间接控制，通过少数受控智能体影响大量未受控智能体的集体行为。


<details>
  <summary>Details</summary>
Motivation: 解决大规模多智能体系统中稀疏控制的多尺度挑战，即如何通过少数受控智能体实现对大量未受控智能体集体行为的有效控制。

Method: 结合常微分方程（建模受控智能体）和偏微分方程（描述未受控群体密度），将模型无关强化学习与自适应交互强度补偿相结合，克服稀疏驱动限制。

Result: 数值验证显示该方法能有效实现密度控制，系统达到目标分布，同时对干扰和测量噪声保持鲁棒性。

Conclusion: 基于学习的稀疏控制可以替代计算昂贵的在线优化方法。

Abstract: We propose a reinforcement learning framework for sparse indirect control of large-scale multi-agent systems, where few controlled agents shape the collective behavior of many uncontrolled agents. The approach addresses this multi-scale challenge by coupling ODEs (modeling controlled agents) with a PDE (describing the uncontrolled population density), capturing how microscopic control achieves macroscopic objectives. Our method combines model-free reinforcement learning with adaptive interaction strength compensation to overcome sparse actuation limitations. Numerical validation demonstrates effective density control, with the system achieving target distributions while maintaining robustness to disturbances and measurement noise, confirming that learning-based sparse control can replace computationally expensive online optimization.

</details>


### [16] [Scalable Multisubject Vital Sign Monitoring With mmWave FMCW Radar and FPGA Prototyping](https://arxiv.org/abs/2511.21314)
*Jewel Benny,Narahari N. Moudhgalya,Mujeev Khan,Hemant Kumar Meena,Mohd Wajid,Abhishek Srivastava*

Main category: eess.SY

TL;DR: 本文提出了一种使用FMCW雷达系统非接触式同时监测多人生理体征的创新方法，解决了传统接触式监测设备的局限性，并通过FPGA实现提供了硬件加速方案。


<details>
  <summary>Details</summary>
Motivation: 传统生理体征监测方法存在显著局限性，包括穿戴设备带来的不适、校准困难以及接触式测量设备的感染传播风险。本研究旨在开发适用于各种关键场景的多功能非接触式生理监测解决方案。

Method: 采用频率调制连续波(FMCW)雷达系统进行非接触式监测，探索扩展到任意数量受试者的挑战，包括硬件和理论限制，并提出了基于FPGA的硬件实现方案。

Result: 实验结果表明，该系统具有重新定义生理体征监测的潜力。FPGA实现相比先前工作执行速度快2.7倍，查找表(LUT)利用率降低18.4%，相比软件实现提供超过7400倍的加速。

Conclusion: 该研究成功开发了一种高效的非接触式多人生理体征监测系统，通过FPGA硬件加速实现了显著的性能提升，为未来医疗监测应用提供了有前景的解决方案。

Abstract: In this work, we introduce an innovative approach to estimate the vital signs of multiple human subjects simultaneously in a non-contact way using a Frequency Modulated Continuous Wave (FMCW) radar-based system. Traditional vital sign monitoring methods often face significant limitations, including subject discomfort with wearable devices, challenges in calibration, and the risk of infection transmission through contact measurement devices. To address these issues, this research is motivated by the need for versatile, non-contact vital monitoring solutions applicable in various critical scenarios. This work also explores the challenges of extending this capability to an arbitrary number of subjects, including hardware and theoretical limitations. Supported by rigorous experimental results and discussions, the paper illustrates the system's potential to redefine vital sign monitoring. An FPGA-based implementation is also presented as proof of concept for a hardware-based and portable solution, improving upon previous works by offering 2.7x faster execution and 18.4% less Look-Up Table (LUT) utilization, as well as providing over 7400x acceleration compared to its software counterpart.

</details>


### [17] [Model Predictive Control and Moving Horizon Estimation using Statistically Weighted Data-Based Ensemble Models](https://arxiv.org/abs/2511.21343)
*Laura Boca de Giuli,Samuel Mallick,Alessio La Bella,Azita Dabiri,Bart De Schutter,Riccardo Scattolini*

Main category: eess.SY

TL;DR: 提出了一种基于数据驱动模型集合的模型预测控制框架，通过马氏距离的组合规则动态调整预测窗口内的模型权重，并开发了移动水平估计的状态观测器，在多种工况下的能源系统上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 复杂系统在多种工况下的最优控制需要能够适应不同运行条件的灵活模型，传统单一模型难以有效处理多工况场景。

Method: 使用数据驱动模型集合，基于马氏距离提出新颖的组合规则使模型权重随系统输入动态变化，并开发了移动水平估计的状态观测器。

Result: 在基准能源系统上的实验表明，所提方法能够有效处理多种运行工况，实现系统的最优控制。

Conclusion: 基于模型集合的MPC框架结合马氏距离组合规则和MHE状态观测器，为多工况复杂系统的控制提供了有效的解决方案。

Abstract: This paper presents a model predictive control (MPC) framework leveraging an ensemble of data-based models to optimally control complex systems under multiple operating conditions. A novel combination rule for ensemble models is proposed, based on the statistical Mahalanobis distance, enabling the ensemble weights to suitably vary across the prediction window based on the system input. In addition, a novel state observer for ensemble models is developed using moving horizon estimation (MHE). The effectiveness of the proposed methodology is demonstrated on a benchmark energy system operating under multiple conditions.

</details>


### [18] [Influence of converter current limiting and prioritization on protection of highly IBR-penetrated networks](https://arxiv.org/abs/2511.21385)
*Andrés E. Quintero,Vinícius A. Lacerda,Oriol Gomis-Bellmunt,Moisés J. B. B. Davi,Mario Oleskovicz*

Main category: eess.SY

TL;DR: 该论文研究了电网形成(GFM)和电网跟随(GFL)控制策略对基于逆变器的资源(IBRs)在线路距离保护和差动保护中的影响。研究发现，现代变流器控制与电流限制和序电流优先级设置会损害传统保护方案的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 随着基于逆变器的资源在电力系统中日益普及，需要了解GFM和GFL控制策略如何影响传统保护系统的性能，特别是在变流器主导的输电系统中。

Method: 使用改进的IEEE 39总线系统进行评估，配备具有低压穿越逻辑、电流限制和正序或负序优先级设置的GFM和GFL单元。距离保护采用mho特性实现，线路差动保护采用alpha-plane方法。

Result: 距离保护中的相地回路会显著高估Zone-1范围内的故障位置。对于线路差动保护，外部故障可能导致操作点短暂进入alpha-plane的跳闸区域，即使在GFL控制下的ABG故障健康相和故障初始时刻也是如此。

Conclusion: 现代变流器控制结合电流限制和序电流优先级设置会损害传统保护方案的可靠性和安全性，需要采取强有力的外部安全措施。

Abstract: This paper investigates how grid-forming (GFM) and grid-following (GFL) control strategies in inverter-based resources (IBRs) influence line distance and differential protection in converter-dominated transmission systems. A modified IEEE 39-bus system is evaluated with GFM and GFL units equipped with low-voltage ride-through logic, current limiting, and positive- or negative-sequence prioritization. Distance protection is implemented with a mho characteristic, while line differential protection uses an alpha-plane approach. Results show that phase-to-ground loops in distance protection can substantially overestimate the fault location near the Zone-1 reach. For line differential protection, external faults may cause the operating point to briefly enter the trip region of the alpha-plane, even for the healthy-phase in ABG faults under GFL control and during the initial moments of the fault, demanding strong external security measures. These findings highlight that modern converter controls, together with current limitation and sequence-current prioritization, can compromise the reliability and security of traditional protection schemes.

</details>


### [19] [Decentralized Shepherding of Non-Cohesive Swarms Through Cluttered Environments via Deep Reinforcement Learning](https://arxiv.org/abs/2511.21405)
*Cristiana Punzo,Italo Napolitano,Cinzia Tomaselli,Mario di Bernardo*

Main category: eess.SY

TL;DR: 本文研究了在复杂环境中使用有限数量牧羊人引导大量非凝聚性、扩散性目标群体到达目标区域的去中心化牧羊控制方法，提出了一种分层控制架构，结合目标分配规则和基于学习的驱动模块。


<details>
  <summary>Details</summary>
Motivation: 解决在存在静态障碍物的复杂环境中，使用少量牧羊人有效引导大量非合作目标群体的挑战，实现可扩展的、无需环境模型的控制方法。

Method: 提出分层控制架构：高层目标分配规则将牧羊人与选定目标配对，低层使用基于强化学习的驱动模块（PPO算法训练），在单牧羊人单目标场景训练后直接扩展到多智能体多障碍物环境。

Result: 数值模拟显示该方法能够产生平滑、无碰撞的轨迹，并持续收敛到目标区域，验证了强化学习在复杂环境中实现可扩展、无模型牧羊控制的潜力。

Conclusion: 基于强化学习的去中心化牧羊控制方法在复杂环境中表现出良好的性能，无需重新训练即可扩展到多智能体多障碍物场景，为复杂环境中的群体控制提供了有效解决方案。

Abstract: This paper investigates decentralized shepherding in cluttered environments, where a limited number of herders must guide a larger group of non-cohesive, diffusive targets toward a goal region in the presence of static obstacles. A hierarchical control architecture is proposed, integrating a high-level target assignment rule, where each herder is paired with a selected target, with a learning-based low-level driving module that enables effective steering of the assigned target. The low-level policy is trained in a one-herder-one-target scenario with a rectangular obstacle using Proximal Policy Optimization and then directly extended to multi-agent settings with multiple obstacles without requiring retraining. Numerical simulations demonstrate smooth, collision-free trajectories and consistent convergence to the goal region, highlighting the potential of reinforcement learning for scalable, model-free shepherding in complex environments.

</details>


### [20] [Robust Rule-Based Sizing and Control of Batteries for Peak Shaving Applications](https://arxiv.org/abs/2511.21619)
*Lorenzo Nespoli,Vasco Medici*

Main category: eess.SY

TL;DR: 本文展示了随机调谐的基于规则控制器（RBCs）在电池储能系统中的应用，相比确定性模型预测控制（MPC），能提供更现实的平准化能源成本估算和更好的运行性能。


<details>
  <summary>Details</summary>
Motivation: 随着电池成本降低，需要既快速又能在部署时实现承诺性能的尺寸和控制方法。

Method: 使用随机调谐的基于规则控制器（RBCs），在真实电表数据的年度配置文件上进行峰值削减应用测试。

Result: 随机RBCs相比确定性MPC能提供更现实的平准化能源成本估算和更好的运行性能。

Conclusion: 随机调谐的基于规则控制器是实现快速且高性能电池控制的有效方法。

Abstract: As the cost of batteries lowers, sizing and control methods that are both fast and can achieve their promised performances when deployed are becoming more important. In this paper, we show how stochastically tuned rule based controllers (RBCs) can be effectively used to achieve both these goals, providing more realistic estimates in terms of achievable levelised cost of energy (LCOE), and better performances while in operation when compared to deterministic model predictive control (MPC). We test the proposed methodology on yearly profiles from real meters for peak shaving applications and provide strong evidence about these claims.

</details>


### [21] [Bang-Bang Evasion: Its Stochastic Optimality and a Terminal-Set-Based Implementation](https://arxiv.org/abs/2511.21633)
*Liraz Mudrik,Yaakov Oshman*

Main category: eess.SY

TL;DR: 本文提出了一种在平面终端对抗中的最优规避策略，针对具有有限横向加速度的目标对抗采用线性反馈制导的导弹。在考虑不完全信息和有限控制的随机框架下，证明了最优规避策略的存在性，并提出了基于终端集的闭环规避策略。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么假设完美信息，要么在随机设置中使用启发式机动模型，无法处理现实中的不完全信息和有限控制问题。本文旨在将确定性环境中已知的bang-bang最优规避扩展到现实的随机规避场景。

Method: 在随机框架下，基于广义分离定理，控制律考虑了状态的后验分布。首先证明了最优规避策略的存在性，且最优解集中至少包含一个bang-bang策略，使最优控制问题变为有限维。其次提出了基于终端集的闭环规避策略。

Result: 仿真结果表明，针对比例导航追击者，TSE策略优于基于随机电报、Singer和编织模型的传统随机规避策略。蒙特卡洛模拟验证了该策略的有效性。

Conclusion: 本文成功地将bang-bang最优规避扩展到随机场景，提出的TSE策略在实际对抗中表现优异，为随机规避问题提供了有效的解决方案。

Abstract: We address the problem of optimal evasion in a planar endgame engagement, where a target with bounded lateral acceleration seeks to avoid interception by a missile guided by a linear feedback law. Contrary to existing approaches, that assume perfect information or use heuristic maneuver models in stochastic settings, we formulate the problem in an inherently stochastic framework involving imperfect information and bounded controls. Complying with the generalized separation theorem, the control law factors in the posterior distribution of the state. Extending the well-known optimality of bang-bang evasion maneuvers in deterministic settings to the realm of realistic, stochastic evasion scenarios, we firstly prove that an optimal evasion strategy always exists, and that the set of optimal solutions includes at least one bang-bang policy, rendering the resulting optimal control problem finite-dimensional. Leveraging this structure, we secondly propose the closed-loop terminal-set-based evasion (TSE) strategy, and demonstrate its effectiveness in simulation against a proportional navigation pursuer. Monte Carlo simulations show that the TSE strategy outperforms traditional stochastic evasion strategies based on random telegraph, Singer, and weaving models.

</details>


### [22] [Model-free practical PI-Lead control design by ultimate sensitivity principle](https://arxiv.org/abs/2511.21641)
*Michael Ruderman*

Main category: eess.SY

TL;DR: 本文提出了一种无需建模的鲁棒PI-Lead控制器设计方法，基于终极灵敏度原理和环路整形特性，通过三步实验程序确定控制器参数，保证足够的相位裕度。


<details>
  <summary>Details</summary>
Motivation: 实际控制器设计常常无法获得动态过程的模型，工程师只能基于一些一般假设（如类型一稳定行为）进行设计，特别是在运动控制系统中。

Method: 基于Ziegler-Nichols PID整定的终极灵敏度原理，结合环路整形的一般特性，提出三步实验程序：通过仅观察输出值的实验来确定积分时间常数、控制增益和Lead元件参数。

Result: 该方法在受噪声干扰的机电执行器平移运动系统上进行了实验评估。

Conclusion: 提出的方法提供了一种实用且易于实现的鲁棒PI-Lead控制器设计程序，无需建模过程，仅通过实验观测即可完成参数整定。

Abstract: Practical design and tuning of feedback controllers has to do often without any model of the given dynamic process. Only some general assumptions about the process, in this work type-one stable behavior, can be available for engineers, in particular in motion control systems. This paper proposes a practical and simple in realization procedure for designing a robust PI-Lead control without modeling. The developed method derives from the ultimate sensitivity principles, known in the empirical Ziegler-Nichols tuning of PID control, and makes use of some general characteristics of loop shaping. A three-steps procedure is proposed to determine the integration time constant, control gain, and Lead-element in a way to guarantee a sufficient phase margin, while all steps are served by only experimental observations of the output value. The proposed method is also evaluated with experiments on a noise-perturbed electro-mechanical actuator system with translational motion.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [23] [Train While You Fight -- Technical Requirements for Advanced Distributed Learning Platforms](https://arxiv.org/abs/2511.20813)
*Simon Hacks*

Main category: cs.SE

TL;DR: 本文探讨了支持'边战边训'(TWYF)模式的先进分布式学习平台所需的技术要求，并分析现有软件工程模式如何满足这些要求。


<details>
  <summary>Details</summary>
Motivation: 推动在作战行动期间进行持续学习，而非仅限于战前或战后训练，以提升军事训练效能。

Method: 采用设计科学研究方法，包括：(i)从PfPC/北约文档和最新实践中推导挑战，(ii)定义解决方案目标，(iii)系统性地将挑战映射到已验证的模式。

Result: 识别出七个关键技术挑战：互操作性、弹性、多语言支持、数据安全与隐私、可扩展性、平台独立性和模块化，并通过德国武装部队的国家用例说明这些模式。

Conclusion: 现有的软件工程模式能够有效支持TWYF模式的技术要求，为先进分布式学习平台的开发提供了可行的解决方案框架。

Abstract: "Train While You Fight" (TWYF) advocates for continuous learning that occurs during operations, not just before or after. This paper examines the technical requirements that advanced distributed learning (ADL) platforms must meet to support TWYF, and how existing software engineering patterns can fulfill these requirements. Using a Design Science Research approach, we (i) derive challenges from PfPC/NATO documentation and recent practice, (ii) define solution objectives, and (iii) conduct a systematic mapping from challenges to proven patterns. We identify seven technical challenges: interoperability, resilience, multilingual support, data security and privacy, scalability, platform independence, and modularity. We illustrate the patterns with a national use case from the German armed forces.

</details>


### [24] [Hierarchical Evaluation of Software Design Capabilities of Large Language Models of Code](https://arxiv.org/abs/2511.20933)
*Mootez Saad,Boqi Chen,José Antonio Hernández López,Dániel Varró,Tushar Sharma*

Main category: cs.SE

TL;DR: 该研究系统评估了DeepSeek-R1系列大语言模型对软件设计概念（内聚性和耦合性）的理解能力。在理想条件下模型表现良好，但在实际应用中知识脆弱且不对称：耦合性推理在噪声环境中表现崩溃，而内聚性分析在引导任务中相对稳健。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在软件工程领域的广泛应用，但其对核心软件设计概念的掌握稳健性尚不明确。需要系统评估模型对内聚性和耦合性等基本设计原则的理解能力。

Method: 通过程序化生成设计不良的代码片段，测试DeepSeek-R1模型家族（14B、32B、70B）在不同指导级别（从简单验证到引导和开放式生成）下的表现，并通过注入干扰元素来改变上下文噪声水平。

Result: 模型在理想条件下对两个概念都有良好理解，但实际知识脆弱且不对称：耦合性推理在噪声开放式场景中表现崩溃（F1分数下降超过50%），内聚性分析在引导任务中对内部噪声具有显著稳健性。推理轨迹分析揭示了耦合性推理中的认知捷径与内聚性分析中的详尽但失败的推理模式。

Conclusion: 虽然大语言模型能够为识别设计缺陷提供可靠帮助，但在噪声现实环境中自主推理的能力有限，凸显了开发更具可扩展性和稳健性的程序理解能力的迫切需求。

Abstract: Large language models (LLMs) are being increasingly adopted in the software engineering domain, yet the robustness of their grasp on core software design concepts remains unclear. We conduct an empirical study to systematically evaluate their understanding of cohesion (intra-module) and coupling (inter-module). We programmatically generate poorly designed code fragments and test the DeepSeek-R1 model family ($14$B, $32$B, $70$B) under varying levels of guidance, from simple \textit{Verification} to \textit{Guided} and \textit{Open-ended Generation}, while varying contextual noise by injecting distractor elements. While models exhibit a solid baseline understanding of both concepts in ideal conditions, their practical knowledge is fragile and highly asymmetrical. Reasoning about coupling proves brittle; performance collapses in noisy, open-ended scenarios, with F1 scores dropping by over $50\%$. In contrast, the models' analysis of cohesion is remarkably robust to internal noise in guided tasks, showing little performance degradation. However, this resilience also fails when all guidance is removed. Reasoning-trace analysis confirms these failure modes, revealing \textit{cognitive shortcutting} for coupling versus a more exhaustive (yet still failing) analysis for cohesion. To summarize, while LLMs can provide reliable assistance for recognizing design flaws, their ability to reason autonomously in noisy, realistic contexts is limited, highlighting the critical need for more scalable and robust program understanding capabilities.

</details>


### [25] [SpaceX: Exploring metrics with the SPACE model for developer productivity](https://arxiv.org/abs/2511.20955)
*Sanchit Kaul,Kevin Nhu,Jason Eissayou,Ivan Eser,Victor Borup*

Main category: cs.SE

TL;DR: 本研究通过实证调查揭示了传统单一维度生产力启发式方法的局限性，提出基于SPACE框架的多维度生产力评估方法，发现负面情绪与提交频率呈正相关，并开发了复合生产力评分（CPS）来应对开发者效能异质性。


<details>
  <summary>Details</summary>
Motivation: 传统确定性、单一维度的生产力启发式方法存在局限性，无法全面评估开发者的真实生产力，需要更全面、多维度的评估框架。

Method: 通过大规模开源仓库数据挖掘，采用广义线性混合模型（GLMM）和基于RoBERTa的情感分类等统计方法，构建综合多维度生产力指标。

Result: 研究发现负面情感状态与提交频率存在显著正相关，表明存在由挫败感驱动的迭代修复循环；同时分析贡献者交互拓扑比传统基于数量的指标能更准确地映射协作动态。

Conclusion: 研究提出了复合生产力评分（CPS）来解决开发者效能异质性问题，为更准确地评估软件开发生产力提供了新方法。

Abstract: This empirical investigation elucidates the limitations of deterministic, unidimensional productivity heuristics by operationalizing the SPACE framework through extensive repository mining. Utilizing a dataset derived from open-source repositories, the study employs rigorous statistical methodologies including Generalized Linear Mixed Models (GLMM) and RoBERTa-based sentiment classification to synthesize a holistic, multi-faceted productivity metric. Analytical results reveal a statistically significant positive correlation between negative affective states and commit frequency, implying a cycle of iterative remediation driven by frustration. Furthermore, the investigation has demonstrated that analyzing the topology of contributor interactions yields superior fidelity in mapping collaborative dynamics compared to traditional volume-based metrics. Ultimately, this research posits a Composite Productivity Score (CPS) to address the heterogeneity of developer efficacy.

</details>


### [26] [Lightweight Model Editing for LLMs to Correct Deprecated API Recommendations](https://arxiv.org/abs/2511.21022)
*Guancheng Lin,Xiao Yu,Jacky Keung,Xing Hu,Xin Xia,Alex X. Liu*

Main category: cs.SE

TL;DR: 本研究首次系统性地应用10种最先进的模型编辑技术来更新LLMs中的过时API知识，并提出了AdaLoRA-L方法，通过定义"通用API层"和"特定API层"来显著提高编辑特异性。


<details>
  <summary>Details</summary>
Motivation: LLMs在代码补全任务中表现优异，但其嵌入知识受训练数据时效性限制，经常生成已弃用的API。重新训练LLMs成本高昂，而轻量级模型编辑方法能否有效更新过时API知识尚不清楚。

Method: 引入EDAPIBench基准测试，包含8个流行Python库的70多个过时API和3000多个编辑实例。应用10种模型编辑技术，并提出AdaLoRA-L方法，通过区分通用API层和特定API层来限制编辑范围。

Result: 参数高效微调方法AdaLoRA在生成正确、最新的API方面表现最佳，但在特异性方面不足。AdaLoRA-L显著提高了特异性，同时在其他评估指标上保持可比性能。

Conclusion: AdaLoRA-L方法通过分层编辑策略有效解决了模型编辑中的特异性问题，为更新LLMs中的过时API知识提供了高效解决方案。

Abstract: Pre-trained or fine-tuned on large code corpora, Large Language Models (LLMs) have demonstrated strong performance in code completion tasks. However, their embedded knowledge is constrained by the timeliness of training data, which often includes code using deprecated APIs. Consequently, LLMs frequently generate deprecated APIs that will no longer be supported in future versions of third-party libraries. While retraining LLMs on updated codebases could refresh their API knowledge, this approach is computationally expensive. Recently, lightweight model editing methods have emerged to efficiently correct specific knowledge in LLMs. However, it remains unclear whether these methods can effectively update deprecated API knowledge and enable edited models to generate up-to-date APIs. To address this gap, we conduct the first systematic study applying 10 state-of-the-art model editing techniques to update deprecated API knowledge in three LLMs: Qwen2.5-Coder, StarCoder2, and DeepSeek-Coder. We introduce EDAPIBench, a dedicated benchmark featuring over 70 deprecated APIs from 8 popular Python libraries, with more than 3,000 editing instances. Our results show that the parameter-efficient fine-tuning method AdaLoRA achieves the best performance in enabling edited models to generate correct, up-to-date APIs, but falls short in Specificity (i.e., the editing influences untargeted knowledge). To resolve this, we propose AdaLoRA-L, which defines "Common API Layers" (layers within the LLMs with high importance across all APIs, storing general knowledge and excluded from editing) and restricts edits exclusively to "Specific API Layers" (layers with high importance only for the target API, storing the API-specific knowledge). Experimental results demonstrate that AdaLoRA-L significantly improves Specificity while maintaining comparable performance across other evaluation metrics.

</details>


### [27] [Exploring Hidden Geographic Disparities in Android Apps](https://arxiv.org/abs/2511.21151)
*M. Alecci,P. Jiménez,J. Samhi,T. Bissyandé,J. Klein*

Main category: cs.SE

TL;DR: 该论文研究了Android应用的地理差异现象，发现了两种重要但未被充分研究的现象：GeoTwins（功能相似但在不同国家发布的应用变体）和App Bundle生态系统中base.apk文件的区域差异，这些差异对安全性和公平性产生影响。


<details>
  <summary>Details</summary>
Motivation: 移动应用演化已被广泛研究，但应用行为的地理差异仍未被充分探索。该研究旨在揭示地理位置对Android应用行为的影响，特别是那些具有安全和公平性影响的隐藏差异。

Method: 构建了跨多个区域的分布式应用收集管道，分析了数千个应用，并发布了包含81,963个GeoTwins的数据集来支持未来研究。

Result: 发现了GeoTwins现象和App Bundle生态系统中base.apk文件的区域差异，这些差异导致相同应用在不同地区可能被标记为良性或可疑，影响了评估的可重复性并引入了地理偏见。

Conclusion: 研究揭示了移动软件中系统性的区域差异，这对研究人员、开发者、平台架构师和政策制定者具有重要意义，特别是在透明度、同意和公平性方面。

Abstract: While mobile app evolution has been widely studied, geographical variation in app behavior remains largely unexplored. This paper presents a large-scale study of location-based Android app differentiation, uncovering two important and underexamined phenomena with security and fairness implications. First, we introduce GeoTwins: apps that are functionally similar and share branding but are released under different package names across countries. Despite their similarity, GeoTwins often diverge in requested permissions, third-party libraries, and privacy disclosures. Second, we examine the Android App Bundle ecosystem and reveal unexpected regional differences in supposedly consistent base.apk files. Contrary to common assumptions, even base.apk files vary by region, exposing hidden customizations that may affect app behavior or security.
  These discrepancies have concrete consequences. Geographically distinct variants can lead the same app to be labeled benign in one malware study but suspicious in another, depending on the region of download. Such hidden variation undermines reproducibility and introduces geographic bias into assessments of security, privacy, and functionality. It also raises ethical concerns about transparency and consent: visually identical Google Play listings may mask subtle but important differences.
  To study these issues, we built a distributed app collection pipeline spanning multiple regions and analyzed thousands of apps. We also release a dataset of 81,963 GeoTwins to support future work. Our findings reveal systemic regional disparities in mobile software, with implications for researchers, developers, platform architects, and policymakers.

</details>


### [28] [Bug Detective and Quality Coach: Developers' Mental Models of AI-Assisted IDE Tools](https://arxiv.org/abs/2511.21197)
*Paolo Buono,Mary Cerullo,Stefano Cirillo,Giuseppe Desolda,Francesco Greco,Emanuela Guglielmi,Grazia Margarella,Giuseppe Polese,Simone Scalabrino,Cesare Tucci*

Main category: cs.SE

TL;DR: 该研究通过6次共同设计工作坊与58名开发者合作，探索了开发者对AI辅助bug检测和代码可读性评估工具的心理模型。研究发现开发者将bug检测工具视为"bug侦探"，而可读性评估工具则被视为"质量教练"。研究还提炼了一套以人为本的AI设计原则。


<details>
  <summary>Details</summary>
Motivation: 尽管AI辅助工具在技术特性上有所进步，但开发者如何心理建模这些工具以及不匹配如何影响信任、控制和采用仍知之甚少。

Method: 进行了6次共同设计工作坊，涉及58名开发者，以获取他们对AI辅助bug检测和可读性功能的心理模型。

Result: 开发者将bug检测工具构想为仅在关键问题时警告用户的"bug侦探"，保证透明度、可操作的反馈和信心提示；可读性评估工具则被设想为提供情境化、个性化和渐进式指导的"质量教练"。信任取决于解释的清晰度、时机和用户控制。

Conclusion: 提炼了一套用于IDE中以人为本AI的设计原则，旨在平衡中断与支持、简洁与深度、自动化与人类能动性。

Abstract: AI-assisted tools support developers in performing cognitively demanding tasks such as bug detection and code readability assessment. Despite the advancements in the technical characteristics of these tools, little is known about how developers mentally model them and how mismatches affect trust, control, and adoption. We conducted six co-design workshops with 58 developers to elicit their mental models about AI-assisted bug detection and readability features. It emerged that developers conceive bug detection tools as \textit{bug detectives}, which warn users only in case of critical issues, guaranteeing transparency, actionable feedback, and confidence cues. Readability assessment tools, on the other hand, are envisioned as \textit{quality coaches}, which provide contextual, personalized, and progressive guidance. Trust, in both tasks, depends on the clarity of explanations, timing, and user control. A set of design principles for Human-Centered AI in IDEs has been distilled, aiming to balance disruption with support, conciseness with depth, and automation with human agency.

</details>


### [29] [Multi-Agent Systems for Dataset Adaptation in Software Engineering: Capabilities, Limitations, and Future Directions](https://arxiv.org/abs/2511.21380)
*Jingyi Chen,Xiaoyan Guo,Songqiang Chen,Shing-Chi Cheung,Jiasi Shen*

Main category: cs.SE

TL;DR: 本文首次实证研究了最先进的多智能体系统在数据集适应任务中的表现，评估了基于GPT-4.1和Claude Sonnet 4的Copilot系统在软件工程研究工件适应方面的能力。


<details>
  <summary>Details</summary>
Motivation: 自动化软件工程研究工件在数据集间的适应对于可扩展性和可复现性至关重要，但目前仍缺乏系统研究。多智能体系统有望通过协调推理、代码生成和工具交互来自动化复杂开发工作流。

Method: 通过五阶段评估流程（文件理解、代码编辑、命令生成、验证和最终执行）评估Copilot系统，测量成功率、分析失败模式，并评估旨在提升智能体性能的提示干预策略。

Result: 当前系统能够识别关键文件并生成部分适应，但很少产生功能正确的实现。提示级干预（特别是提供执行错误消息和参考代码）显著提高了与真实情况的结构相似性（从7.25%提升到67.14%）。

Conclusion: 研究揭示了当前多智能体LLM系统在数据集适应方面的潜力和局限性，并为未来构建更可靠、自校正的智能体提供了具体方向。

Abstract: Automating the adaptation of software engineering (SE) research artifacts across datasets is essential for scalability and reproducibility, yet it remains largely unstudied. Recent advances in large language model (LLM)-based multi-agent systems, such as GitHub Copilot's agent mode, promise to automate complex development workflows through coordinated reasoning, code generation, and tool interaction. This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks. We evaluate Copilot, backed by GPT-4.1 and Claude Sonnet 4, on adapting SE research artifacts from benchmark repositories including ROCODE and LogHub2.0. Through a five-stage evaluation pipeline (file comprehension, code editing, command generation, validation, and final execution), we measure success rates, analyze failure patterns, and assess prompt-based interventions designed to enhance agent performance. Results show that current systems can identify key files and generate partial adaptations but rarely produce functionally correct implementations. Prompt-level interventions, especially providing execution error messages and reference code, substantially improve structural similarity to ground truth (from 7.25% to 67.14%), highlighting the importance of contextual and feedback-driven guidance. Our findings reveal both the promise and limitations of today's multi-agent LLM systems for dataset adaptation, and suggest concrete directions for building more reliable, self-correcting agents in future SE research.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [30] [Assessing Redundancy Strategies to Improve Availability in Virtualized System Architectures](https://arxiv.org/abs/2511.20780)
*Alison Silva,Gustavo Callou*

Main category: cs.DC

TL;DR: 本文提出了一种基于随机Petri网的方法来分析私有云环境中Nextcloud文件服务器的可用性，评估了四种冗余架构配置，发现主机和虚拟机级别的冗余能显著提高系统可用性。


<details>
  <summary>Details</summary>
Motivation: 随着云存储平台在学术和商业环境中的普及，可靠性成为关键需求，特别是对于寻求替代公共云服务的组织。评估这些系统的可靠性至关重要。

Method: 使用随机Petri网建模方法，通过Apache CloudStack在私有云环境中分析Nextcloud文件服务器的可用性，评估了四种架构配置：基线、主机级冗余、虚拟机冗余以及两者结合。

Result: 结果显示，主机和虚拟机级别的冗余显著提高了可用性并减少了预期停机时间。组合冗余策略效果最佳。

Conclusion: 提出的方法为评估私有云可用性和支持基础设施设计决策提供了一种有效手段。

Abstract: Cloud-based storage platforms are becoming more common in both academic and business settings due to their flexible access to data and support for collaborative functionalities. As reliability becomes a vital requirement, particularly for organizations looking for alternatives to public cloud services, assessing the dependability of these systems is crucial. This paper presents a methodology for analyzing the availability of a file server (Nextcloud) hosted in a private cloud environment using Apache CloudStack. The analysis is based on a modeling approach through Stochastic Petri Nets (SPNs) that allows the evaluation of different redundancy strategies to enhance the availability of such systems. Four architectural configurations were modeled, including the baseline, host-level redundancy, virtual machine (VM) redundancy, and a combination of both. The results show that redundancy at both the host and VM levels significantly improves availability and reduces expected downtime. The proposed approach provides a method to evaluate the availability of a private cloud and support infrastructure design decisions.

</details>


### [31] [Aragog: Just-in-Time Model Routing for Scalable Serving of Agentic Workflows](https://arxiv.org/abs/2511.20975)
*Yinwei Dai,Zhuofu Chen,Anand Iyer,Ravi Netravali*

Main category: cs.DC

TL;DR: Aragog系统通过运行时动态调整工作流配置来解决大规模Agentic工作流服务中的计算成本问题，相比固定配置方法显著提升了吞吐量和降低了延迟。


<details>
  <summary>Details</summary>
Motivation: Agentic工作流虽然能解决复杂多阶段任务，但大规模服务时计算成本高昂，现有固定配置方法无法适应系统负载的快速波动，导致配置很快变得次优。

Method: Aragog将问题分解为两个核心要素：一次性路由步骤识别所有保持精度的配置，以及基于最新系统观测的廉价每阶段调度器，并引入新策略加速每个步骤。

Result: 在多样化工作流和模型家族中，Aragog在峰值请求率下将最大服务吞吐量提高了50.0-217.0%，中位数延迟降低了32.5-78.9%，同时保持与最昂贵配置相当的精度。

Conclusion: Aragog通过运行时渐进式配置适应，有效解决了Agentic工作流服务中的成本效率问题，在保持精度的同时显著提升了系统性能。

Abstract: Agentic workflows have emerged as a powerful paradigm for solving complex, multi-stage tasks, but serving them at scale is computationally expensive given the many LLM inferences that each request must pass through. Configuration selection, or the cost-aware assignment of workflow agents to specific LLMs, can reduce these costs, but existing approaches bind configuration decisions before request execution, making them ill-suited for the heterogeneous and lengthy execution of workflows. Specifically, system loads can fluctuate rapidly and substantially during a request's lifetime, causing fixed configurations to quickly become suboptimal. We present Aragog, a system that progressively adapts a request's configuration throughout its execution to match runtime dynamics. To make this practical despite the massive space of workflow configurations, Aragog decouples the problem into two core elements -- a one-time routing step that identifies all accuracy-preserving configurations, and a cheap per-stage scheduler that selects among them using up-to-date system observations -- and introduces novel strategies to accelerate each. Across diverse workflows and model families, Aragog increases maximum serving throughput by 50.0--217.0\% and reduces median latency by 32.5--78.9\% at peak request rates, while maintaining accuracy comparable to the most expensive configurations.

</details>


### [32] [A Dynamic PD-Disaggregation Architecture for Maximizing Goodput in LLM Inference Serving](https://arxiv.org/abs/2511.20982)
*Junhan Liao,Minxian Xu,Wanyi Zheng,Yan Wang,Kejiang Ye,Rajkumar Buyya,Chengzhong Xu*

Main category: cs.DC

TL;DR: DOPD是一个动态LLM推理系统，通过实时负载监控调整实例分配，实现最优的prefill/decoding比例，解决异构工作负载下的生产者-消费者不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统将prefill和decoding阶段分离到不同GPU上，但异构工作负载导致两个实例类型之间出现生产者-消费者不平衡问题。

Method: 提出DOPD系统，动态调整实例分配实现最优P/D比例，结合适当的请求调度策略，解决高并发下混合长度请求导致的资源分配不匹配问题。

Result: 相比vLLM和DistServe，DOPD将系统吞吐量提升最高1.5倍，P90 TTFT降低67.5%，P90 TPOT降低22.8%。

Conclusion: 动态P/D调整技术基于历史负载进行主动重配置，使用更少的额外资源实现超过99%的SLO达成率。

Abstract: To meet strict Service-Level Objectives (SLOs),contemporary Large Language Models (LLMs) decouple the prefill and decoding stages and place them on separate GPUs to mitigate the distinct bottlenecks inherent to each phase. However, the heterogeneity of LLM workloads causes producerconsumer imbalance between the two instance types in such disaggregated architecture. To address this problem, we propose DOPD (Dynamic Optimal Prefill/Decoding), a dynamic LLM inference system that adjusts instance allocations to achieve an optimal prefill-to-decoding (P/D) ratio based on real-time load monitoring. Combined with an appropriate request-scheduling policy, DOPD effectively resolves imbalances between prefill and decoding instances and mitigates resource allocation mismatches due to mixed-length requests under high concurrency. Experimental evaluations show that, compared with vLLM and DistServe (representative aggregation-based and disaggregationbased approaches), DOPD improves overall system goodput by up to 1.5X, decreases P90 time-to-first-token (TTFT) by up to 67.5%, and decreases P90 time-per-output-token (TPOT) by up to 22.8%. Furthermore, our dynamic P/D adjustment technique performs proactive reconfiguration based on historical load, achieving over 99% SLOs attainment while using less additional resources.

</details>


### [33] [Automated Dynamic AI Inference Scaling on HPC-Infrastructure: Integrating Kubernetes, Slurm and vLLM](https://arxiv.org/abs/2511.21413)
*Tim Trappen,Robert Keßler,Roland Pabel,Viktor Achter,Stefan Wesner*

Main category: cs.DC

TL;DR: 提出了一种在超级计算机RAMSES上集成vLLM、Slurm和Kubernetes来服务LLM的解决方案，该架构能够高效扩展以处理100、500和1000个并发请求，端到端延迟仅增加约500毫秒。


<details>
  <summary>Details</summary>
Motivation: 由于AI推理需求增长，特别是在高等教育领域，需要利用现有基础设施的新解决方案。传统HPC操作模型不适用于同步、面向用户的动态AI应用工作负载。

Method: 在超级计算机RAMSES上集成vLLM、Slurm和Kubernetes来服务大语言模型(LLM)。

Result: 初始基准测试表明，该架构能够高效扩展处理100、500和1000个并发请求，端到端延迟仅增加约500毫秒。

Conclusion: 提出的解决方案成功解决了传统HPC在AI推理应用中的局限性，实现了高效可扩展的LLM服务架构。

Abstract: Due to rising demands for Artificial Inteligence (AI) inference, especially in higher education, novel solutions utilising existing infrastructure are emerging. The utilisation of High-Performance Computing (HPC) has become a prevalent approach for the implementation of such solutions. However, the classical operating model of HPC does not adapt well to the requirements of synchronous, user-facing dynamic AI application workloads. In this paper, we propose our solution that serves LLMs by integrating vLLM, Slurm and Kubernetes on the supercomputer \textit{RAMSES}. The initial benchmark indicates that the proposed architecture scales efficiently for 100, 500 and 1000 concurrent requests, incurring only an overhead of approximately 500 ms in terms of end-to-end latency.

</details>


### [34] [MemFine: Memory-Aware Fine-Grained Scheduling for MoE Training](https://arxiv.org/abs/2511.21431)
*Lu Zhao,Rong Shi,Shaoqing Zhang,Yueqiang Chen,Baoguo He,Hongfeng Sun,Ziqing Yin,Shangchao Su,Zhiyan Cui,Liang Dong,Xiyuan Li,Lingbin Wang,Jianwei He,Jiesong Ma,Weikang Huang,Jianglei Tong,Dongdong Gao,Jian Zhang,Hong Tian*

Main category: cs.DC

TL;DR: MemFine是一个内存感知的细粒度调度框架，用于解决MoE模型训练中的内存瓶颈问题，通过分块重计算策略减少48.03%的激活内存并提升4.42%的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大规模MoE模型训练面临严重的内存瓶颈，由于动态令牌路由导致的负载不均衡会在有限容量的GPU上造成内存溢出，限制了模型的可扩展性。现有的负载平衡方法会牺牲模型精度且无法在内存受限的硬件上工作。

Method: MemFine将令牌分布和专家计算分解为可管理的块，采用分块重计算策略，通过理论内存模型动态优化以平衡内存效率和吞吐量。

Result: 实验表明，MemFine相比基于完全重计算的基线方法，减少了48.03%的激活内存使用，并提升了4.42%的吞吐量，能够在内存有限的GPU上实现稳定的大规模MoE训练。

Conclusion: MemFine框架有效解决了MoE训练中的内存瓶颈问题，通过内存感知的细粒度调度实现了内存效率和训练性能的平衡，为大规模MoE模型在资源受限环境下的训练提供了可行方案。

Abstract: The training of large-scale Mixture of Experts (MoE) models faces a critical memory bottleneck due to severe load imbalance caused by dynamic token routing. This imbalance leads to memory overflow on GPUs with limited capacity, constraining model scalability. Existing load balancing methods, which cap expert capacity, compromise model accuracy and fail on memory-constrained hardware. To address this, we propose MemFine, a memory-aware fine-grained scheduling framework for MoE training. MemFine decomposes the token distribution and expert computation into manageable chunks and employs a chunked recomputation strategy, dynamically optimized through a theoretical memory model to balance memory efficiency and throughput. Experiments demonstrate that MemFine reduces activation memory by 48.03% and improves throughput by 4.42% compared to full recomputation-based baselines, enabling stable large-scale MoE training on memory-limited GPUs.

</details>


### [35] [Modeling the Effect of Data Redundancy on Speedup in MLFMA Near-Field Computation](https://arxiv.org/abs/2511.21535)
*Morteza Sadeghi*

Main category: cs.DC

TL;DR: 该论文通过引入数据冗余来改善MLFMA中近场算子的GPU性能，减少内存访问分散性以提高空间局部性。提出了基于局部性度量的分析模型来预测加速趋势，并在两个MLFMA应用中验证，结果显示内核加速达7倍，但端到端应用加速仅1.04倍。


<details>
  <summary>Details</summary>
Motivation: MLFMA中的近场算子在GPU上由于内存局部性差而成为性能瓶颈，需要改善内存访问模式来提升性能。

Method: 引入数据冗余来减少内存访问分散性，提高空间局部性；提出基于数据量和访问分散性的局部性度量分析模型来预测性能趋势。

Result: 内核性能提升达7倍，但由于数据重组开销增加，端到端应用加速仅1.04倍；分析模型能可靠捕捉不同问题规模和密度下的性能趋势。

Conclusion: 数据冗余可以提升GPU上近场算子的性能，前提是局部性收益超过数据移动成本；该技术可最小化代码修改注入现有实现。

Abstract: The near-field (P2P) operator in the Multilevel Fast Multipole Algorithm (MLFMA) is a performance bottleneck on GPUs due to poor memory locality. This work introduces data redundancy to improve spatial locality by reducing memory access dispersion. For validation of results, we propose an analytical model based on a Locality metric that combines data volume and access dispersion to predict speedup trends without hardware-specific profiling. The approach is validated on two MLFMA-based applications: an electromagnetic solver (DBIM-MLFMA) with regular structure, and a stellar dynamics code (PhotoNs-2.0) with irregular particle distribution. Results show up to 7X kernel speedup due to improved cache behavior. However, increased data volume raises overheads in data restructuring, limiting end-to-end application speedup to 1.04X. While the model cannot precisely predict absolute speedups, it reliably captures performance trends across different problem sizes and densities. The technique is injectable into existing implementations with minimal code changes. This work demonstrates that data redundancy can enhance GPU performance for P2P operator, provided locality gains outweigh data movement costs.

</details>


### [36] [Diagonal Scaling: A Multi-Dimensional Resource Model and Optimization Framework for Distributed Databases](https://arxiv.org/abs/2511.21612)
*Shahir Abdullah,Syed Rohit Zaman*

Main category: cs.DC

TL;DR: 该论文提出了二维扩展平面模型，将水平扩展（节点数）和垂直扩展（节点资源）结合起来，通过对角线扩展策略优化云数据库的性能和成本。


<details>
  <summary>Details</summary>
Motivation: 传统云数据库的扩展策略过于简单，只考虑水平或垂直扩展，无法有效应对性能、成本和协调开销的复杂交互关系，导致系统对负载波动反应不当。

Method: 提出扩展平面模型，将数据库配置表示为(H,V)点；开发DIAGONALSCALE算法，在扩展平面中评估水平、垂直和对角线移动，选择最优配置。

Result: 对角线扩展相比纯水平或垂直扩展，可将p95延迟降低40%，查询成本降低37%，重新平衡次数减少2-5倍。

Conclusion: 需要多维扩展模型，对角线扩展为下一代云数据库自动扩展提供了基础。

Abstract: Modern cloud databases present scaling as a binary decision: scale-out by adding nodes or scale-up by increasing per-node resources. This one-dimensional view is limiting because database performance, cost, and coordination overhead emerge from the joint interaction of horizontal elasticity and per-node CPU, memory, network bandwidth, and storage IOPS. As a result, systems often overreact to load spikes, underreact to memory pressure, or oscillate between suboptimal states. We introduce the Scaling Plane, a two-dimensional model in which each distributed database configuration is represented as a point (H, V), with H denoting node count and V a vector of resources. Over this plane, we define smooth approximations of latency, throughput, coordination overhead, and monetary cost, providing a unified view of performance trade-offs. We show analytically and empirically that optimal scaling trajectories frequently lie along diagonal paths: sequences of joint horizontal and vertical adjustments that simultaneously exploit cluster parallelism and per-node improvements. To compute such actions, we propose DIAGONALSCALE, a discrete local-search algorithm that evaluates horizontal, vertical, and diagonal moves in the Scaling Plane and selects the configuration minimizing a multi-objective function subject to SLA constraints. Using synthetic surfaces, microbenchmarks, and experiments on distributed SQL and KV systems, we demonstrate that diagonal scaling reduces p95 latency by up to 40 percent, lowers cost-per-query by up to 37 percent, and reduces rebalancing by 2 to 5 times compared to horizontal-only and vertical-only autoscaling. Our results highlight the need for multi-dimensional scaling models and provide a foundation for next-generation autoscaling in cloud database systems.

</details>


### [37] [AI/ML Model Cards in Edge AI Cyberinfrastructure: towards Agentic AI](https://arxiv.org/abs/2511.21661)
*Beth Plale,Neelesh Karthikeyan,Isuru Gamage,Joe Stubbs,Sachith Withana*

Main category: cs.DC

TL;DR: 该论文研究了通过Patra模型卡和模型上下文协议(MCP)实现动态模型卡评估，分析了MCP作为接口的优缺点，包括性能开销和活跃会话支持。


<details>
  <summary>Details</summary>
Motivation: 传统AI/ML模型卡在训练时的一次性评估无法反映模型在实际使用过程中的表现，需要动态评估机制来跟踪模型在整个生命周期中的使用情况。

Method: 在ICICLE AI Institute软件生态系统中嵌入Patra模型卡，研究模型卡作为动态对象，并评估采用模型上下文协议(MCP)作为Patra模型卡服务器接口的效益和权衡。

Result: 定量评估显示MCP相比REST接口存在性能开销，但核心价值在于MCP支持的活跃会话功能，这为动态模型卡提供了更好的适用性。

Conclusion: MCP虽然带来一定的性能开销，但通过支持活跃会话为动态模型卡提供了更好的使用环境，解决了传统一次性评估的局限性。

Abstract: AI/ML model cards can contain a benchmarked evaluation of an AI/ML model against intended use but a one time assessment during model training does not get at how and where a model is actually used over its lifetime. Through Patra Model Cards embedded in the ICICLE AI Institute software ecosystem we study model cards as dynamic objects. The study reported here assesses the benefits and tradeoffs of adopting the Model Context Protocol (MCP) as an interface to the Patra Model Card server. Quantitative assessment shows the overhead of MCP as compared to a REST interface. The core question however is of active sessions enabled by MCP; this is a qualitative question of fit and use in the context of dynamic model cards that we address as well.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [38] [E-GEO: A Testbed for Generative Engine Optimization in E-Commerce](https://arxiv.org/abs/2511.20867)
*Puneet S. Bagga,Vivek F. Farias,Tamar Korkotashvili,Tianyi Peng,Yuhang Wu*

Main category: cs.IR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the rise of large language models (LLMs), generative engines are becoming powerful alternatives to traditional search, reshaping retrieval tasks. In e-commerce, for instance, conversational shopping agents now guide consumers to relevant products. This shift has created the need for generative engine optimization (GEO)--improving content visibility and relevance for generative engines. Yet despite its growing importance, current GEO practices are ad hoc, and their impacts remain poorly understood, especially in e-commerce. We address this gap by introducing E-GEO, the first benchmark built specifically for e-commerce GEO. E-GEO contains over 7,000 realistic, multi-sentence consumer product queries paired with relevant listings, capturing rich intent, constraints, preferences, and shopping contexts that existing datasets largely miss. Using this benchmark, we conduct the first large-scale empirical study of e-commerce GEO, evaluating 15 common rewriting heuristics and comparing their empirical performance. To move beyond heuristics, we further formulate GEO as a tractable optimization problem and develop a lightweight iterative prompt-optimization algorithm that can significantly outperform these baselines. Surprisingly, the optimized prompts reveal a stable, domain-agnostic pattern--suggesting the existence of a "universally effective" GEO strategy. Our data and code are publicly available at https://github.com/psbagga17/E-GEO.

</details>


### [39] [Generating Querying Code from Text for Multi-Modal Electronic Health Record](https://arxiv.org/abs/2511.20904)
*Mengliang ZHang*

Main category: cs.IR

TL;DR: 构建了TQGen数据集和TQGen-EHRQuery框架，用于电子健康记录的自然语言查询生成，通过医疗知识模块和问题模板匹配模块解决复杂医学术语和多样化查询的挑战。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录包含大量结构化和非结构化数据，查询相关信息需要复杂数据库操作，增加了临床医生的工作负担。复杂表关系和专业术语限制了查询准确性。

Method: 提出TQGen-EHRQuery框架，包含医疗知识模块和问题模板匹配模块。引入工具集概念，将文本处理模块封装为可调用工具，提高处理效率和灵活性。

Result: 通过广泛实验验证了数据集和工作流程的有效性，展示了增强EHR系统信息查询能力的潜力。

Conclusion: 该研究构建的公开数据集和提出的框架能够有效解决EHR中复杂查询问题，为医疗信息查询提供了实用解决方案。

Abstract: Electronic health records (EHR) contain extensive structured and unstructured data, including tabular information and free-text clinical notes. Querying relevant patient information often requires complex database operations, increasing the workload for clinicians. However, complex table relationships and professional terminology in EHRs limit the query accuracy. In this work, we construct a publicly available dataset, TQGen, that integrates both \textbf{T}ables and clinical \textbf{T}ext for natural language-to-query \textbf{Gen}eration. To address the challenges posed by complex medical terminology and diverse types of questions in EHRs, we propose TQGen-EHRQuery, a framework comprising a medical knowledge module and a questions template matching module. For processing medical text, we introduced the concept of a toolset, which encapsulates the text processing module as a callable tool, thereby improving processing efficiency and flexibility. We conducted extensive experiments to assess the effectiveness of our dataset and workflow, demonstrating their potential to enhance information querying in EHR systems.

</details>


### [40] [FITRep: Attention-Guided Item Representation via MLLMs](https://arxiv.org/abs/2511.21389)
*Guoxiao Zhang,Ao Li,Tan Qu,Qianlong Xie,Xingxing Wang*

Main category: cs.IR

TL;DR: FITRep是一个基于特征整合理论的白盒项目表示框架，通过分层语义概念提取、结构保持降维和FAISS聚类，解决了多模态项目去重中的局部结构崩溃问题，在美团广告系统中显著提升了点击率和千次展示收益。


<details>
  <summary>Details</summary>
Motivation: 在线平台存在大量视觉和文本相似的近重复项目，导致用户体验下降。现有多模态大语言模型方法将表示视为黑盒，忽略了结构关系，造成局部结构崩溃问题。

Method: FITRep包含三个核心组件：1）概念分层信息提取，使用MLLMs提取分层语义概念；2）结构保持降维，基于UMAP的自适应信息压缩方法；3）FAISS聚类，为每个项目分配唯一聚类ID。

Result: 在美团广告系统的在线A/B测试中，FITRep实现了+3.60%的点击率提升和+4.25%的千次展示收益提升。

Conclusion: FITRep通过注意力引导的白盒表示框架，有效解决了多模态项目去重中的结构关系忽略问题，在实际应用中展现出显著效果和商业价值。

Abstract: Online platforms usually suffer from user experience degradation due to near-duplicate items with similar visuals and text. While Multimodal Large Language Models (MLLMs) enable multimodal embedding, existing methods treat representations as black boxes, ignoring structural relationships (e.g., primary vs. auxiliary elements), leading to local structural collapse problem. To address this, inspired by Feature Integration Theory (FIT), we propose FITRep, the first attention-guided, white-box item representation framework for fine-grained item deduplication. FITRep consists of: (1) Concept Hierarchical Information Extraction (CHIE), using MLLMs to extract hierarchical semantic concepts; (2) Structure-Preserving Dimensionality Reduction (SPDR), an adaptive UMAP-based method for efficient information compression; and (3) FAISS-Based Clustering (FBC), a FAISS-based clustering that assigns each item a unique cluster id using FAISS. Deployed on Meituan's advertising system, FITRep achieves +3.60% CTR and +4.25% CPM gains in online A/B tests, demonstrating both effectiveness and real-world impact.

</details>


### [41] [RIA: A Ranking-Infused Approach for Optimized listwise CTR Prediction](https://arxiv.org/abs/2511.21394)
*Guoxiao Zhang,Tan Qu,Ao Li,DongLin Ni,Qianlong Xie,Xingxing Wang*

Main category: cs.IR

TL;DR: RIA是一个统一的端到端重排序框架，通过集成点对点和列表评估，解决了传统方法中排序与重排序分离导致的组合稀疏性和表示能力受限问题。


<details>
  <summary>Details</summary>
Motivation: 现有重排序方法通常将排序和重排序解耦，导致在严格延迟约束下产生弱列表评估模型，存在组合稀疏性和有限表示能力的问题。

Method: RIA包含四个关键组件：用户和候选双Transformer（UCDT）用于细粒度用户-物品-上下文建模；上下文感知用户历史和目标（CUHT）模块用于位置敏感偏好学习；列表多HSTU（LMH）模块捕获层次化物品依赖关系；嵌入缓存（EC）模块在推理时平衡效率与效果。

Result: 在公共和工业数据集上的广泛实验表明，RIA在AUC和LogLoss指标上显著优于最先进模型。在美团广告系统中部署后，在线A/B测试显示点击率提升1.69%，千次展示成本提升4.54%。

Conclusion: RIA通过跨排序和重排序共享表示，实现了丰富的上下文知识传递，同时保持低延迟，为推荐系统重排序提供了有效的端到端解决方案。

Abstract: Reranking improves recommendation quality by modeling item interactions. However, existing methods often decouple ranking and reranking, leading to weak listwise evaluation models that suffer from combinatorial sparsity and limited representational power under strict latency constraints. In this paper, we propose RIA (Ranking-Infused Architecture), a unified, end-to-end framework that seamlessly integrates pointwise and listwise evaluation. RIA introduces four key components: (1) the User and Candidate DualTransformer (UCDT) for fine-grained user-item-context modeling; (2) the Context-aware User History and Target (CUHT) module for position-sensitive preference learning; (3) the Listwise Multi-HSTU (LMH) module to capture hierarchical item dependencies; and (4) the Embedding Cache (EC) module to bridge efficiency and effectiveness during inference. By sharing representations across ranking and reranking, RIA enables rich contextual knowledge transfer while maintaining low latency. Extensive experiments show that RIA outperforms state-of-the-art models on both public and industrial datasets, achieving significant gains in AUC and LogLoss. Deployed in Meituan advertising system, RIA yields a +1.69% improvement in Click-Through Rate (CTR) and a +4.54% increase in Cost Per Mille (CPM) in online A/B tests.

</details>


<div id='nucl-th'></div>

# nucl-th [[Back]](#toc)

### [42] [Simultaneous Inference of Effective Range Parameters and EFT Truncation Uncertainty in $^{3}$He-$α$ Scattering](https://arxiv.org/abs/2511.21069)
*Andrius Burnelis,Daniel R. Phillips*

Main category: nucl-th

TL;DR: 本文扩展了氦-3和氦-4低能弹性散射的光晕有效场理论分析，将7/2- f波共振作为显式自由度纳入，构建了包含理论不确定性的贝叶斯分析框架。


<details>
  <summary>Details</summary>
Motivation: 研究f波共振在氦-3和氦-4散射中的作用，解决不同运动学区域需要不同幂计数方案的问题，并量化有效场理论的截断不确定性。

Method: 构建部分波振幅层面的理论不确定性模型，生成理论协方差矩阵，进行贝叶斯分析同时估计有效范围理论参数和截断不确定性参数的后验分布。

Result: 比较了两种分析：在2.6 MeV以下不考虑f波相互作用，在5.5 MeV以下包含f波相互作用。推断的分解尺度与先前工作一致，发现当实验室能量大于约3.6 MeV时需要f波相互作用来描述数据。

Conclusion: f波相互作用对于描述高能区（E_lab > 3.6 MeV）的氦-3和氦-4散射数据是必要的，构建的理论不确定性模型能够有效捕捉理论误差结构随能量的变化。

Abstract: We extend previous halo effective field theory analyses of low-energy elastic scattering of $^{3}$He-$^{4}$He, including the $\frac{7}{2}^{-}$ $f$-wave resonance as an explicit degree of freedom. The presence of this resonance necessitates a changing power counting scheme depending on the kinematic region. Therefore, we construct a theory uncertainty model at the partial wave amplitude level, allowing us to generate a sophisticated theory covariance matrix that captures the way the theory error structure changes as energy increases. We then perform a Bayesian analysis and simultaneously estimate the joint posterior distributions of the effective range theory parameters and the parameters that characterize the effective field theory truncation uncertainty. We compare two different analyses: no $f$-wave interactions for data up to $E_{\text{max}} = 2.6$ MeV, and including $f$-wave interactions for data up to $E_{\text{max}} = 5.5$ MeV. The inferred breakdown scales in each analysis are consistent with previous work. We find that $f$-wave interactions are needed to describe data for $E_{lab} \gtrapprox 3.6$ MeV.

</details>


### [43] [Deuteron yields near the QCD phase transition](https://arxiv.org/abs/2511.21117)
*Sheng-nan Han,Jing Wu,Yong-rui Chen,Yi-zhen Huang,Feng Li,Wei-jie Fu*

Main category: nucl-th

TL;DR: 本文研究了QCD相变和临界端点(CEP)的临界涨落对氘核产额的影响，发现氘核产额在低碰撞能量区域（大重子化学势区域）的增强效应较弱。


<details>
  <summary>Details</summary>
Motivation: 研究QCD相变和临界端点的临界涨落如何影响氘核产额，探索在重离子碰撞实验中探测QCD临界点的可能性。

Method: 采用功能重整化群(fRG)方法，结合核子聚结模型和夸克介子的低能有效场论，分析两点重子密度关联函数。

Result: 发现两点重子密度关联函数在临界端点沿相边界辐射的狭窄区域内增强，但氘核产额相对于主导阶贡献较小。

Conclusion: 在低碰撞能量区域，由于冻结曲线偏离临界区域，临界涨落对氘核产额的增强效应较为温和。

Abstract: We investigate the influence of QCD phase transition and critical fluctuations of the critical end point (CEP) on the deuteron yield within the functional renormalization group (fRG) approach, by using the nucleon coalescence model and a low energy effective field theory of quarks and mesons. It is found that the two-point baryon density correlation function is enhanced in a narrow region radiated from the CEP along the phase boundary. The deuteron yield arising from the two-point baryon correlation is small compared to the leading-order contribution, which is attributed to the fact that in the regime of low collision energy, i.e., the region of large baryon chemical potential, the freeze-out curves deviate from the critical region, resulting in that the enhancement of the deuteron yield stemming from the critical fluctuations near the CEP is mild.

</details>


### [44] [A Bottom-Up EFT Approach To Superdense Baryonic Matter](https://arxiv.org/abs/2511.21141)
*Mannque Rho*

Main category: nucl-th

TL;DR: 本文描述了如何从Walecka的线性ω-σ平均场模型出发，通过隐局部对称性、隐标度对称性和涌现宇称双重对称性，构建致密星中最高密度物质的理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究如何在致密星中心实现从强子到夸克的拓扑转变，而不经历相变，以解释高密度物质的性质。

Method: 采用自下而上的方法，从手征对称性出发，结合隐局部和标度对称性自由度，利用重正化群处理费米球上的费米子相互作用，得到广义的密度泛函。

Result: 获得了伪共形物质，其声速平方约为1/3，但能量-动量张量的迹不为零，表明物质是非共形的。

Conclusion: 通过拓扑变化实现了强子到夸克的转变，高密度物质表现出伪共形特性，但本质上是非共形的。

Abstract: How to arrive at the densest matter in massive compact stars starting from Walecka's linear $ω$-$σ$ mean-field model is described in a series of arguments anchored on hidden local symmetry, hidden scale symmetry and emergent parity-doublet symmetry. I follow the bottom-up approach from chiral symmetry with pions, coupled to hidden local and scale symmetry degrees of freedom. Exploiting the renormalization-group treatment à la Shankar and Polchinski of the fermionic interactions on the Fermi sphere, leading to Landau-Migdal Fermi-liquid, one obtains a sort of generalized ``Density Functional" that allows via a topology change hadrons transform to quarks without phase changes at the center of massive stars. The highly dense matter is ``pseudo-conformal" with the sound velocity $v_{pcs}^2/c^2\approx 1/3$ but the trace of the energy-momentum tensor is not equal to zero, hence the matter is non-conformal.

</details>
